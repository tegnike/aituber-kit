{
  "Description": "حول التطبيق",
  "BasedSettings": "الإعدادات الأساسية",
  "AISettings": "إعدادات الذكاء الاصطناعي",
  "CharacterSettings": "إعدادات الشخصية",
  "YoutubeSettings": "إعدادات يوتيوب",
  "VoiceSettings": "إعدادات الصوت الاصطناعي",
  "SlideSettings": "إعدادات الشريحة",
  "LogSettings": "سجل المحادثات",
  "OtherSettings": "أخرى",
  "ExternalLinkageMode": "وضع الربط الخارجي (نسخة تجريبية)",
  "YoutubeMode": "وضع يوتيوب",
  "YoutubeInfo": "إذا كان الحرف الأول من التعليق هو '#'، يتم تجاهله.",
  "YoutubeAPIKey": "مفتاح API يوتيوب",
  "YoutubeLiveID": "معرف البث المباشر على يوتيوب",
  "ConversationContinuityMode": "وضع استمرارية المحادثة (تجريبي)",
  "ConversationContinuityModeInfo": "عندما لا يكون هناك تعليق، يحاول الذكاء الاصطناعي مواصلة المحادثة. حالياً يدعم فقط OpenAI وAnthropicClaude وGoogle Gemini.",
  "ConversationContinuityModeInfo2": "كل إجابة تستدعي LLM عدة مرات، لذا قد يزيد استخدام API. يرجى الانتباه لذلك.",
  "ConversationContinuityModeInfo3": "gpt-4o وgpt-4-turbo وclaude-3-opus وclaude-3.5-sonnet تعمل بشكل مستقر نسبياً.",
  "MaxPastMessages": "عدد الرسائل السابقة للاحتفاظ بها",
  "StatusOn": "الحالة: تشغيل",
  "StatusOff": "الحالة: إيقاف",
  "Select": "اختيار",
  "TestVoice": "اختبار الصوت",
  "SelectAIService": "اختيار خدمة الذكاء الاصطناعي",
  "LocalLLM": "LLM محلي",
  "SelectModel": "اختيار النموذج",
  "OpenAIAPIKeyLabel": "مفتاح API OpenAI",
  "AnthropicAPIKeyLabel": "مفتاح API Anthropic",
  "GoogleAPIKeyLabel": "مفتاح API Google Gemini",
  "AzureAPIKeyLabel": "مفتاح API Azure OpenAI",
  "AzureAPIURL": "رابط API Azure OpenAI",
  "GroqAPIKeyLabel": "مفتاح API Groq",
  "CohereAPIKeyLabel": "مفتاح API Cohere",
  "MistralAIAPIKeyLabel": "مفتاح API MistralAI",
  "PerplexityAPIKeyLabel": "مفتاح API Perplexity",
  "FireworksAPIKeyLabel": "مفتاح API Fireworks",
  "DifyAPIKeyLabel": "مفتاح API Dify",
  "DeepSeekAPIKeyLabel": "مفتاح API DeepSeek",
  "APIKeyInstruction": "يمكنك الحصول على مفتاح API أدناه. أدخل مفتاح API الذي حصلت عليه في النموذج.",
  "LocalLLMInfo": "يجب أن يكون خادم LLM المحلي قيد التشغيل. الإعداد كما يلي.",
  "LocalLLMInfo2": "الرجاء إدخال عنوان URL لخادم LLM المحلي (متضمناً رقم المنفذ) واسم النموذج.",
  "GroqInfo": "يتم الوصول إلى Groq API مباشرة من المتصفح.",
  "DifyInfo": "Dify يدعم فقط نوع chatbot وagent.",
  "DifyInfo2": "طول سجل المحادثة يعتمد على مواصفات Dify.",
  "DifyInfo3": "مثال: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "إذا كنت تستخدم Dify، لن يتم استخدام النص التمهيدي للنظام. يرجى إعداد chatbot Dify.",
  "EnterURL": "URL",
  "CharacterModelLabel": "نموذج الشخصية",
  "CharacterModelInfo": "قد يستغرق تحميل النموذج وقتاً عند عرضه لأول مرة.",
  "OpenVRM": "فتح VRM",
  "BackgroundImage": "صورة الخلفية",
  "ChangeBackgroundImage": "تغيير صورة الخلفية",
  "CharacterSettingsPrompt": "نص الشخصية",
  "CharacterSettingsInfo": "يتم تعيين هذه القيمة كنص تمهيدي للنظام.\nيرجى الرجوع إلى النص التمهيدي الأولي وتحديد علامات المشاعر للتحكم في تعبيرات وحركات الشخصية. مثال: [neutral]صباح الخير![happy]اليوم أيضاً يوم صعب!",
  "characterpresetInfo": " يؤدي تحديد إعداد مسبق إلى تغيير موجه الأحرف.\nCmd + Shift + 1~5 (ماك) / Ctrl + Shift + 1~5 (ويندوز) للاختصارات.\n يؤدي تحديد إعداد مسبق أثناء الضغط باستمرار على مفتاح Shift إلى حفظ مطالبة الحرف الحالي في الإعداد المسبق.",
  "Characterpreset1": "الإعداد المسبق 1",
  "Characterpreset2": "الإعداد المسبق 2",
  "Characterpreset3": "الإعداد المسبق 3",
  "Characterpreset4": "الإعداد المسبق 4",
  "Characterpreset5": "الإعداد المسبق 5",
  "SyntheticVoiceEngineChoice": "اختيار محرك الصوت الاصطناعي",
  "VoiceAdjustment": "ضبط الصوت",
  "VoiceEngineInstruction": "اختر محرك الصوت الاصطناعي الذي تريد استخدامه.",
  "UsingKoeiromap": "Koeiromap",
  "KoeiromapInfo": "استخدام Koeiromap API من Koemotion. يدعم اللغة اليابانية فقط. لمزيد من التفاصيل، يرجى الرجوع إلى الرابط أدناه.",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceVoxInfo": "استخدام VOICEVOX. يدعم اللغة اليابانية فقط. يستخدم API محلي، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "VoicevoxSpeed": "السرعة",
  "VoicevoxPitch": "درجة الصوت",
  "VoicevoxIntonation": "نبرة الصوت",
  "UsingAivisSpeech": "AivisSpeech",
  "AivisSpeechInfo": "استخدام AivisSpeech. يدعم اللغة اليابانية فقط. يستخدم API محلي، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "AivisSpeechSpeaker": "المتحدث",
  "AivisSpeechSpeed": "السرعة",
  "AivisSpeechPitch": "درجة الصوت",
  "AivisSpeechIntonation": "نبرة الصوت",
  "AivisSpeechServerUrl": "عنوان خادم AivisSpeech",
  "UsingNijiVoice": "NijiVoice",
  "NijiVoiceInfo": "يتم استخدام NijiVoice API. يدعم اللغة اليابانية فقط. يمكن الحصول على مفتاح API من الرابط أدناه.",
  "NijiVoiceApiKey": "مفتاح API NijiVoice",
  "NijiVoiceActorId": "معرف الممثل",
  "NijiVoiceSpeed": "سرعة الكلام",
  "NijiVoiceEmotionalLevel": "مستوى العاطفة",
  "NijiVoiceSoundDuration": "مدة الصوت",
  "VoicevoxServerUrl": "عنوان خادم VOICEVOX",
  "UpdateSpeakerList": "تحديث قائمة المتحدثين",
  "UsingGoogleTTS": "استخدام Google Text-to-Speech",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "StyleBertVITS2Info": "استخدام Style-Bert-VITS2. يدعم اللغة اليابانية والإنجليزية والصينية فقط. إذا كنت تستخدم API محلي، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه. يرجى أيضاً إعداد مفتاح API إذا لزم الأمر.",
  "SpeakerSelection": "اختيار المتحدث",
  "IncludeTimestampInUserMessage": "تضمين الطابع الزمني في رسالة المستخدم",
  "IncludeTimestampInUserMessageInfo": "من خلال تضمين الطوابع الزمنية في رسائل المستخدم، يمكن للذكاء الاصطناعي إنشاء ردود مع مراعاة الوقت.\nيرجى تضمين النص التالي في النص التمهيدي للنظام:\n\n\"قد يتضمن إدخال المستخدم [timestamp]. هذا يمثل وقت UTC في لحظة الطلب، لذا يرجى إنشاء ردود مع مراعاة هذا الطابع الزمني.\"",
  "GoogleTTSInfo": "استخدام Google Cloud Text-to-Speech. يدعم لغات متعددة.",
  "AuthFileInstruction": "مفتاح API أو ملف المصادقة مطلوب. احصل عليه من الرابط أدناه وضعه في المجلد الجذر للمستودع إذا كان ملف JSON.",
  "LanguageModelURL": "اختر نموذج اللغة من الرابط أدناه.",
  "LanguageChoice": "اختيار اللغة",
  "StyleBeatVITS2ServerURL": "عنوان الخادم",
  "StyleBeatVITS2ApiKey": "مفتاح API",
  "StyleBeatVITS2ModelID": "معرف النموذج",
  "StyleBeatVITS2Style": "النمط",
  "StyleBeatVITS2SdpRatio": "نسبة خلط SDP/DP",
  "StyleBeatVITS2Length": "معدل الكلام",
  "ConversationHistory": "سجل المحادثات",
  "ConversationHistoryInfo": "سيتم الاحتفاظ بأحدث {{count}} محادثات كذاكرة.",
  "ConversationHistoryReset": "إعادة تعيين سجل المحادثات",
  "NotConnectedToExternalAssistant": "غير متصل بمساعد خارجي.",
  "APIKeyNotEntered": "لم يتم إدخال مفتاح API.",
  "ChatLog": "سجل المحادثة",
  "EnterYourQuestion": "أدخل سؤالك هنا",
  "AnswerGenerating": "جاري إنشاء الإجابة",
  "AboutThisApplication": "حول هذا التطبيق",
  "AboutThisApplicationDescription": "استمتع بالمحادثات مع شخصية ثلاثية الأبعاد مباشرة في متصفحك، باستخدام الميكروفون أو إدخال النص وتوليف الصوت. يمكنك أيضاً تغيير الشخصية (VRM)، وضبط شخصيتها، وتعديل صوتها.<br />يمكن تغيير الإعدادات من زر القائمة في الأعلى اليسار.",
  "AboutThisApplicationDescription2": "إذا كنت تريد تغيير الشخصية، يرجى الرجوع إلى علامة تبويب \"إعدادات الشخصية\".",
  "TechnologyIntroduction": "مقدمة التقنية",
  "TechnologyIntroductionDescription1": "تم إنشاء هذا التطبيق عن طريق تعديل <b>ChatVRM</b> من pixiv. يمكن العثور على الكود المصدري الأصلي",
  "TechnologyIntroductionLink1": "هنا",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "لعرض ومعالجة النماذج ثلاثية الأبعاد،",
  "TechnologyIntroductionDescription4": "يتم استخدام. لتوليد نص المحادثة، يتم استخدام نماذج LLM مختلفة مثل",
  "TechnologyIntroductionDescription5": "يتم استخدام. لتوليف الكلام، يتم استخدام محركات TTS مختلفة مثل",
  "TechnologyIntroductionDescription6": "يتم استخدام. لمزيد من التفاصيل، يرجى الاطلاع على هذا",
  "TechnologyIntroductionLink2": "المقال التوضيحي",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "الكود المصدري لهذا التطبيق متاح للعموم على GitHub. لا تتردد في تعديله وتكييفه كما تريد.",
  "SourceCodeDescription2": "للاستخدام التجاري، يرجى الرجوع إلى ملف README في نفس المستودع.",
  "RepositoryURL": "رابط المستودع:",
  "DontShowIntroductionNextTime": "لا تظهر هذا الحوار في المرة القادمة",
  "Close": "إغلاق",
  "Contact": "اتصل بنا",
  "ContactDescription": "يرجى الاتصال بي عبر عنوان البريد الإلكتروني أو حساب تويتر أدناه بخصوص هذا التطبيق.",
  "Creator": "المنشئ",
  "CreatorDescription": "المنشئ: Tegan",
  "Language": "اللغة",
  "UsingGSVITTS": "GSVI TTS",
  "GSVITTSInfo": "إعدادات GSVI TTS",
  "GSVITTSServerUrl": "نقطة نهاية API GSVI TTS",
  "GSVITTSModelID": "معرف نموذج GSVI TTS",
  "GSVITTSBatchSize": "حجم الدفعة GSVI TTS (1 ~ 100 كلما كانت القيمة أكبر، كانت سرعة الاستدلال أسرع، ولكن قد تستنفد الذاكرة إذا كانت كبيرة جداً.)",
  "GSVITTSSpeechRate": "معدل الكلام (0.5 ~ 2.0 كلما كانت القيمة أكبر، كان أسرع.)",
  "UsingElevenLabs": "ElevenLabs",
  "ElevenLabsInfo": "يتم استخدام ElevenLabs API. يدعم لغات متعددة. يمكن الحصول على مفتاح API من الرابط أدناه.",
  "ElevenLabsApiKey": "مفتاح API ElevenLabs",
  "ElevenLabsVoiceId": "معرف صوت ElevenLabs",
  "ElevenLabsVoiceIdInfo": "يمكن اختيار معرف الصوت من الرابط أدناه.",
  "CharacterName": "اسم الشخصية",
  "ShowAssistantText": "إظهار مربع الإجابة",
  "ShowCharacterName": "إظهار اسم الشخصية في مربع الإجابة",
  "ShowControlPanel": "إظهار زر الإعدادات",
  "ShowControlPanelInfo": "يمكن عرض شاشة الإعدادات باستخدام Cmd + . (ماك) / Ctrl + . (ويندوز).\nإذا كنت تستخدم هاتفًا ذكيًا، يمكنك الضغط لفترة طويلة على الزاوية العلوية اليسرى من الشاشة (حوالي 1 ثانية).",
  "SlideMode": "وضع العرض التقديمي",
  "SelectedSlideDocs": "مستندات العرض المحددة",
  "SlideModeDescription": "هذا وضع حيث يقدم الذكاء الاصطناعي العروض التقديمية تلقائياً. متاح فقط عندما تكون خدمة الذكاء الاصطناعي المحددة هي OpenAI أو Anthropic Claude أو Google Gemini.",
  "PdfConvertLabel": "تحويل PDF إلى عرض تقديمي",
  "PdfConvertDescription": "تحويل PDF إلى بيانات وضع العرض التقديمي. متاح فقط عندما تكون خدمة الذكاء الاصطناعي المحددة هي OpenAI أو Anthropic Claude أو Google Gemini.",
  "PdfConvertFileUpload": "اختيار ملف PDF",
  "PdfConvertFolderName": "اسم مجلد الحفظ",
  "PdfConvertModelSelect": "اختيار النموذج",
  "PdfConvertButton": "تحويل PDF إلى عرض تقديمي",
  "PdfConvertLoading": "جاري التحويل...",
  "PdfConvertSuccess": "اكتمل التحويل",
  "PdfConvertError": "فشل التحويل",
  "PdfConvertSubmitError": "يرجى التأكد من تعيين ملف PDF واسم المجلد ومفتاح API.",
  "LocalStorageReset": "إعادة تعيين الإعدادات",
  "LocalStorageResetInfo": "تكون متغيرات البيئة لها الأولوية إذا تم تعيينها. سيتم إعادة تحميل الصفحة.",
  "LocalStorageResetButton": "إعادة تعيين الإعدادات",
  "Errors": {
    "EmptyAPIKey": "لم يتم تعيين مفتاح API",
    "AIInvalidProperty": "إعدادات خدمة الذكاء الاصطناعي غير صحيحة",
    "AIAPIError": "حدث خطأ أثناء تنفيذ API الذكاء الاصطناعي",
    "InvalidAIService": "خدمة الذكاء الاصطناعي المحددة غير صالحة",
    "MethodNotAllowed": "الطلب غير مناسب",
    "TTSServiceError": "حدث خطأ في خدمة {{serviceName}} TTS: {{message}}",
    "UnexpectedError": "حدث خطأ غير متوقع",
    "LocalLLMError": "خطأ في LLM المحلي",
    "LocalLLMStreamError": "خطأ في تدفق LLM المحلي",
    "LocalLLMConnectionError": "خطأ في الاتصال بخادم LLM المحلي",
    "LocalLLMNotFound": "لم يتم العثور على نقطة نهاية LLM المحلي",
    "LocalLLMAPIError": "خطأ في API LLM المحلي",
    "EmptyLocalLLMURL": "لم يتم تعيين عنوان URL لـ LLM المحلي",
    "CustomAPIError": "حدث خطأ في واجهة برمجة التطبيقات المخصصة",
    "InvalidJSON": "تنسيق JSON غير صحيح"
  },
  "MessageReceiver": "تلقي التعليمات من الخارج",
  "MessageReceiverDescription": "يمكنك استخدام API لتوجيه شخصيات الذكاء الاصطناعي للتحدث من الخارج.",
  "ClientID": "معرف العميل",
  "OpenSendMessagePage": "فتح صفحة إرسال الرسائل",
  "RealtimeAPIMode": "وضع API في الوقت الفعلي",
  "RealtimeAPIModeContentType": "نوع الإرسال",
  "RealtimeAPIModeVoice": "نوع الصوت",
  "AudioMode": "وضع الصوت",
  "InputText": "النص",
  "InputAudio": "الصوت",
  "SearchGrounding": "استخدام البحث الأرضي",
  "SearchGroundingDescription": "عند استخدام ميزة متعددة الوسائط، يتم تعطيل وظيفة البحث تلقائياً.",
  "UpdateRealtimeAPISettings": "تحديث إعدادات API في الوقت الفعلي",
  "UpdateRealtimeAPISettingsInfo": "عند تحديث مفتاح API، نقطة نهاية Azure، نوع الصوت، النموذج، أو النص التمهيدي للنظام، يرجى الضغط على زر التحديث لبدء جلسة WebSocket جديدة.",
  "AzureEndpoint": "نقطة نهاية Azure",
  "Toasts": {
    "WebSocketConnectionError": "حدث خطأ في اتصال WebSocket",
    "WebSocketConnectionClosed": "تم إغلاق اتصال WebSocket",
    "WebSocketConnectionAttempt": "محاولة اتصال WebSocket...",
    "WebSocketConnectionSuccess": "نجح اتصال WebSocket",
    "FunctionExecuting": "جاري تنفيذ {{funcName}}",
    "FunctionExecutionFailed": "فشل تنفيذ {{funcName}}",
    "FirefoxNotSupported": "هذه الميزة غير مدعومة على Firefox",
    "SpeechRecognitionError": "حدث خطأ في التعرف على الكلام",
    "PresetSwitching": "تم التبديل إلى {{presetName}}.",
    "WhisperError": "حدث خطأ في التعرف على الصوت بواسطة Whisper"
  },
  "UsingOpenAITTS": "استخدام OpenAI",
  "OpenAITTSInfo": "استخدام OpenAI. يدعم لغات متعددة. إذا اخترت OpenAI كخدمة ذكاء اصطناعي، فلا تحتاج إلى تعيين مفتاح API أدناه.",
  "OpenAITTSVoice": "نوع الصوت",
  "OpenAITTSModel": "النموذج",
  "OpenAITTSSpeed": "السرعة",
  "UsingAzureTTS": "استخدام Azure OpenAI",
  "AzureTTSInfo": "استخدام Azure OpenAI. يدعم لغات متعددة.",
  "SendMessage": {
    "title": "محول AITuberKit الخارجي",
    "directSendTitle": "التحدث مباشرة إلى شخصية الذكاء الاصطناعي",
    "directSendDescription": "يمكنك إرسال الرسالة مباشرة إلى شخصية الذكاء الاصطناعي. إذا تم إرسال رسائل متعددة، تتم معالجتها بالترتيب. نموذج الصوت هو المحدد في إعدادات AITuberKit.",
    "aiGenerateTitle": "توليد رد الذكاء الاصطناعي ثم التحدث",
    "aiGenerateDescription": "يولد الذكاء الاصطناعي رداً من الرسالة المرسلة ثم يتحدث به. إذا تم إرسال رسائل متعددة، تتم معالجتها بالترتيب. نموذج الذكاء الاصطناعي ونموذج الصوت هما المحددان في إعدادات AITuberKit. يمكن اختيار النص التمهيدي للنظام لاستخدام النص التمهيدي لنظام AITuberKit أو نص تمهيدي مخصص. إذا كنت تريد تحميل سجل المحادثة السابق، قم بتضمين السلسلة [conversation_history] في النص التمهيدي للنظام أو رسالة المستخدم.",
    "useCurrentSystemPrompt": "استخدام النص التمهيدي لنظام AITuberKit",
    "userInputTitle": "إرسال إدخال المستخدم",
    "userInputDescription": "تتم معالجة الرسالة المرسلة بنفس طريقة الإدخال من نموذج إدخال AITuberKit. إذا تم إرسال رسائل متعددة، تتم معالجتها بالترتيب. نموذج الذكاء الاصطناعي ونموذج الصوت هما المحددان في إعدادات AITuberKit. النص التمهيدي للنظام وسجل المحادثة هما القيم المعينة في AITuberKit."
  },
  "CannotUseVoice": "إذا كان وضع واجهة برمجة التطبيقات في الوقت الحقيقي أو وضع الصوت مفعلًا،\nفإن إعدادات الصوت الاصطناعي ليست ضرورية.",
  "Live2D": {
    "FileInfo": "ضع نموذج Live2D الذي تريد استخدامه في مجلد public/live2d. يجب أن يوجد ملف model3.json في جذر هذا المجلد.\nإذا لم يتم عرضه في الاختيار، يرجى إعادة تحميل الشاشة أو التحقق من صحة مسار المجلد.",
    "Info": "يمكنك تحديد المشاعر والحركات.\nيتم التحكم في كل عاطفة من خلال النص التمهيدي. لمزيد من التفاصيل، يرجى الرجوع إلى \"إعدادات الذكاء الاصطناعي => إعدادات الشخصية\".",
    "Emotions": "إعدادات المشاعر",
    "EmotionInfo": "يمكن تحديد المشاعر بتنسيق مفصول بفواصل. إذا تم تحديد مشاعر متعددة، يتم اختيارها عشوائياً.\nالقيمة الأولية هي للنموذج المقدم من AITuberKit. إذا كنت تستخدم نموذجاً أصلياً، يرجى إدخال القيمة وفقاً لنموذجك.\nبعد اكتمال المحادثة، يتم عرض عاطفة \"محايد\".",
    "neutralEmotions": "محايد",
    "happyEmotions": "سعيد",
    "sadEmotions": "حزين",
    "angryEmotions": "غاضب",
    "relaxedEmotions": "مسترخي",
    "MotionGroups": "إعدادات مجموعة الحركة",
    "MotionGroupsInfo": "يتم اختيار مجموعات الحركة عشوائياً من المجموعة المحددة.\nمثل إعدادات المشاعر، يرجى تعيينها وفقاً لنموذجك.\n\"خامل\" هي الحركة المعروضة بعد اكتمال المحادثة.",
    "SelectMotionGroup": "اختيار مجموعة الحركة",
    "idleMotionGroup": "خامل",
    "neutralMotionGroup": "محايد",
    "happyMotionGroup": "سعيد",
    "sadMotionGroup": "حزين",
    "angryMotionGroup": "غاضب",
    "relaxedMotionGroup": "مسترخي",
    "surprisedEmotions": "دهشة",
    "surprisedMotionGroup": "دهشة"
  },
  "UseVideoAsBackground": "استخدام الشاشة المشتركة أو كاميرا الويب كخلفية",
  "Temperature": "درجة الحرارة",
  "MaxTokens": "أقصى عدد من الرموز",
  "MaxTokensInfo": "يختلف أقصى عدد من الرموز حسب نموذج الذكاء الاصطناعي المستخدم. يرجى التحقق من مواصفات كل نموذج.",
  "CannotUseParameters": "إذا كان وضع API في الوقت الحقيقي أو وضع الصوت مفعلًا، فلا يمكن تحديد معلمات Temperature و Max Tokens.",
  "DocumentationDescription": "يمكنك الاطلاع على كيفية استخدام AITuberKit والدروس التعليمية التفصيلية من خلال الرابط أدناه.",
  "PresetQuestions": "إعدادات مسبقة للأسئلة",
  "PresetQuestionsInfo": "يمكنك إنشاء وتسجيل أنماط متعددة من الأسئلة مسبقًا. ستظهر الأسئلة المسجلة على واجهة المستخدم الخاصة بالمستخدم في شكل أزرار، وعند النقر عليها، سيتم تعيينها في حقل إدخال الدردشة.",
  "EnterPresetQuestion": "يرجى إدخال السؤال",
  "DragToReorder": "اسحب لتغيير الترتيب",
  "ShowSilenceProgressBar": "عرض شريط تقدم اكتشاف الصمت",
  "CharacterpresetInfo": "عند اختيار الإعداد المسبق، سيتم تغيير موجه الشخصية.\nيمكن استخدام الاختصارات Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "SpeechInputSettings": "إعدادات إدخال الصوت",
  "SpeechRecognitionMode": "وضع التعرف على الصوت",
  "SpeechRecognitionModeInfo": "يمكنك اختيار وضع التعرف على الصوت.\n\"المعيار في المتصفح\" يستخدم التعرف على الصوت المدمج في المتصفح. \"OpenAI TTS\" يستخدم واجهة برمجة التطبيقات لتحويل النص إلى كلام من OpenAI.\nبشكل عام، يُفضل استخدام \"المعيار في المتصفح\" لأنه أكثر دقة وسرعة في التعرف. ومع ذلك، إذا كنت تستخدم متصفحًا لا يدعم واجهة برمجة تطبيقات WebSpeech مثل Firefox، يرجى اختيار \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "استخدام التعرف على الصوت المعياري في المتصفح",
  "WhisperSpeechRecognition": "استخدام التعرف على الصوت من OpenAI TTS",
  "WhisperAPIKeyInfo": "وضع Whisper يتطلب مفتاح API من OpenAI. يرجى إعداد مفتاح API الخاص بـ OpenAI في إعدادات الذكاء الاصطناعي.",
  "WhisperTranscriptionModel": "نموذج النسخ",
  "WhisperTranscriptionModelInfo": "يمكنك اختيار النموذج المستخدم في التعرف على الصوت. كلما كان النموذج أكثر كفاءة، كانت دقته أعلى، ولكن قد تكون تكاليف واجهة برمجة التطبيقات أعلى.",
  "InitialSpeechTimeout": "مهلة التعرف على الصوت",
  "InitialSpeechTimeoutInfo": "قم بتعيين وقت الانتظار حتى يتم اكتشاف أول حديث بعد بدء التعرف على الصوت. إذا لم يتم اكتشاف حديث خلال هذا الوقت، سيتوقف التعرف على الصوت تلقائيًا.\nإذا تم تعيينه على 0 ثانية، سيكون وقت الانتظار غير محدود.",
  "Milliseconds": "ميلي ثانية",
  "ContinuousMic": "إدخال ميكروفون مستمر",
  "ContinuousMicActive": "إدخال ميكروفون مستمر نشط",
  "ContinuousMicModeOn": "وضع إدخال الميكروفون المستمر مفعل",
  "ContinuousMicModeOff": "وضع إدخال الميكروفون المستمر معطل",
  "ListeningContinuously": "في انتظار إدخال الصوت...",
  "ContinuousMicInfo": "سيتم استئناف إدخال الميكروفون تلقائيًا عند انتهاء حديث الذكاء الاصطناعي. سيتم الإرسال تلقائيًا بعد مرور الوقت المحدد للصمت.\nإذا تجاوز الوقت المحدد دون التعرف على الصوت، سيتم إيقاف إدخال الميكروفون المستمر تلقائيًا، لذا إذا كنت ترغب في إبقائه مفعلًا دائمًا، يرجى تعيين مهلة التعرف على الصوت إلى 0 ثانية.",
  "CustomAPIEndpoint": "نقطة نهاية واجهة برمجة التطبيقات المخصصة",
  "CustomAPIEndpointInfo": "يرجى إدخال عنوان URL لنقطة نهاية واجهة برمجة التطبيقات التي سترسل طلب POST إليها.",
  "CustomAPIStream": "وضع البث",
  "CustomAPIStreamForced": "حاليًا، وضع البث مفعل دائمًا.",
  "CustomAPIHeaders": "رؤوس مخصصة",
  "CustomAPIHeadersInfo": "يرجى إدخال معلومات الرأس التي يجب تضمينها في طلب واجهة برمجة التطبيقات بتنسيق JSON.",
  "CustomAPIBody": "جسم مخصص",
  "CustomAPIBodyInfo": "يرجى إدخال معلومات الجسم التي يجب تضمينها في طلب واجهة برمجة التطبيقات بتنسيق JSON. سيتم تضمين الرسائل تلقائيًا.",
  "CustomAPIDescription": "ملاحظة: سيتم تضمين الرسائل تلقائيًا في جسم الطلب. في وضع البث، يجب على الخادم إرجاع text/event-stream.",
  "ShowCharacterPresetMenu": "عرض زر قائمة إعدادات الشخصية",
  "SpeechRecognitionModeDisabledInfo": "إذا كان وضع الصوت مفعلًا، فإن التعرف على الصوت في المتصفح هو الخيار الوحيد المتاح.\nأيضًا، في وضع واجهة برمجة التطبيقات في الوقت الحقيقي، يكون التعرف على الصوت في المتصفح هو الخيار الوحيد المتاح، وستكون ميزة مهلة التعرف على الصوت غير مفعلة."
}