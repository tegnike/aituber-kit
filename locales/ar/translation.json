{
  "Description": "حول التطبيق",
  "BasedSettings": "الإعدادات الأساسية",
  "AISettings": "إعدادات الذكاء الاصطناعي",
  "CharacterSettings": "إعدادات الشخصية",
  "YoutubeSettings": "إعدادات يوتيوب",
  "VoiceSettings": "إعدادات الصوت الاصطناعي",
  "SpeechInputSettings": "إعدادات إدخال الصوت",
  "SlideSettings": "إعدادات العرض التقديمي",
  "LogSettings": "سجل المحادثات",
  "OtherSettings": "إعدادات أخرى",
  "ExternalLinkageMode": "وضع الربط الخارجي (نسخة تجريبية)",
  "YoutubeMode": "وضع يوتيوب",
  "YoutubeInfo": "سيتم تجاهل التعليقات التي تبدأ بـ \"#\".",
  "YoutubeAPIKey": "مفتاح واجهة برمجة يوتيوب",
  "YoutubeLiveID": "معرف بث يوتيوب المباشر",
  "ConversationContinuityMode": "وضع استمرارية المحادثة (نسخة تجريبية)",
  "ConversationContinuityModeInfo": "هذا وضع يحاول فيه الذكاء الاصطناعي مواصلة المحادثة عندما لا تكون هناك تعليقات. يدعم حاليًا OpenAI و Anthropic Claude و Google Gemini فقط.",
  "ConversationContinuityModeInfo2": "يرجى ملاحظة أنه نظرًا لاستدعاء نماذج اللغة الكبيرة عدة مرات في إجابة واحدة، قد تزيد رسوم استخدام واجهة البرمجة.",
  "ConversationContinuityModeInfo3": "يعمل بشكل مستقر نسبيًا مع gpt-4o و gpt-4-turbo و claude-3-opus و claude-3.5-sonnet.",
  "MaxPastMessages": "عدد الرسائل السابقة المحتفظ بها",
  "StatusOn": "الحالة: تشغيل",
  "StatusOff": "الحالة: إيقاف",
  "Select": "الرجاء الاختيار",
  "TestVoice": "اختبار الصوت",
  "SelectAIService": "اختر خدمة الذكاء الاصطناعي",
  "LocalLLM": "نموذج لغوي محلي",
  "SelectModel": "اختر النموذج",
  "OpenAIAPIKeyLabel": "مفتاح واجهة برمجة OpenAI",
  "AnthropicAPIKeyLabel": "مفتاح واجهة برمجة Anthropic",
  "GoogleAPIKeyLabel": "مفتاح واجهة برمجة Google Gemini",
  "AzureAPIKeyLabel": "مفتاح واجهة برمجة Azure OpenAI",
  "AzureAPIURL": "رابط واجهة برمجة Azure OpenAI",
  "GroqAPIKeyLabel": "مفتاح واجهة برمجة Groq",
  "CohereAPIKeyLabel": "مفتاح واجهة برمجة Cohere",
  "MistralAIAPIKeyLabel": "مفتاح واجهة برمجة MistralAI",
  "PerplexityAPIKeyLabel": "مفتاح واجهة برمجة Perplexity",
  "FireworksAPIKeyLabel": "مفتاح واجهة برمجة Fireworks",
  "DifyAPIKeyLabel": "مفتاح واجهة برمجة Dify",
  "DeepSeekAPIKeyLabel": "مفتاح واجهة برمجة DeepSeek",
  "APIKeyInstruction": "يمكنك الحصول على مفتاح واجهة البرمجة من الرابط أدناه. يرجى إدخال مفتاح واجهة البرمجة الذي حصلت عليه في النموذج.",
  "LocalLLMInfo": "يجب تشغيل خادم نموذج اللغة المحلي.",
  "LocalLLMInfo2": "يرجى إدخال عنوان URL للنموذج اللغوي المحلي (مع رقم المنفذ) واسم النموذج.",
  "GroqInfo": "تستخدم واجهة برمجة Groq الوصول المباشر من المتصفح.",
  "DifyInfo": "في Dify، ندعم فقط نوعي الروبوتات أو الوكلاء. إذا لم تحصل على إجابة جيدة، يرجى حذف سجل المحادثة ثم طرح السؤال مرة أخرى.",
  "DifyInfo2": "يعتمد طول سجل المحادثة على إعدادات روبوت دردشة Dify.",
  "DifyInfo3": "مثال: https://api.dify.ai/v1، http://localhost:80/v1",
  "DifyInstruction": "عند استخدام Dify، لا يتم استخدام موجه النظام هذا. يرجى تكوينه في روبوت دردشة Dify.",
  "EnterURL": "أدخل URL",
  "CharacterModelLabel": "نموذج الشخصية",
  "CharacterModelInfo": "قد يستغرق بعض الوقت لتحميل بعض النماذج عند العرض الأولي.",
  "OpenVRM": "فتح VRM",
  "BackgroundImage": "صورة الخلفية",
  "ChangeBackgroundImage": "تغيير صورة الخلفية",
  "BackgroundSettings": "إعدادات الخلفية",
  "BackgroundSettingsDescription": "يمكنك تحميل واختيار صورة خلفية للتطبيق.",
  "UploadBackground": "تحميل صورة خلفية",
  "DefaultBackground": "الخلفية الافتراضية",
  "CharacterSettingsPrompt": "موجه شخصية",
  "CharacterSettingsInfo": "سيتم تعيين هذه القيمة كموجه نظام.\nيمكنك التحكم في تعبيرات وحركات الشخصية باستخدام علامات المشاعر بالإشارة إلى الموجه الأولي. مثال: [neutral]صباح الخير![happy]أتمنى لك يومًا رائعًا!",
  "CharacterpresetInfo": "سيؤدي تحديد إعداد مسبق إلى تغيير موجه الشخصية.\nيمكنك استخدام الاختصارات Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "Characterpreset1": "الإعداد المسبق 1",
  "Characterpreset2": "الإعداد المسبق 2",
  "Characterpreset3": "الإعداد المسبق 3",
  "Characterpreset4": "الإعداد المسبق 4",
  "Characterpreset5": "الإعداد المسبق 5",
  "SyntheticVoiceEngineChoice": "اختيار محرك الصوت الاصطناعي",
  "VoiceAdjustment": "ضبط الصوت",
  "VoiceEngineInstruction": "يرجى اختيار محرك الصوت الاصطناعي الذي تريد استخدامه.",
  "UsingKoeiromap": "استخدام Koeiromap",
  "KoeiromapInfo": "نحن نستخدم واجهة برمجة Koeiromap من Koemotion. تدعم اللغة اليابانية فقط. للمزيد من المعلومات، يرجى الاطلاع على الرابط أدناه.",
  "UsingVoiceVox": "استخدام VOICEVOX",
  "VoiceVoxInfo": "نحن نستخدم VOICEVOX. تدعم اللغة اليابانية فقط. نظرًا لأننا نستخدم واجهة برمجة محلية، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "VoicevoxSpeed": "سرعة الكلام",
  "VoicevoxPitch": "طبقة الصوت",
  "VoicevoxIntonation": "نبرة الصوت",
  "VoicevoxServerUrl": "عنوان URL لخادم VOICEVOX",
  "UsingAivisSpeech": "استخدام AivisSpeech",
  "AivisSpeechInfo": "نحن نستخدم AivisSpeech. تدعم اللغة اليابانية فقط. نظرًا لأننا نستخدم واجهة برمجة محلية، تحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه.",
  "AivisSpeechSpeaker": "المتحدث",
  "AivisSpeechSpeed": "سرعة الكلام",
  "AivisSpeechPitch": "طبقة الصوت",
  "AivisSpeechIntonation": "نبرة الصوت",
  "AivisSpeechServerUrl": "عنوان URL لخادم AivisSpeech",
  "UsingNijiVoice": "استخدام NijiVoice",
  "NijiVoiceInfo": "نحن نستخدم واجهة برمجة NijiVoice. تدعم اللغة اليابانية فقط. يرجى الحصول على مفتاح واجهة البرمجة من URL أدناه.",
  "NijiVoiceApiKey": "مفتاح واجهة برمجة NijiVoice",
  "NijiVoiceActorId": "معرف المتحدث",
  "NijiVoiceSpeed": "سرعة الكلام",
  "NijiVoiceEmotionalLevel": "مستوى العاطفة",
  "NijiVoiceSoundDuration": "مدة الصوت",
  "UpdateSpeakerList": "تحديث قائمة المتحدثين",
  "UsingGoogleTTS": "استخدام Google Text-to-Speech",
  "UsingStyleBertVITS2": "استخدام Style-Bert-VITS2",
  "StyleBertVITS2Info": "نحن نستخدم Style-Bert-VITS2. يدعم اليابانية والإنجليزية والصينية فقط. إذا كنت تستخدم واجهة برمجة محلية، فستحتاج إلى تنزيل وتشغيل التطبيق المناسب لبيئتك من الموقع أدناه. قم أيضًا بتكوين مفتاح واجهة البرمجة إذا لزم الأمر.",
  "SpeakerSelection": "اختيار نوع الصوت",
  "EnglishToJapanese": "نطق الكلمات الإنجليزية باليابانية",
  "IncludeTimestampInUserMessage": "تضمين الطابع الزمني في رسالة المستخدم",
  "IncludeTimestampInUserMessageInfo": "بتضمين الطابع الزمني في رسالة المستخدم، يمكن للذكاء الاصطناعي إنشاء استجابات تأخذ الوقت بعين الاعتبار.\nيرجى تضمين الجملة التالية في موجه النظام الخاص بك:\n\n\"قد يتم تقديم إدخال المستخدم مع [timestamp]. هذا يمثل الوقت بتوقيت UTC في وقت الطلب، لذا يرجى إنشاء إجابتك مع مراعاة هذا الوقت.\"",
  "GoogleTTSInfo": "نحن نستخدم Google Cloud Text-to-Speech. يدعم لغات متعددة.",
  "AuthFileInstruction": "تحتاج إلى مفتاح واجهة برمجة أو ملف JSON للمصادقة. الحصول عليه من أدناه، وإذا كان ملف JSON، فضعه في المجلد الجذر للمستودع باسم credentials.json.",
  "LanguageModelURL": "يرجى اختيار نموذج اللغة من URL أدناه.",
  "LanguageChoice": "اختيار اللغة",
  "StyleBeatVITS2ServerURL": "عنوان URL للخادم",
  "StyleBeatVITS2ApiKey": "مفتاح واجهة البرمجة",
  "StyleBeatVITS2ModelID": "معرف النموذج",
  "StyleBeatVITS2Style": "الأسلوب",
  "StyleBeatVITS2SdpRatio": "نسبة خلط SDP/DP",
  "StyleBeatVITS2Length": "سرعة الكلام",
  "ConversationHistory": "سجل المحادثة",
  "ConversationHistoryInfo": "سيتم الاحتفاظ بآخر {{count}} محادثة كذاكرة.",
  "ConversationHistoryReset": "إعادة تعيين سجل المحادثة",
  "NotConnectedToExternalAssistant": "غير متصل بمساعد خارجي.",
  "APIKeyNotEntered": "لم يتم إدخال مفتاح واجهة البرمجة.",
  "ChatLog": "سجل الدردشة",
  "EnterYourQuestion": "أدخل سؤالك هنا",
  "AnswerGenerating": "جاري إنشاء الإجابة",
  "AboutThisApplication": "حول هذا التطبيق",
  "AboutThisApplicationDescription": "يمكنك الاستمتاع بالمحادثة مع شخصية ثلاثية الأبعاد باستخدام الميكروفون أو إدخال النص أو توليف الصوت في متصفح الويب فقط. يمكنك أيضًا تغيير الشخصية (VRM) وإعدادات الشخصية وضبط الصوت.<br />يمكنك تغيير الإعدادات من زر القائمة في الزاوية العلوية اليسرى.",
  "AboutThisApplicationDescription2": "مع AITuberKit، يمكنك الاستمتاع بالمحادثة مع شخصية الذكاء الاصطناعي في متصفح الويب فقط. يرجى الرجوع إلى كل عنصر إعداد لتغيير الشخصية وإعدادات الشخصية وضبط الصوت.",
  "TechnologyIntroduction": "مقدمة تقنية",
  "TechnologyIntroductionDescription1": "تم إنشاء هذا التطبيق عن طريق تعديل <b>ChatVRM</b> من شركة pixiv. يمكنك العثور على الكود المصدري الأصلي",
  "TechnologyIntroductionLink1": "هنا",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "نحن نستخدم",
  "TechnologyIntroductionDescription4": " لعرض ومعالجة النماذج ثلاثية الأبعاد، و",
  "TechnologyIntroductionDescription5": " ومختلف نماذج اللغة الكبيرة لإنشاء نص المحادثة، و",
  "TechnologyIntroductionDescription6": " ومختلف تقنيات تحويل النص إلى كلام لتوليف الصوت. للحصول على مزيد من التفاصيل، يرجى الاطلاع على",
  "TechnologyIntroductionLink2": "مقالة توضيحية",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "رمز المصدر لهذا التطبيق متاح على GitHub. يمكنك تعديله وتغييره بحرية.",
  "SourceCodeDescription2": "فيما يتعلق بالاستخدام التجاري، يرجى الرجوع إلى ملف README في نفس المستودع.",
  "RepositoryURL": "عنوان URL للمستودع:",
  "DontShowIntroductionNextTime": "عدم عرض هذا الحوار في المرة القادمة",
  "Close": "إغلاق",
  "Contact": "اتصل بنا",
  "ContactDescription": "للاستفسارات حول هذا التطبيق، يرجى الاتصال بعنوان البريد الإلكتروني أو حساب تويتر أدناه.",
  "Creator": "معلومات المنشئ",
  "CreatorDescription": "المنشئ: نيكي",
  "Documentation": "التوثيق",
  "DocumentationDescription": "يمكنك العثور على دليل مفصل وبرامج تعليمية لـ AITuberKit على URL أدناه.",
  "Language": "إعدادات اللغة",
  "UsingGSVITTS": "استخدام GSVI TTS",
  "GSVITTSInfo": "إعدادات GSVI TTS",
  "GSVITTSServerUrl": "عنوان URL لخادم GSVI TTS",
  "GSVITTSModelID": "معرف نموذج GSVI TTS",
  "GSVITTSBatchSize": "حجم الدفعة GSVI TTS (1 ~ 100 كلما كانت القيمة أكبر، كان الاستدلال أسرع، ولكن إذا كانت كبيرة جدًا، فقد تنفد الذاكرة)",
  "GSVITTSSpeechRate": "معدل الكلام (0.5 ~ 2.0 كلما كانت القيمة أكبر، كان أسرع)",
  "UsingElevenLabs": "استخدام ElevenLabs",
  "ElevenLabsInfo": "نحن نستخدم واجهة برمجة ElevenLabs. يدعم لغات متعددة. يرجى الحصول على مفتاح واجهة البرمجة من URL أدناه.",
  "ElevenLabsApiKey": "مفتاح واجهة برمجة ElevenLabs",
  "ElevenLabsVoiceId": "معرف صوت ElevenLabs",
  "ElevenLabsVoiceIdInfo": "يرجى اختيار معرف الصوت من URL أدناه.",
  "CharacterName": "اسم الشخصية",
  "ShowAssistantText": "عرض مربع الإجابة",
  "ShowCharacterName": "عرض اسم الشخصية في مربع الإجابة",
  "ShowControlPanel": "عرض لوحة التحكم",
  "ShowControlPanelInfo": "يمكنك عرض شاشة الإعدادات باستخدام Cmd + . (Mac) / Ctrl + . (Windows).\nإذا كنت تستخدم هاتفًا ذكيًا، يمكنك أيضًا الضغط لفترة طويلة (حوالي ثانية واحدة) في الزاوية العلوية اليسرى من الشاشة.",
  "ShowCharacterPresetMenu": "عرض زر قائمة الإعدادات المسبقة للشخصية",
  "SlideMode": "وضع العرض التقديمي",
  "SelectedSlideDocs": "الشرائح المستخدمة",
  "SlideModeDescription": "هذا هو الوضع الذي يعرض فيه الذكاء الاصطناعي الشرائح تلقائيًا. متاح فقط عند اختيار OpenAI أو Anthropic Claude أو Google Gemini كخدمة ذكاء اصطناعي.",
  "PdfConvertLabel": "تحويل شرائح PDF",
  "PdfConvertDescription": "تحويل ملفات PDF إلى بيانات لوضع العرض التقديمي. متاح فقط عند اختيار OpenAI أو Anthropic Claude أو Google Gemini كخدمة ذكاء اصطناعي.",
  "PdfConvertFileUpload": "اختر ملف PDF",
  "PdfConvertFolderName": "اسم مجلد الحفظ",
  "CustomVoiceTextPlaceholder": "أدخل النص الذي تريد سماعه",
  "TestVoiceSettings": "اختبار الصوت",
  "TestSelectedVoice": "تشغيل",
  "PdfConvertModelSelect": "اختر النموذج",
  "PdfConvertButton": "تحويل PDF إلى شرائح",
  "PdfConvertLoading": "جاري التحويل...",
  "PdfConvertSuccess": "اكتمل التحويل",
  "PdfConvertError": "فشل التحويل",
  "PdfConvertSubmitError": "يرجى التأكد من تكوين ملف PDF واسم المجلد ومفتاح واجهة البرمجة",
  "LocalStorageReset": "إعادة تعيين الإعدادات",
  "LocalStorageResetInfo": "ستكون الأولوية للقيم المحددة في متغيرات البيئة إذا تم تعيينها. ستتم إعادة تحميل الصفحة.",
  "LocalStorageResetButton": "إعادة تعيين الإعدادات",
  "InitialSpeechTimeout": "مهلة التعرف على الكلام",
  "InitialSpeechTimeoutInfo": "يحدد هذا وقت الانتظار بعد بدء التعرف على الكلام حتى يتم اكتشاف الكلام الأول. إذا لم يتم اكتشاف الكلام خلال هذا الوقت، سيتوقف التعرف على الكلام تلقائيًا.\nإذا تم تعيينه إلى 0 ثانية، سيكون وقت الانتظار غير محدود.",
  "Milliseconds": "مللي ثانية",
  "NoSpeechTimeout": "مهلة اكتشاف الصمت",
  "NoSpeechTimeoutInfo": "يحدد هذا الوقت الذي سيتم بعده إنهاء الإدخال تلقائيًا عندما يستمر الصمت أثناء إدخال الصوت.\nإذا تم تعيينه إلى 0 ثانية، سيتم تعطيل الإرسال التلقائي بواسطة اكتشاف الصمت.",
  "ShowSilenceProgressBar": "عرض شريط تقدم اكتشاف الصمت",
  "SpeechRecognitionMode": "وضع التعرف على الكلام",
  "SpeechRecognitionModeInfo": "يمكنك اختيار وضع التعرف على الكلام.\n\"قياسي المتصفح\" يستخدم التعرف على الكلام المدمج في المتصفح. \"OpenAI TTS\" يستخدم واجهة برمجة تحويل النص إلى كلام من OpenAI.\nبشكل عام، \"قياسي المتصفح\" هو الخيار الموصى به لأنه أكثر دقة وأسرع في التعرف. ومع ذلك، إذا كنت تستخدم متصفحًا لا يدعم واجهة برمجة WebSpeech مثل Firefox، فيرجى اختيار \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "استخدام التعرف على الكلام القياسي للمتصفح",
  "WhisperSpeechRecognition": "استخدام التعرف على كلام OpenAI TTS",
  "WhisperTranscriptionModel": "نموذج النسخ",
  "WhisperTranscriptionModelInfo": "يمكنك اختيار النموذج المستخدم للتعرف على الكلام. النماذج الأكثر تقدمًا تقدم تعرفًا أكثر دقة ولكن قد تكون أعلى تكلفة من حيث واجهة البرمجة.",
  "SpeechRecognitionModeDisabledInfo": "عندما يكون وضع الصوت نشطًا، يكون التعرف على كلام المتصفح فقط متاحًا.\nأيضًا، في وضع واجهة برمجة التطبيقات في الوقت الفعلي، يكون التعرف على كلام المتصفح فقط متاحًا وتكون ميزة مهلة التعرف على الكلام معطلة.",
  "Errors": {
    "EmptyAPIKey": "لم يتم تعيين مفتاح واجهة البرمجة",
    "EmptyLocalLLMURL": "لم يتم تعيين URL لنموذج اللغة المحلي",
    "AIInvalidProperty": "قيمة إعداد خدمة الذكاء الاصطناعي غير صحيحة",
    "AIAPIError": "حدث خطأ أثناء تنفيذ واجهة برمجة الذكاء الاصطناعي",
    "InvalidAIService": "خدمة الذكاء الاصطناعي المحددة غير صحيحة",
    "MethodNotAllowed": "الطلب غير مناسب",
    "TTSServiceError": "حدث خطأ في خدمة {{serviceName}} TTS: {{message}}",
    "UnexpectedError": "حدث خطأ غير متوقع",
    "LocalLLMError": "حدث خطأ في نموذج اللغة المحلي",
    "LocalLLMStreamError": "حدث خطأ في معالجة تدفق نموذج اللغة المحلي",
    "LocalLLMConnectionError": "لا يمكن الاتصال بخادم نموذج اللغة المحلي",
    "LocalLLMNotFound": "لم يتم العثور على نقطة نهاية نموذج اللغة المحلي",
    "LocalLLMAPIError": "حدث خطأ في واجهة برمجة نموذج اللغة المحلي",
    "CustomAPIError": "حدث خطأ في واجهة البرمجة المخصصة",
    "InvalidJSON": "تنسيق JSON غير صحيح"
  },
  "MessageReceiver": "قبول التعليمات من الخارج",
  "MessageReceiverDescription": "يمكنك توجيه تعليق شخصية الذكاء الاصطناعي من الخارج باستخدام واجهة البرمجة.",
  "ClientID": "معرف العميل",
  "OpenSendMessagePage": "فتح صفحة إرسال الرسائل",
  "RealtimeAPIMode": "وضع واجهة البرمجة في الوقت الفعلي",
  "RealtimeAPIModeContentType": "نوع الإرسال",
  "RealtimeAPIModeVoice": "نوع الصوت",
  "AudioMode": "وضع الصوت",
  "InputText": "نص",
  "InputAudio": "صوت",
  "SearchGrounding": "استخدام ميزة البحث",
  "SearchGroundingDescription": "عند استخدام ميزة متعددة الوسائط، سيتم تعطيل ميزة البحث تلقائيًا.",
  "UpdateRealtimeAPISettings": "تحديث إعدادات واجهة البرمجة في الوقت الفعلي",
  "UpdateRealtimeAPISettingsInfo": "عند تحديث مفتاح واجهة البرمجة أو نقطة نهاية Azure أو نوع الصوت أو النموذج أو موجه النظام، يرجى الضغط على زر التحديث لبدء جلسة WebSocket جديدة.",
  "AzureEndpoint": "نقطة نهاية Azure",
  "Toasts": {
    "WebSocketConnectionError": "حدث خطأ في اتصال WebSocket",
    "WebSocketConnectionClosed": "تم إغلاق اتصال WebSocket",
    "WebSocketConnectionAttempt": "جارٍ محاولة الاتصال بـ WebSocket...",
    "WebSocketConnectionSuccess": "تم الاتصال بـ WebSocket بنجاح",
    "FunctionExecuting": "يتم تنفيذ {{funcName}}",
    "FunctionExecutionFailed": "فشل تنفيذ {{funcName}}",
    "FirefoxNotSupported": "لا يدعم Firefox هذه الميزة",
    "SpeechRecognitionError": "حدث خطأ في التعرف على الصوت",
    "NoSpeechDetected": "لم يتم اكتشاف صوت.",
    "PresetSwitching": "تم التبديل إلى {{presetName}}.",
    "WhisperError": "حدث خطأ في التعرف على الصوت بواسطة Whisper",
    "UsingTool": "أثناء استخدام {{toolName}}"
  },
  "ContinuousMic": "إدخال الميكروفون المستمر",
  "ContinuousMicActive": "إدخال الميكروفون المستمر نشط",
  "ContinuousMicModeOn": "وضع إدخال الميكروفون المستمر قيد التشغيل",
  "ContinuousMicModeOff": "وضع إدخال الميكروفون المستمر متوقف",
  "ListeningContinuously": "في انتظار إدخال الصوت...",
  "ContinuousMicInfo": "سيتم إعادة تشغيل إدخال الميكروفون تلقائيًا بعد انتهاء الذكاء الاصطناعي من التحدث. سيتم إرسال الإدخال تلقائيًا بعد انقضاء وقت الصمت المحدد.\nإذا تجاوز الوقت المحدد دون التعرف على الكلام، سيتم إيقاف إدخال الميكروفون المستمر تلقائيًا. إذا كنت تريد إبقاءه قيد التشغيل دائمًا، فيرجى تعيين مهلة التعرف على الكلام إلى 0 ثانية.",
  "UsingOpenAITTS": "استخدام OpenAI",
  "OpenAITTSInfo": "نحن نستخدم OpenAI. يدعم لغات متعددة. إذا كنت قد اخترت OpenAI كخدمة ذكاء اصطناعي، فلا داعي لتعيين مفتاح واجهة البرمجة أدناه.",
  "OpenAITTSVoice": "نوع الصوت",
  "OpenAITTSModel": "النموذج",
  "OpenAITTSSpeed": "سرعة الكلام",
  "UsingAzureTTS": "استخدام Azure OpenAI",
  "AzureTTSInfo": "نحن نستخدم Azure OpenAI. يدعم لغات متعددة.",
  "SendMessage": {
    "title": "محول خارجي لـ AITuberKit",
    "directSendTitle": "جعل شخصية الذكاء الاصطناعي تتحدث مباشرة",
    "directSendDescription": "يمكنك جعل شخصية الذكاء الاصطناعي تتحدث بالرسالة التي أرسلتها مباشرة. إذا أرسلت عدة رسائل، فستتم معالجتها بالترتيب.\nسيتم استخدام نموذج الصوت المحدد في إعدادات AITuberKit.",
    "aiGenerateTitle": "توليد إجابة بالذكاء الاصطناعي ثم نطقها",
    "aiGenerateDescription": "سيقوم الذكاء الاصطناعي بتوليد إجابة من الرسالة التي أرسلتها، ثم جعل شخصية الذكاء الاصطناعي تنطق بتلك الإجابة. إذا أرسلت عدة رسائل، فستتم معالجتها بالترتيب.\nسيتم استخدام نموذج الذكاء الاصطناعي ونموذج الصوت المحددين في إعدادات AITuberKit.\nيمكنك اختيار استخدام موجه النظام من AITuberKit أو موجه نظام مخصص.\nإذا كنت ترغب في تحميل سجل المحادثة السابق، يرجى تضمين السلسلة [conversation_history] في أي مكان في موجه النظام أو رسالة المستخدم.",
    "useCurrentSystemPrompt": "استخدام موجه النظام من AITuberKit",
    "userInputTitle": "إرسال إدخال المستخدم",
    "userInputDescription": "ستتم معالجة الرسالة التي أرسلتها بنفس طريقة معالجة الإدخال من نموذج الإدخال في AITuberKit. إذا أرسلت عدة رسائل، فستتم معالجتها بالترتيب.\nسيتم استخدام نموذج الذكاء الاصطناعي ونموذج الصوت المحددين في إعدادات AITuberKit.\nسيتم استخدام موجه النظام وسجل المحادثة من AITuberKit."
  },
  "CannotUseVoice": "عند تنشيط وضع واجهة البرمجة في الوقت الفعلي أو وضع الصوت،\nلا حاجة لإعدادات الصوت الاصطناعي.",
  "Live2D": {
    "FileInfo": "يرجى وضع مجلد نموذج Live2D الذي ترغب في استخدامه في public/live2d. يجب أن يكون ملف model3.json موجودًا مباشرة داخل هذا المجلد.\nإذا لم يظهر في القائمة، يرجى إعادة تحميل الصفحة أو التحقق من صحة مسار المجلد.",
    "Info": "يمكنك تحديد المشاعر والحركات.\nتتم إدارة كل مشاعر من خلال الموجه. لمزيد من التفاصيل، يرجى الاطلاع على \"إعدادات الذكاء الاصطناعي => إعدادات الشخصية\".",
    "Emotions": "إعدادات التعبير",
    "EmotionInfo": "يمكن تحديد المشاعر مفصولة بفواصل. إذا تم تحديد عدة مشاعر، سيتم اختيار واحدة عشوائيًا.\nالقيم الافتراضية متوافقة مع النماذج المتوفرة في AITuberKit. إذا كنت تستخدم نموذجًا أصليًا، يرجى إدخال القيم المناسبة لنموذجك.\nبعد اكتمال المحادثة، سيتم عرض تعبير \"عادي\".",
    "neutralEmotions": "عادي",
    "happyEmotions": "سعيد",
    "sadEmotions": "حزين",
    "angryEmotions": "غاضب",
    "relaxedEmotions": "مسترخي",
    "surprisedEmotions": "متفاجئ",
    "MotionGroups": "إعدادات مجموعة الحركة",
    "MotionGroupsInfo": "سيتم اختيار حركة عشوائية من مجموعة الحركة المحددة.\nكما هو الحال مع إعدادات التعبير، يرجى تكوينها وفقًا لنموذجك.\n\"وضع الخمول\" هو الحركة التي تظهر بعد اكتمال المحادثة.",
    "SelectMotionGroup": "اختر مجموعة الحركة",
    "idleMotionGroup": "وضع الخمول",
    "neutralMotionGroup": "عادي",
    "happyMotionGroup": "سعيد",
    "sadMotionGroup": "حزين",
    "angryMotionGroup": "غاضب",
    "relaxedMotionGroup": "مسترخي",
    "surprisedMotionGroup": "متفاجئ"
  },
  "UseVideoAsBackground": "استخدم شاشة مشتركة أو كاميرا الويب كخلفية",
  "Temperature": "درجة الحرارة",
  "MaxTokens": "الحد الأقصى للرموز",
  "MaxTokensInfo": "يختلف الحد الأقصى للرموز حسب نموذج الذكاء الاصطناعي المستخدم. يرجى التحقق من مواصفات كل نموذج.",
  "CannotUseParameters": "عند تنشيط وضع واجهة البرمجة في الوقت الفعلي أو وضع الصوت، لا يمكن تحديد معلمات درجة الحرارة والحد الأقصى للرموز.",
  "PresetQuestions": "أسئلة معدة مسبقًا",
  "PresetQuestionsInfo": "يمكنك إنشاء وتسجيل أنماط أسئلة متعددة مسبقًا. ستظهر الأسئلة المسجلة كأزرار في واجهة المستخدم، وعند النقر عليها ستوضع في مربع إدخال الدردشة.",
  "EnterPresetQuestion": "أدخل سؤالاً",
  "DragToReorder": "اسحب لإعادة الترتيب",
  "CustomAPIEndpoint": "نقطة نهاية واجهة البرمجة المخصصة",
  "CustomAPIEndpointInfo": "أدخل عنوان URL لنقطة نهاية واجهة البرمجة التي سيتم إرسال طلبات POST إليها.",
  "CustomAPIStream": "وضع التدفق",
  "CustomAPIStreamForced": "حاليًا، وضع التدفق مفعل دائمًا.",
  "IncludeSystemMessages": "تضمين الرسائل النظامية",
  "CustomAPIHeaders": "رؤوس مخصصة",
  "CustomAPIHeadersInfo": "أدخل معلومات الرؤوس التي سيتم تضمينها في طلب واجهة البرمجة بتنسيق JSON.",
  "CustomAPIBody": "هيكل مخصص",
  "CustomAPIBodyInfo": "أدخل معلومات الهيكل التي سيتم تضمينها في طلب واجهة البرمجة بتنسيق JSON. سيتم تضمين الرسائل تلقائيًا.",
  "CustomAPIDescription": "ملاحظة: سيتم تضمين الرسائل تلقائيًا في جسم الطلب. في وضع التدفق، يجب أن يعيد الخادم text/event-stream.",
  "EditSlideScripts": "تحرير الحوار",
  "PleaseSelectSlide": "يرجى اختيار الشريحة"
}
