{
  "Description": "O aplikacji",
  "BasedSettings": "Ustawienia podstawowe",
  "AISettings": "Ustawienia AI",
  "CharacterSettings": "Ustawienia postaci",
  "YoutubeSettings": "Ustawienia YouTube",
  "VoiceSettings": "Ustawienia syntezy głosu",
  "SpeechInputSettings": "Ustawienia wejścia głosowego",
  "SlideSettings": "Ustawienia slajdów",
  "LogSettings": "Historia rozmów",
  "OtherSettings": "Inne",
  "ExternalLinkageMode": "Tryb połączenia zewnętrznego (wersja beta)",
  "YoutubeMode": "Tryb YouTube",
  "YoutubeInfo": "Komentarze zaczynające się od \"#\" są ignorowane.",
  "YoutubeAPIKey": "Klucz API YouTube",
  "YoutubeLiveID": "ID transmisji YouTube Live",
  "ConversationContinuityMode": "Tryb ciągłości rozmowy (wersja beta)",
  "ConversationContinuityModeInfo": "Tryb, w którym AI samodzielnie kontynuuje rozmowę, gdy brak jest komentarzy. Działa tylko wtedy, gdy wybrany jest model obsługujący multimodalność.",
  "ConversationContinuityModeInfo2": "Ponieważ LLM jest wywoływany wielokrotnie w jednej odpowiedzi, koszty API mogą wzrosnąć. Proszę o ostrożność.",
  "ConversationContinuityModeInfo3": "W zależności od wybranego modelu, może nie działać stabilnie.",
  "MaxPastMessages": "Liczba przechowywanych poprzednich wiadomości",
  "StatusOn": "Stan: WŁĄCZONY",
  "StatusOff": "Stan: WYŁĄCZONY",
  "Select": "Wybierz",
  "TestVoice": "Testuj głos",
  "SelectAIService": "Wybierz usługę AI",
  "LocalLLM": "Lokalny LLM",
  "SelectModel": "Wybierz model",
  "OpenAIAPIKeyLabel": "Klucz API OpenAI",
  "AnthropicAPIKeyLabel": "Klucz API Anthropic",
  "GoogleAPIKeyLabel": "Klucz API Google Gemini",
  "AzureAPIKeyLabel": "Klucz API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "GroqAPIKeyLabel": "Klucz API Groq",
  "CohereAPIKeyLabel": "Klucz API Cohere",
  "MistralAIAPIKeyLabel": "Klucz API MistralAI",
  "PerplexityAPIKeyLabel": "Klucz API Perplexity",
  "FireworksAPIKeyLabel": "Klucz API Fireworks",
  "DifyAPIKeyLabel": "Klucz API Dify",
  "DeepSeekAPIKeyLabel": "Klucz API DeepSeek",
  "APIKeyInstruction": "Klucze API można uzyskać z poniższego linku. Proszę wprowadzić uzyskany klucz API w formularzu.",
  "LocalLLMInfo": "Wymagane jest uruchomienie serwera lokalnego LLM.",
  "LocalLLMInfo2": "Wprowadź URL lokalnego LLM (włącznie z numerem portu) i nazwę modelu.",
  "GroqInfo": "API Groq jest dostępne bezpośrednio z przeglądarki.",
  "DifyInfo": "W Dify obsługiwane są tylko chatboty lub typy agentów. Jeśli nie uzyskasz poprawnej odpowiedzi, usuń historię rozmów i spróbuj ponownie zadać pytanie.",
  "DifyInfo2": "Długość historii rozmowy zależy od ustawień chatbota Dify.",
  "DifyInfo3": "Przykład: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Gdy używasz Dify, ten prompt systemowy nie jest używany. Ustaw go w chatbocie Dify.",
  "EnterURL": "Wprowadź URL",
  "CharacterModelLabel": "Model postaci",
  "CharacterModelInfo": "W zależności od modelu, początkowe ładowanie może potrwać dłużej.",
  "OpenVRM": "Otwórz VRM",
  "BackgroundImage": "Obraz tła",
  "ChangeBackgroundImage": "Zmień obraz tła",
  "BackgroundSettings": "Ustawienia tła",
  "BackgroundSettingsDescription": "Możesz przesłać i wybrać obraz tła dla aplikacji.",
  "UploadBackground": "Prześlij obraz tła",
  "DefaultBackground": "Domyślne tło",
  "CharacterSettingsPrompt": "Prompt postaci",
  "CharacterSettingsInfo": "Ta wartość jest ustawiana jako prompt systemowy.\nKorzystając z początkowego promptu, możesz kontrolować wyrażenia i ruchy postaci, określając tagi emocji. Przykład: [neutral]Dzień dobry![happy]Dobrej pracy na dziś!",
  "CharacterpresetInfo": "Wybór presetu zmieni prompt postaci.\nMożna używać skrótów Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Wybór silnika syntezy głosu",
  "VoiceAdjustment": "Regulacja głosu",
  "VoiceEngineInstruction": "Wybierz silnik syntezy głosu do użycia.",
  "UsingKoeiromap": "Użyj Koeiromap",
  "KoeiromapInfo": "Używamy API Koeiromap Koemotion. Obsługuje tylko język japoński. Więcej informacji poniżej.",
  "UsingVoiceVox": "Użyj VOICEVOX",
  "VoiceVoxInfo": "Używamy VOICEVOX. Obsługuje tylko język japoński. Ponieważ używa lokalnego API, musisz pobrać i uruchomić aplikację odpowiednią dla swojego środowiska z poniższej strony.",
  "VoicevoxSpeed": "Prędkość mowy",
  "VoicevoxPitch": "Wysokość głosu",
  "VoicevoxIntonation": "Intonacja",
  "VoicevoxServerUrl": "URL serwera VOICEVOX",
  "UsingAivisSpeech": "Użyj AivisSpeech",
  "AivisSpeechInfo": "Używamy AivisSpeech. Obsługuje tylko język japoński. Ponieważ używa lokalnego API, musisz pobrać i uruchomić aplikację odpowiednią dla swojego środowiska z poniższej strony.",
  "AivisSpeechSpeaker": "Głos",
  "AivisSpeechSpeed": "Prędkość mowy",
  "AivisSpeechPitch": "Wysokość głosu",
  "AivisSpeechIntonation": "Intonacja",
  "AivisSpeechServerUrl": "URL serwera AivisSpeech",
  "UsingNijiVoice": "Użyj NijiVoice",
  "NijiVoiceInfo": "Używamy API NijiVoice. Obsługuje tylko język japoński. Uzyskaj klucz API z poniższego URL.",
  "NijiVoiceApiKey": "Klucz API NijiVoice",
  "NijiVoiceActorId": "ID głosu",
  "NijiVoiceSpeed": "Prędkość mowy",
  "NijiVoiceEmotionalLevel": "Poziom emocji",
  "NijiVoiceSoundDuration": "Długość dźwięku",
  "UpdateSpeakerList": "Aktualizuj listę głosów",
  "UsingGoogleTTS": "Użyj Google Text-to-Speech",
  "UsingStyleBertVITS2": "Użyj Style-Bert-VITS2",
  "StyleBertVITS2Info": "Używamy Style-Bert-VITS2. Obsługuje tylko języki japoński, angielski i chiński. Jeśli używasz lokalnego API, musisz pobrać i uruchomić aplikację odpowiednią dla swojego środowiska z poniższej strony. W razie potrzeby ustaw także klucz API.",
  "SpeakerSelection": "Wybór typu głosu",
  "EnglishToJapanese": "Czytaj angielskie słowa po japońsku",
  "IncludeTimestampInUserMessage": "Dołącz znacznik czasu do wypowiedzi użytkownika",
  "IncludeTimestampInUserMessageInfo": "Dołączenie znacznika czasu do wypowiedzi użytkownika pozwala AI generować odpowiedzi z uwzględnieniem czasu.\nDodaj następujący tekst do promptu systemowego:\n\n\"Jeśli dane wejściowe użytkownika zawierają [timestamp], reprezentuje to czas w strefie czasowej UTC w momencie żądania, więc proszę wygenerować odpowiedź z uwzględnieniem tego czasu.\"",
  "GoogleTTSInfo": "Używamy Google Cloud Text-to-Speech. Obsługuje wiele języków.",
  "AuthFileInstruction": "Wymagany jest klucz API lub plik JSON do uwierzytelniania. Uzyskaj go z poniższej strony i umieść plik JSON jako credentials.json w głównym folderze repozytorium.",
  "LanguageModelURL": "Wybierz model języka z poniższego URL.",
  "LanguageChoice": "Wybór języka",
  "StyleBeatVITS2ServerURL": "URL serwera",
  "StyleBeatVITS2ApiKey": "Klucz API",
  "StyleBeatVITS2ModelID": "ID modelu",
  "StyleBeatVITS2Style": "Styl",
  "StyleBeatVITS2SdpRatio": "Stosunek mieszania SDP/DP",
  "StyleBeatVITS2Length": "Prędkość mowy",
  "ConversationHistory": "Historia rozmowy",
  "ConversationHistoryInfo": "Ostatnie {{count}} wiadomości rozmowy są przechowywane jako pamięć.",
  "ConversationHistoryReset": "Resetuj historię rozmowy",
  "NotConnectedToExternalAssistant": "Nie połączono z zewnętrznym asystentem.",
  "APIKeyNotEntered": "Nie wprowadzono klucza API.",
  "ChatLog": "Dziennik rozmów",
  "EnterYourQuestion": "Wpisz, o co chcesz zapytać",
  "AnswerGenerating": "Generowanie odpowiedzi",
  "AboutThisApplication": "O tej aplikacji",
  "AboutThisApplicationDescription": "Możesz cieszyć się rozmową z postacią 3D tylko za pomocą przeglądarki internetowej, wykorzystując mikrofon, wprowadzanie tekstu i syntezę głosu. Możesz również zmienić postać (VRM), ustawienia osobowości i dostosować głos.<br />Ustawienia można zmienić za pomocą przycisku menu w lewym górnym rogu.",
  "AboutThisApplicationDescription2": "W AITuberKit możesz cieszyć się rozmową z postacią AI tylko za pomocą przeglądarki internetowej. Sprawdź poszczególne ustawienia, aby zmienić postać, ustawienia osobowości i dostosować głos.",
  "TechnologyIntroduction": "Wprowadzenie technologii",
  "TechnologyIntroductionDescription1": "Ta aplikacja została stworzona poprzez modyfikację <b>ChatVRM</b> firmy pixiv. Oryginalny kod źródłowy można znaleźć",
  "TechnologyIntroductionLink1": "tutaj",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Do wyświetlania i obsługi modeli 3D używamy",
  "TechnologyIntroductionDescription4": ", do generowania rozmów używamy",
  "TechnologyIntroductionDescription5": "i innych LLM, a do syntezy głosu używamy",
  "TechnologyIntroductionDescription6": "i innych TTS. Szczegółowe informacje można znaleźć w",
  "TechnologyIntroductionLink2": "artykule wyjaśniającym",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "Kod źródłowy tej aplikacji jest publikowany na GitHubie. Możesz swobodnie go modyfikować i zmieniać.",
  "SourceCodeDescription2": "Informacje na temat użytku komercyjnego znajdują się w README w tym repozytorium.",
  "RepositoryURL": "URL repozytorium:",
  "DontShowIntroductionNextTime": "Nie pokazuj tego dialogu następnym razem",
  "Close": "Zamknij",
  "Contact": "Kontakt",
  "ContactDescription": "W przypadku pytań dotyczących tej aplikacji, skontaktuj się za pomocą poniższego adresu e-mail lub konta Twitter.",
  "Creator": "Informacje o twórcy",
  "CreatorDescription": "Twórca: Nike",
  "Documentation": "Dokumentacja",
  "DocumentationDescription": "Szczegółowe instrukcje i tutoriale dotyczące AITuberKit można znaleźć pod poniższym URL.",
  "Language": "Ustawienia języka",
  "UsingGSVITTS": "Użyj GSVI TTS",
  "GSVITTSInfo": "Ustawienia GSVI TTS",
  "GSVITTSServerUrl": "URL serwera GSVI TTS",
  "GSVITTSModelID": "ID modelu GSVI TTS",
  "GSVITTSBatchSize": "Rozmiar partii GSVI TTS (1 ~ 100, większa wartość przyspiesza wnioskowanie, ale zbyt duża może wyczerpać pamięć)",
  "GSVITTSSpeechRate": "Prędkość mowy (0.5 ~ 2.0, większa wartość oznacza szybciej)",
  "UsingElevenLabs": "Użyj ElevenLabs",
  "ElevenLabsInfo": "Używamy API ElevenLabs. Obsługuje wiele języków. Uzyskaj klucz API z poniższego URL.",
  "ElevenLabsApiKey": "Klucz API ElevenLabs",
  "ElevenLabsVoiceId": "ID głosu ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Wybierz ID głosu z poniższego URL.",
  "CharacterName": "Nazwa postaci",
  "ShowAssistantText": "Pokaż pole odpowiedzi",
  "ShowCharacterName": "Pokaż nazwę postaci w polu odpowiedzi",
  "ShowControlPanel": "Pokaż panel sterowania",
  "ShowControlPanelInfo": "Ekran ustawień można wyświetlić za pomocą Cmd + . (Mac) / Ctrl + . (Windows).\nJeśli korzystasz ze smartfona, możesz także przytrzymać lewy górny róg ekranu (przez około 1 sekundę).",
  "ShowCharacterPresetMenu": "Pokaż przycisk menu presetów postaci",
  "SlideMode": "Tryb slajdów",
  "SelectedSlideDocs": "Używane slajdy",
  "SlideModeDescription": "Tryb automatycznej prezentacji slajdów przez AI. Dostępny tylko wtedy, gdy wybrany jest model obsługujący multimodalność.",
  "PdfConvertLabel": "Konwersja slajdów PDF",
  "PdfConvertDescription": "Konwertuje plik PDF na dane do trybu slajdów. Dostępne tylko wtedy, gdy wybrano model obsługujący multimodalność.",
  "PdfConvertFileUpload": "Wybierz plik PDF",
  "PdfConvertFolderName": "Nazwa folderu zapisu",
  "CustomVoiceTextPlaceholder": "Wprowadź tekst do przetestowania",
  "TestVoiceSettings": "Test głosu",
  "TestSelectedVoice": "Odtwórz",
  "PdfConvertModelSelect": "Wybierz model",
  "PdfConvertButton": "Konwertuj PDF na slajdy",
  "PdfConvertLoading": "Konwersja...",
  "PdfConvertSuccess": "Konwersja zakończona",
  "PdfConvertError": "Konwersja nie powiodła się",
  "PdfConvertSubmitError": "Sprawdź, czy plik PDF, nazwa folderu i klucz API są ustawione",
  "LocalStorageReset": "Resetuj ustawienia",
  "LocalStorageResetInfo": "Jeśli ustawione są zmienne środowiskowe, ich wartości mają pierwszeństwo. Strona zostanie ponownie załadowana.",
  "LocalStorageResetButton": "Resetuj ustawienia",
  "InitialSpeechTimeout": "Limit czasu rozpoznawania mowy",
  "InitialSpeechTimeoutInfo": "Ustaw czas oczekiwania na wykrycie pierwszej wypowiedzi po rozpoczęciu rozpoznawania głosu. Jeśli w tym czasie nie zostanie wykryta żadna wypowiedź, rozpoznawanie głosu zostanie automatycznie zatrzymane.\nUstawienie na 0 sekund oznacza nieograniczony czas oczekiwania.",
  "Milliseconds": "milisekundy",
  "NoSpeechTimeout": "Limit czasu wykrywania ciszy",
  "NoSpeechTimeoutInfo": "Ustaw czas, po którym wejście głosowe zostanie automatycznie zakończone, jeśli wystąpi cisza podczas wprowadzania głosu.\nUstawienie na 0 sekund wyłącza automatyczne wysyłanie po wykryciu ciszy.",
  "ShowSilenceProgressBar": "Pokaż pasek postępu wykrywania ciszy",
  "SpeechRecognitionMode": "Tryb rozpoznawania mowy",
  "SpeechRecognitionModeInfo": "Możesz wybrać tryb rozpoznawania mowy.\n\"Standardowy przeglądarkowy\" używa wbudowanego rozpoznawania mowy przeglądarki. \"OpenAI TTS\" używa API Text to Speech OpenAI.\nOgólnie zaleca się \"Standardowy przeglądarkowy\", ponieważ ma wyższą dokładność i szybsze rozpoznawanie. Jednak jeśli używasz przeglądarki, która nie obsługuje WebSpeech API, takiej jak Firefox, wybierz \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Użyj standardowego rozpoznawania mowy przeglądarki",
  "WhisperSpeechRecognition": "Użyj rozpoznawania mowy OpenAI TTS",
  "WhisperTranscriptionModel": "Model transkrypcji",
  "WhisperTranscriptionModelInfo": "Możesz wybrać model używany do rozpoznawania mowy. Bardziej zaawansowane modele oferują wyższą dokładność rozpoznawania, ale mogą wiązać się z wyższymi kosztami API.",
  "SpeechRecognitionModeDisabledInfo": "Gdy tryb audio jest włączony, można używać tylko rozpoznawania mowy przeglądarki.\nPonadto, w trybie API w czasie rzeczywistym można używać tylko rozpoznawania mowy przeglądarki, a funkcja limitu czasu rozpoznawania mowy jest wyłączona.",
  "Errors": {
    "EmptyAPIKey": "Klucz API nie jest ustawiony",
    "EmptyLocalLLMURL": "URL lokalnego LLM nie jest ustawiony",
    "AIInvalidProperty": "Wartość ustawienia usługi AI jest nieprawidłowa",
    "AIAPIError": "Wystąpił błąd podczas wykonywania API AI",
    "InvalidAIService": "Wybrana usługa AI jest nieprawidłowa",
    "MethodNotAllowed": "Żądanie nie jest odpowiednie",
    "TTSServiceError": "Wystąpił błąd w usłudze TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Wystąpił nieznany błąd",
    "LocalLLMError": "Wystąpił błąd w lokalnym LLM",
    "LocalLLMStreamError": "Wystąpił błąd w przetwarzaniu strumienia lokalnego LLM",
    "LocalLLMConnectionError": "Nie można połączyć się z serwerem lokalnego LLM",
    "LocalLLMNotFound": "Nie znaleziono punktu końcowego lokalnego LLM",
    "LocalLLMAPIError": "Wystąpił błąd w API lokalnego LLM",
    "CustomAPIError": "Wystąpił błąd w niestandardowym API",
    "InvalidJSON": "Format JSON jest nieprawidłowy"
  },
  "MessageReceiver": "Przyjmuj instrukcje z zewnątrz",
  "MessageReceiverDescription": "Możesz instruować postać AI z zewnątrz za pomocą API.",
  "ClientID": "ID klienta",
  "OpenSendMessagePage": "Otwórz stronę wysyłania wiadomości",
  "RealtimeAPIMode": "Tryb API w czasie rzeczywistym",
  "RealtimeAPIModeContentType": "Typ transmisji",
  "RealtimeAPIModeVoice": "Typ głosu",
  "AudioMode": "Tryb audio",
  "InputText": "Tekst",
  "InputAudio": "Głos",
  "SearchGrounding": "Użyj funkcji wyszukiwania",
  "SearchGroundingDescription": "Funkcja wyszukiwania jest automatycznie wyłączana podczas korzystania z funkcji multimodalnych.",
  "UpdateRealtimeAPISettings": "Aktualizuj ustawienia API w czasie rzeczywistym",
  "UpdateRealtimeAPISettingsInfo": "Po aktualizacji klucza API, endpointu Azure, typu głosu, modelu lub promptu systemowego, naciśnij przycisk aktualizacji, aby rozpocząć nową sesję WebSocket.",
  "AzureEndpoint": "Endpoint Azure",
  "Toasts": {
    "WebSocketConnectionError": "Wystąpił błąd połączenia WebSocket",
    "WebSocketConnectionClosed": "Połączenie WebSocket zostało zamknięte",
    "WebSocketConnectionAttempt": "Próba połączenia WebSocket...",
    "WebSocketConnectionSuccess": "Połączenie WebSocket zostało nawiązane pomyślnie",
    "FunctionExecuting": "Wykonywanie {{funcName}}",
    "FunctionExecutionFailed": "Nie udało się wykonać {{funcName}}",
    "FirefoxNotSupported": "Ta funkcja nie jest obsługiwana w Firefoxie",
    "SpeechRecognitionError": "Wystąpił błąd rozpoznawania mowy",
    "NoSpeechDetected": "Nie wykryto dźwięku.",
    "PresetSwitching": "Przełączono na {{presetName}}.",
    "WhisperError": "Wystąpił błąd podczas rozpoznawania mowy za pomocą Whisper",
    "UsingTool": "Używanie {{toolName}}",
    "PositionFixed": "Pozycja postaci została ustalona",
    "PositionUnfixed": "Odblokowano pozycję postaci",
    "PositionReset": "Pozycja postaci została zresetowana",
    "PositionActionFailed": "Nie udało się wykonać operacji na pozycji",
    "MicrophonePermissionDenied": "Dostęp do mikrofonu został odrzucony"
  },
  "ContinuousMic": "Ciągłe wejście mikrofonu",
  "ContinuousMicActive": "Ciągłe wejście mikrofonu aktywne",
  "ContinuousMicModeOn": "Tryb ciągłego wejścia mikrofonu włączony",
  "ContinuousMicModeOff": "Tryb ciągłego wejścia mikrofonu wyłączony",
  "ListeningContinuously": "Oczekiwanie na wejście głosowe...",
  "ContinuousMicInfo": "Automatycznie wznawia wejście mikrofonu po zakończeniu wypowiedzi AI. Automatycznie wysyła po upływie ustawionego czasu ciszy.\nJeśli rozpoznawanie mowy nie nastąpi przed upływem ustawionego czasu, ciągłe wejście mikrofonu zostanie automatycznie wyłączone. Jeśli chcesz, aby zawsze było włączone, ustaw limit czasu rozpoznawania mowy na 0 sekund.",
  "UsingOpenAITTS": "Użyj OpenAI",
  "OpenAITTSInfo": "Używamy OpenAI. Obsługuje wiele języków. Jeśli wybrano OpenAI jako usługę AI, nie musisz ustawiać poniższego klucza API.",
  "OpenAITTSVoice": "Typ głosu",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Prędkość mowy",
  "UsingAzureTTS": "Użyj Azure OpenAI",
  "AzureTTSInfo": "Używamy Azure OpenAI. Obsługuje wiele języków.",
  "SendMessage": {
    "title": "Adapter zewnętrzny AITuberKit",
    "directSendTitle": "Kazać postaci AI mówić bezpośrednio",
    "directSendDescription": "Możesz kazać postaci AI mówić dokładnie to, co wysyłasz. W przypadku wielu wiadomości będą one przetwarzane po kolei.\nUżywany jest model głosowy wybrany w ustawieniach AITuberKit.",
    "aiGenerateTitle": "Wygenerować odpowiedź przez AI, a następnie kazać postaci mówić",
    "aiGenerateDescription": "AI generuje odpowiedź na podstawie wysłanej wiadomości, a postać AI wypowiada tę odpowiedź. W przypadku wielu wiadomości będą one przetwarzane po kolei.\nModel AI i model głosowy są wybierane w ustawieniach AITuberKit.\nMożesz wybrać, czy chcesz używać promptu systemowego AITuberKit, czy niestandardowego promptu systemowego.\nAby załadować poprzednią historię rozmowy, dołącz ciąg \"[conversation_history]\" w dowolnym miejscu promptu systemowego lub wiadomości użytkownika.",
    "useCurrentSystemPrompt": "Użyj promptu systemowego AITuberKit",
    "userInputTitle": "Wysłać dane wejściowe użytkownika",
    "userInputDescription": "Wysłana wiadomość jest przetwarzana tak samo, jakby została wprowadzona z formularza wejściowego AITuberKit. W przypadku wielu wiadomości będą one przetwarzane po kolei.\nModel AI i model głosowy są wybierane w ustawieniach AITuberKit.\nUżywany jest prompt systemowy i historia rozmowy z AITuberKit."
  },
  "CannotUseVoice": "Gdy tryb API w czasie rzeczywistym lub tryb audio jest włączony,\nustawienia syntezy głosu nie są potrzebne.",
  "Live2D": {
    "FileInfo": "Umieść folder z modelem Live2D, którego chcesz użyć, w public/live2d. Plik model3.json musi istnieć bezpośrednio w tym folderze.\nJeśli nie pojawia się w opcjach, odśwież stronę lub sprawdź, czy ścieżka folderu jest poprawna.",
    "Info": "Możesz określić emocje i ruchy.\nKażda emocja jest kontrolowana przez prompt. Szczegóły znajdziesz w \"Ustawienia AI => Ustawienia postaci\".",
    "Emotions": "Ustawienia emocji",
    "EmotionInfo": "Emocje można określić oddzielając je przecinkami. W przypadku wielu określeń jedna zostanie wybrana losowo.\nWartości domyślne są przeznaczone dla modeli dostarczanych z AITuberKit. Jeśli używasz własnego modelu, wprowadź wartości odpowiednie dla swojego modelu.\nPo zakończeniu rozmowy wyświetlane jest wyrażenie \"normalne\".",
    "neutralEmotions": "Normalne",
    "happyEmotions": "Szczęśliwe",
    "sadEmotions": "Smutne",
    "angryEmotions": "Złe",
    "relaxedEmotions": "Zrelaksowane",
    "surprisedEmotions": "Zaskoczone",
    "MotionGroups": "Ustawienia grup ruchów",
    "MotionGroupsInfo": "Ruchy są losowo wybierane z wybranej grupy.\nPodobnie jak w przypadku ustawień emocji, dostosuj do własnego modelu.\n\"Bezczynność\" to ruch wyświetlany po zakończeniu rozmowy.",
    "SelectMotionGroup": "Wybierz grupę ruchów",
    "idleMotionGroup": "Bezczynność",
    "neutralMotionGroup": "Normalne",
    "happyMotionGroup": "Szczęśliwe",
    "sadMotionGroup": "Smutne",
    "angryMotionGroup": "Złe",
    "relaxedMotionGroup": "Zrelaksowane",
    "surprisedMotionGroup": "Zaskoczone"
  },
  "UseVideoAsBackground": "Użyj udostępnionego ekranu lub kamery internetowej jako tła",
  "Temperature": "Temperature",
  "MaxTokens": "Maksymalna liczba tokenów",
  "MaxTokensInfo": "Maksymalna liczba tokenów różni się w zależności od używanego modelu AI. Sprawdź specyfikację każdego modelu.",
  "CannotUseParameters": "Gdy tryb API w czasie rzeczywistym lub tryb audio jest włączony, nie można określić parametrów Temperature i Max Tokens.",
  "PresetQuestions": "Wstępnie ustawione pytania",
  "PresetQuestionsInfo": "Możesz tworzyć i rejestrować wiele wzorców pytań. Zarejestrowane pytania będą wyświetlane jako przyciski w interfejsie użytkownika, które po kliknięciu zostaną wprowadzone w polu czatu.",
  "EnterPresetQuestion": "Wprowadź pytanie",
  "DragToReorder": "Przeciągnij, aby zmienić kolejność",
  "CustomAPIEndpoint": "Niestandardowy punkt końcowy API",
  "CustomAPIEndpointInfo": "Wprowadź URL punktu końcowego API, do którego będą wysyłane żądania POST.",
  "CustomAPIStream": "Tryb strumieniowy",
  "CustomAPIStreamForced": "Tryb strumieniowy jest obecnie zawsze włączony.",
  "IncludeSystemMessages": "Uwzględnij wiadomości systemowe",
  "CustomAPIHeaders": "Niestandardowe nagłówki",
  "CustomAPIHeadersInfo": "Wprowadź informacje nagłówka, które mają być zawarte w żądaniu API, w formacie JSON.",
  "CustomAPIBody": "Niestandardowy treść",
  "CustomAPIBodyInfo": "Wprowadź informacje treści, które mają być zawarte w żądaniu API, w formacie JSON. Wiadomości są automatycznie dołączane.",
  "CustomAPIDescription": "Uwaga: Wiadomości są automatycznie dołączane do treści żądania. W trybie strumieniowym serwer musi zwracać text/event-stream.",
  "EditSlideScripts": "Edycja dialogów",
  "PleaseSelectSlide": "Wybierz slajd.",
  "XAIAPIKeyLabel": "Klucz API xAI",
  "DynamicRetrievalDescription": "Ustawia próg czasu, kiedy model wykonuje wyszukiwanie. Wartość 0 oznacza, że wyszukiwanie jest wykonywane zawsze, a 1 oznacza, że wyszukiwanie nie jest wykonywane.",
  "DynamicRetrieval": "Wyszukiwanie dynamiczne",
  "OpenRouterModelNameInstruction": "Wprowadź identyfikator modelu z OpenRouter (np. \"openai/gpt-4o\", \"mistralai/mistral-large-latest\"). Identyfikator modelu można znaleźć na stronie modelu OpenRouter.",
  "FixPosition": "Przypnij pozycję",
  "ResetPosition": "Zresetuj pozycję",
  "CharacterPosition": "Pozycja postaci",
  "DynamicRetrievalThreshold": "Dynamiczny próg",
  "CurrentStatus": "Aktualny stan",
  "PositionNotFixed": "Nieprzypięte",
  "PositionFixed": "Przytwierdzony",
  "OpenRouterAPIKeyLabel": "Klucz API OpenRouter",
  "CharacterPositionInfo": "Możesz ustawić stałą pozycję i orientację postaci. Pozycja kamery jest zapisywana dla VRM, a pozycja modelu dla Live2D.",
  "UnfixPosition": "Odblokuj przypięcie"
}
