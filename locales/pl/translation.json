{
  "Description": "O aplikacji",
  "BasedSettings": "Ustawienia podstawowe",
  "AISettings": "Ustawienia AI",
  "CharacterSettings": "Ustawienia postaci",
  "YoutubeSettings": "Ustawienia YouTube",
  "VoiceSettings": "Ustawienia syntezy głosu",
  "SpeechInputSettings": "Ustawienia wejścia głosowego",
  "SlideSettings": "Ustawienia slajdów",
  "ImageSettings": "Ustawienia obrazu",
  "LogSettings": "Historia rozmów",
  "OtherSettings": "Inne",
  "ExternalLinkageMode": "Tryb połączenia zewnętrznego (wersja beta)",
  "YoutubeMode": "Tryb YouTube",
  "YoutubeInfo": "Komentarze zaczynające się od \"#\" są ignorowane.",
  "YoutubeAPIKey": "Klucz API YouTube",
  "YoutubeLiveID": "ID transmisji YouTube Live",
  "YoutubeCommentSource": "Źródło komentarzy",
  "YoutubeCommentSourceAPI": "YouTube API",
  "YoutubeCommentSourceOneComme": "OneComme",
  "OneCommeInfo": "Pobiera komentarze za pomocą OneComme. OneComme musi być uruchomiony.\nMożna agregować komentarze z wielu platform streamingowych (YouTube, Twitch itp.) za pośrednictwem OneComme.\nKomentarze zaczynające się od '#' są ignorowane.",
  "OneCommePort": "Numer portu OneComme",
  "OneCommeConnected": "Połączono z OneComme",
  "OneCommeDisconnected": "Nie połączono z OneComme",
  "OneCommeConnecting": "Łączenie z OneComme...",
  "OneCommeConnectionError": "Nie udało się połączyć z OneComme. Sprawdź, czy OneComme jest uruchomiony.",
  "YoutubeCommentInterval": "Interwał pobierania komentarzy (sekundy)",
  "ConversationContinuityMode": "Tryb ciągłości rozmowy (wersja beta)",
  "ConversationContinuityModeInfo": "Tryb, w którym AI samodzielnie kontynuuje rozmowę, gdy brak jest komentarzy. Działa tylko wtedy, gdy wybrany jest model obsługujący multimodalność.",
  "ConversationContinuityModeInfo2": "Ponieważ LLM jest wywoływany wielokrotnie w jednej odpowiedzi, koszty API mogą wzrosnąć. Proszę o ostrożność.",
  "ConversationContinuityModeInfo3": "W zależności od wybranego modelu, może nie działać stabilnie.",
  "ConversationContinuityNewTopicThreshold": "Liczba rund przed wygenerowaniem nowego tematu",
  "ConversationContinuityNewTopicThresholdInfo": "Gdy brak komentarzy przez tę liczbę rund, AI wygeneruje nowy temat.",
  "ConversationContinuitySleepThreshold": "Liczba rund przed trybem uśpienia",
  "ConversationContinuitySleepThresholdInfo": "Gdy brak komentarzy przez tę liczbę rund, AI przejdzie w tryb uśpienia.",
  "ConversationContinuityAdvancedPrompts": "Zaawansowane ustawienia promptów",
  "ConversationContinuityAdvancedPromptsInfo": "Możesz dostosować prompty używane w trybie kontynuacji rozmowy. Użyj przycisku 'Przywróć domyślne', aby przywrócić wartości początkowe.",
  "ResetToDefault": "Przywróć domyślne",
  "ConversationContinuityPromptEvaluate": "1. Prompt oceny kontynuacji",
  "ConversationContinuityPromptEvaluateInfo": "Prompt określający, czy streamer powinien kontynuować mówienie na podstawie kontekstu rozmowy. Ten tekst jest wysyłany jako prompt systemowy, po którym następuje ostatnia historia jako wiadomości user/assistant. AI zwraca wynik w formacie JSON.",
  "ConversationContinuityPromptContinuation": "2. Wytyczne kontynuacji",
  "ConversationContinuityPromptContinuationInfo": "Wytyczne do naturalnego kontynuowania rozmowy przy braku komentarzy. Łączone z ustawieniami postaci jako dodatkowe instrukcje promptu systemowego, wysyłane do AI wraz z ostatnią historią.",
  "ConversationContinuityPromptSelectComment": "3. Prompt wyboru komentarza",
  "ConversationContinuityPromptSelectCommentInfo": "Prompt instrukcyjny do wyboru najodpowiedniejszego komentarza dla toku rozmowy. Ten tekst plus historia staje się promptem systemowym, a lista komentarzy jest wysyłana jako wiadomość użytkownika do AI.",
  "ConversationContinuityPromptNewTopic": "4. Prompt generowania nowego tematu",
  "ConversationContinuityPromptNewTopicInfo": "Prompt instrukcyjny do generowania nowego powiązanego tematu z rozmowy. Ten tekst jest wysyłany jako prompt systemowy, po którym następuje ostatnia historia jako wiadomości user/assistant. AI zwraca słowa kluczowe tematu.",
  "ConversationContinuityPromptSleep": "5. Wytyczne trybu uśpienia",
  "ConversationContinuityPromptSleepInfo": "Wytyczne do generowania dialogów trybu uśpienia przy braku komentarzy widzów. Łączone z ustawieniami postaci jako dodatkowe instrukcje promptu systemowego, wysyłane do AI wraz z ostatnią historią.",
  "MaxPastMessages": "Liczba przechowywanych poprzednich wiadomości",
  "UseCustomModel": "Użyj niestandardowego modelu",
  "CustomModelPlaceholder": "Wprowadź niestandardową nazwę modelu...",
  "Select": "Wybierz",
  "TestVoice": "Testuj głos",
  "SelectAIService": "Wybierz usługę AI",
  "LocalLLM": "Lokalny LLM",
  "SelectModel": "Wybierz model",
  "OpenAIAPIKeyLabel": "Klucz API OpenAI",
  "AnthropicAPIKeyLabel": "Klucz API Anthropic",
  "GoogleAPIKeyLabel": "Klucz API Google Gemini",
  "AzureAPIKeyLabel": "Klucz API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "GroqAPIKeyLabel": "Klucz API Groq",
  "CohereAPIKeyLabel": "Klucz API Cohere",
  "MistralAIAPIKeyLabel": "Klucz API MistralAI",
  "PerplexityAPIKeyLabel": "Klucz API Perplexity",
  "FireworksAPIKeyLabel": "Klucz API Fireworks",
  "DifyAPIKeyLabel": "Klucz API Dify",
  "DeepSeekAPIKeyLabel": "Klucz API DeepSeek",
  "APIKeyInstruction": "Klucze API można uzyskać z poniższego linku. Proszę wprowadzić uzyskany klucz API w formularzu.",
  "LocalLLMInfo": "Wymagane jest uruchomienie serwera lokalnego LLM.",
  "LocalLLMInfo2": "Wprowadź URL lokalnego LLM (włącznie z numerem portu) i nazwę modelu.",
  "GroqInfo": "API Groq jest dostępne bezpośrednio z przeglądarki.",
  "DifyInfo": "W Dify obsługiwane są tylko chatboty lub typy agentów. Jeśli nie uzyskasz poprawnej odpowiedzi, usuń historię rozmów i spróbuj ponownie zadać pytanie.",
  "DifyInfo2": "Długość historii rozmowy zależy od ustawień chatbota Dify.",
  "DifyInfo3": "Przykład: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Gdy używasz Dify, ten prompt systemowy nie jest używany. Ustaw go w chatbocie Dify.",
  "EnterURL": "Wprowadź URL",
  "CharacterModelLabel": "Model postaci",
  "CharacterModelInfo": "W zależności od modelu, początkowe ładowanie może potrwać dłużej.",
  "OpenVRM": "Otwórz VRM",
  "CharacterPosition": "Pozycja postaci",
  "CharacterPositionInfo": "Możesz ustawić stałą pozycję i orientację postaci. Pozycja kamery jest zapisywana dla VRM, a pozycja modelu dla Live2D.",
  "FixPosition": "Przypnij pozycję",
  "UnfixPosition": "Odblokuj przypięcie",
  "ResetPosition": "Zresetuj pozycję",
  "Save": "Zapisz",
  "CurrentStatus": "Aktualny stan",
  "PositionFixed": "Przytwierdzony",
  "PositionNotFixed": "Nieprzypięte",
  "ChangeBackgroundImage": "Zmień obraz tła",
  "BackgroundSettings": "Ustawienia tła",
  "BackgroundSettingsDescription": "Możesz przesłać i wybrać obraz tła dla aplikacji.",
  "Cancel": "Anuluj",
  "UploadBackground": "Prześlij obraz tła",
  "DefaultBackground": "Domyślne tło",
  "GreenBackground": "zielone tło",
  "CharacterSettingsPrompt": "Prompt postaci",
  "CharacterSettingsInfo": "Ta wartość jest ustawiana jako prompt systemowy.\nKorzystając z początkowego promptu, możesz kontrolować wyrażenia i ruchy postaci, określając tagi emocji. Przykład: [neutral]Dzień dobry![happy]Dobrej pracy na dziś!",
  "CharacterpresetInfo": "Wybór presetu zmieni prompt postaci.\nMożna używać skrótów Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Wybór silnika syntezy głosu",
  "VoiceAdjustment": "Regulacja głosu",
  "VoiceEngineInstruction": "Wybierz silnik syntezy głosu do użycia.",
  "UsingKoeiromap": "Użyj Koeiromap",
  "KoeiromapInfo": "Używamy API Koeiromap Koemotion. Obsługuje tylko język japoński. Więcej informacji poniżej.",
  "UsingVoiceVox": "Użyj VOICEVOX",
  "VoiceVoxInfo": "Używamy VOICEVOX. Obsługuje tylko język japoński. Ponieważ używa lokalnego API, musisz pobrać i uruchomić aplikację odpowiednią dla swojego środowiska z poniższej strony.",
  "VoicevoxSpeed": "Prędkość mowy",
  "VoicevoxPitch": "Wysokość głosu",
  "VoicevoxIntonation": "Intonacja",
  "VoicevoxServerUrl": "URL serwera VOICEVOX",
  "UsingAivisSpeech": "Użyj AivisSpeech",
  "UsingAivisCloudAPI": "Użyj Aivis Cloud API",
  "AivisCloudAPIInfo": "Ustawienia Aivis Cloud API",
  "AivisCloudAPIDashboard": "Aivis Cloud API Panel",
  "AivisSpeechInfo": "Używamy AivisSpeech. Obsługuje tylko język japoński. Ponieważ używa lokalnego API, musisz pobrać i uruchomić aplikację odpowiednią dla swojego środowiska z poniższej strony.",
  "AivisSpeechSpeaker": "Głos",
  "AivisSpeechSpeed": "Prędkość mowy",
  "AivisSpeechPitch": "Wysokość głosu",
  "AivisSpeechIntonationScale": "Siła stylu",
  "AivisSpeechServerUrl": "URL serwera AivisSpeech",
  "NoClientIDSet": "ID klienta nie jest ustawione",
  "UpdateSpeakerList": "Aktualizuj listę głosów",
  "UsingGoogleTTS": "Użyj Google Text-to-Speech",
  "UsingStyleBertVITS2": "Użyj Style-Bert-VITS2",
  "StyleBertVITS2Info": "Używamy Style-Bert-VITS2. Obsługuje tylko języki japoński, angielski i chiński. Jeśli używasz lokalnego API, musisz pobrać i uruchomić aplikację odpowiednią dla swojego środowiska z poniższej strony. W razie potrzeby ustaw także klucz API.",
  "SpeakerSelection": "Wybór typu głosu",
  "EnglishToJapanese": "Czytaj angielskie słowa po japońsku",
  "IncludeTimestampInUserMessage": "Dołącz znacznik czasu do wypowiedzi użytkownika",
  "IncludeTimestampInUserMessageInfo": "Dołączenie znacznika czasu do wypowiedzi użytkownika pozwala AI generować odpowiedzi z uwzględnieniem czasu.\nDodaj następujący tekst do promptu systemowego:\n\n\"Jeśli dane wejściowe użytkownika zawierają [timestamp], reprezentuje to czas w strefie czasowej UTC w momencie żądania, więc proszę wygenerować odpowiedź z uwzględnieniem tego czasu.\"",
  "GoogleTTSInfo": "Używamy Google Cloud Text-to-Speech. Obsługuje wiele języków.",
  "AuthFileInstruction": "Wymagany jest klucz API lub plik JSON do uwierzytelniania. Uzyskaj go z poniższej strony i umieść plik JSON jako credentials.json w głównym folderze repozytorium.",
  "LanguageModelURL": "Wybierz model języka z poniższego URL.",
  "LanguageChoice": "Wybór języka",
  "StyleBeatVITS2ServerURL": "URL serwera",
  "StyleBeatVITS2ApiKey": "Klucz API",
  "StyleBeatVITS2ModelID": "ID modelu",
  "StyleBeatVITS2Style": "Styl",
  "StyleBeatVITS2SdpRatio": "Stosunek mieszania SDP/DP",
  "StyleBeatVITS2Length": "Prędkość mowy",
  "ConversationHistory": "Historia rozmowy",
  "ConversationHistoryInfo": "Ostatnie {{count}} wiadomości rozmowy są przechowywane jako pamięć.",
  "ConversationHistoryReset": "Resetuj historię rozmowy",
  "NotConnectedToExternalAssistant": "Nie połączono z zewnętrznym asystentem.",
  "APIKeyNotEntered": "Nie wprowadzono klucza API.",
  "ChatLog": "Dziennik rozmów",
  "EnterYourQuestion": "Wpisz, o co chcesz zapytać",
  "AnswerGenerating": "Generowanie odpowiedzi",
  "AboutThisApplication": "O tej aplikacji",
  "AboutThisApplicationDescription": "Możesz cieszyć się rozmową z postacią 3D tylko za pomocą przeglądarki internetowej, wykorzystując mikrofon, wprowadzanie tekstu i syntezę głosu. Możesz również zmienić postać (VRM), ustawienia osobowości i dostosować głos.<br />Ustawienia można zmienić za pomocą przycisku menu w lewym górnym rogu.",
  "AboutThisApplicationDescription2": "W AITuberKit możesz cieszyć się rozmową z postacią AI tylko za pomocą przeglądarki internetowej. Sprawdź poszczególne ustawienia, aby zmienić postać, ustawienia osobowości i dostosować głos.",
  "TechnologyIntroduction": "Wprowadzenie technologii",
  "TechnologyIntroductionDescription1": "Ta aplikacja została stworzona poprzez modyfikację <b>ChatVRM</b> firmy pixiv. Oryginalny kod źródłowy można znaleźć",
  "TechnologyIntroductionLink1": "tutaj",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Do wyświetlania i obsługi modeli 3D używamy",
  "TechnologyIntroductionDescription4": ", do generowania rozmów używamy",
  "TechnologyIntroductionDescription5": "i innych LLM, a do syntezy głosu używamy",
  "TechnologyIntroductionDescription6": "i innych TTS. Szczegółowe informacje można znaleźć w",
  "TechnologyIntroductionLink2": "artykule wyjaśniającym",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "Kod źródłowy tej aplikacji jest publikowany na GitHubie. Możesz swobodnie go modyfikować i zmieniać.",
  "SourceCodeDescription2": "Informacje na temat użytku komercyjnego znajdują się w README w tym repozytorium.",
  "RepositoryURL": "URL repozytorium:",
  "DontShowIntroductionNextTime": "Nie pokazuj tego dialogu następnym razem",
  "Close": "Zamknij",
  "Contact": "Kontakt",
  "ContactDescription": "W przypadku pytań dotyczących tej aplikacji, skontaktuj się za pomocą poniższego adresu e-mail lub konta Twitter.",
  "Creator": "Informacje o twórcy",
  "CreatorDescription": "Twórca: Nike",
  "Documentation": "Dokumentacja",
  "DocumentationDescription": "Szczegółowe instrukcje i tutoriale dotyczące AITuberKit można znaleźć pod poniższym URL.",
  "Language": "Ustawienia języka",
  "UsingGSVITTS": "Użyj GSVI TTS",
  "GSVITTSInfo": "Ustawienia GSVI TTS",
  "GSVITTSServerUrl": "URL serwera GSVI TTS",
  "GSVITTSModelID": "ID modelu GSVI TTS",
  "GSVITTSBatchSize": "Rozmiar partii GSVI TTS (1 ~ 100, większa wartość przyspiesza wnioskowanie, ale zbyt duża może wyczerpać pamięć)",
  "GSVITTSSpeechRate": "Prędkość mowy (0.5 ~ 2.0, większa wartość oznacza szybciej)",
  "UsingElevenLabs": "Użyj ElevenLabs",
  "ElevenLabsInfo": "Używamy API ElevenLabs. Obsługuje wiele języków. Uzyskaj klucz API z poniższego URL.",
  "ElevenLabsApiKey": "Klucz API ElevenLabs",
  "ElevenLabsVoiceId": "ID głosu ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Wybierz ID głosu z poniższego URL.",
  "UsingCartesia": "Użyj Cartesia",
  "CartesiaInfo": "Używa API Cartesia. Obsługuje wiele języków. Proszę uzyskać klucz API z poniższego URL.",
  "CartesiaApiKey": "Klucz API Cartesia",
  "CartesiaVoiceId": "Cartesia ID głosowe",
  "CartesiaVoiceIdInfo": "Wybierz Voice ID z poniższego adresu URL.",
  "CharacterName": "Nazwa postaci",
  "UserDisplayName": "Nazwa wyświetlana użytkownika",
  "ShowAssistantText": "Pokaż pole odpowiedzi",
  "ShowCharacterName": "Pokaż nazwę postaci w polu odpowiedzi",
  "ShowControlPanel": "Pokaż panel sterowania",
  "ShowControlPanelInfo": "Ekran ustawień można wyświetlić za pomocą Cmd + . (Mac) / Ctrl + . (Windows).\nJeśli korzystasz ze smartfona, możesz także przytrzymać lewy górny róg ekranu (przez około 1 sekundę).",
  "ColorTheme": "Motyw kolorystyczny",
  "ColorThemeInfo": "Możesz wybrać motyw kolorystyczny aplikacji. Wybrany motyw zostanie zastosowany natychmiast.",
  "ThemeDefault": "Domyślny",
  "ThemeMono": "Monochromatyczny",
  "ThemeCool": "Chłodny",
  "ThemeOcean": "Ocean",
  "ThemeForest": "Las",
  "ThemeSunset": "Zachód słońca",
  "ShowQuickMenu": "Pokaż przycisk szybkiego menu",
  "SlideMode": "Tryb slajdów",
  "SelectedSlideDocs": "Używane slajdy",
  "EditSlideScripts": "Edycja dialogów",
  "PleaseSelectSlide": "Wybierz slajd.",
  "SlideModeDescription": "Tryb automatycznej prezentacji slajdów przez AI. Dostępny tylko wtedy, gdy wybrany jest model obsługujący multimodalność.",
  "PdfConvertLabel": "Konwersja slajdów PDF",
  "PdfConvertDescription": "Konwertuje plik PDF na dane do trybu slajdów. Dostępne tylko wtedy, gdy wybrano model obsługujący multimodalność.",
  "PdfConvertFileUpload": "Wybierz plik PDF",
  "PdfConvertFolderName": "Nazwa folderu zapisu",
  "CustomVoiceTextPlaceholder": "Wprowadź tekst do przetestowania",
  "TestVoiceSettings": "Test głosu",
  "TestSelectedVoice": "Odtwórz",
  "PdfConvertModelSelect": "Wybierz model",
  "PdfConvertButton": "Konwertuj PDF na slajdy",
  "PdfConvertLoading": "Konwersja...",
  "PdfConvertSuccess": "Konwersja zakończona",
  "PdfConvertError": "Konwersja nie powiodła się",
  "PdfConvertSubmitError": "Sprawdź, czy plik PDF, nazwa folderu i klucz API są ustawione",
  "LocalStorageReset": "Resetuj ustawienia",
  "LocalStorageResetInfo": "Jeśli ustawione są zmienne środowiskowe, ich wartości mają pierwszeństwo. Strona zostanie ponownie załadowana.",
  "LocalStorageResetButton": "Resetuj ustawienia",
  "InitialSpeechTimeout": "Limit czasu rozpoznawania mowy",
  "InitialSpeechTimeoutInfo": "Ustaw czas oczekiwania na wykrycie pierwszej wypowiedzi po rozpoczęciu rozpoznawania głosu. Jeśli w tym czasie nie zostanie wykryta żadna wypowiedź, rozpoznawanie głosu zostanie automatycznie zatrzymane.\nUstawienie na 0 sekund oznacza nieograniczony czas oczekiwania.",
  "Milliseconds": "milisekundy",
  "NoSpeechTimeout": "Limit czasu wykrywania ciszy",
  "NoSpeechTimeoutInfo": "Ustaw czas, po którym wejście głosowe zostanie automatycznie zakończone, jeśli wystąpi cisza podczas wprowadzania głosu.\nUstawienie na 0 sekund wyłącza automatyczne wysyłanie po wykryciu ciszy.",
  "ShowSilenceProgressBar": "Pokaż pasek postępu wykrywania ciszy",
  "SpeechRecognitionMode": "Tryb rozpoznawania mowy",
  "SpeechRecognitionModeInfo": "Możesz wybrać tryb rozpoznawania mowy.\n\"Standardowy przeglądarkowy\" używa wbudowanego rozpoznawania mowy przeglądarki. \"OpenAI TTS\" używa API Text to Speech OpenAI.\nOgólnie zaleca się \"Standardowy przeglądarkowy\", ponieważ ma wyższą dokładność i szybsze rozpoznawanie. Jednak jeśli używasz przeglądarki, która nie obsługuje WebSpeech API, takiej jak Firefox, wybierz \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Użyj standardowego rozpoznawania mowy przeglądarki",
  "WhisperSpeechRecognition": "Użyj rozpoznawania mowy OpenAI TTS",
  "WhisperTranscriptionModel": "Model transkrypcji",
  "WhisperTranscriptionModelInfo": "Możesz wybrać model używany do rozpoznawania mowy. Bardziej zaawansowane modele oferują wyższą dokładność rozpoznawania, ale mogą wiązać się z wyższymi kosztami API.",
  "SpeechRecognitionModeDisabledInfo": "Gdy tryb audio jest włączony, można używać tylko rozpoznawania mowy przeglądarki.\nPonadto, w trybie API w czasie rzeczywistym można używać tylko rozpoznawania mowy przeglądarki, a funkcja limitu czasu rozpoznawania mowy jest wyłączona.",
  "Errors": {
    "EmptyAPIKey": "Klucz API nie jest ustawiony",
    "EmptyLocalLLMURL": "URL lokalnego LLM nie jest ustawiony",
    "AIInvalidProperty": "Wartość ustawienia usługi AI jest nieprawidłowa",
    "AIAPIError": "Wystąpił błąd podczas wykonywania API AI",
    "InvalidAIService": "Wybrana usługa AI jest nieprawidłowa",
    "MethodNotAllowed": "Żądanie nie jest odpowiednie",
    "TTSServiceError": "Wystąpił błąd w usłudze TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Wystąpił nieznany błąd",
    "LocalLLMError": "Wystąpił błąd w lokalnym LLM",
    "LocalLLMStreamError": "Wystąpił błąd w przetwarzaniu strumienia lokalnego LLM",
    "LocalLLMConnectionError": "Nie można połączyć się z serwerem lokalnego LLM",
    "LocalLLMNotFound": "Nie znaleziono punktu końcowego lokalnego LLM",
    "LocalLLMAPIError": "Wystąpił błąd w API lokalnego LLM",
    "CustomAPIError": "Wystąpił błąd w niestandardowym API",
    "InvalidJSON": "Format JSON jest nieprawidłowy"
  },
  "MessageReceiver": "Przyjmuj instrukcje z zewnątrz",
  "MessageReceiverDescription": "Możesz instruować postać AI z zewnątrz za pomocą API.",
  "ClientID": "ID klienta",
  "OpenSendMessagePage": "Otwórz stronę wysyłania wiadomości",
  "RealtimeAPIMode": "Tryb API w czasie rzeczywistym",
  "RealtimeAPIModeContentType": "Typ transmisji",
  "RealtimeAPIModeVoice": "Typ głosu",
  "AudioMode": "Tryb audio",
  "InputText": "Tekst",
  "InputAudio": "Głos",
  "SearchGrounding": "Użyj funkcji wyszukiwania",
  "SearchGroundingDescription": "Funkcja wyszukiwania jest automatycznie wyłączana podczas korzystania z funkcji multimodalnych.",
  "DynamicRetrieval": "Wyszukiwanie dynamiczne",
  "DynamicRetrievalDescription": "Ustawia próg czasu, kiedy model wykonuje wyszukiwanie. Wartość 0 oznacza, że wyszukiwanie jest wykonywane zawsze, a 1 oznacza, że wyszukiwanie nie jest wykonywane.",
  "DynamicRetrievalThreshold": "Dynamiczny próg",
  "UpdateRealtimeAPISettings": "Aktualizuj ustawienia API w czasie rzeczywistym",
  "UpdateRealtimeAPISettingsInfo": "Po aktualizacji klucza API, endpointu Azure, typu głosu, modelu lub promptu systemowego, naciśnij przycisk aktualizacji, aby rozpocząć nową sesję WebSocket.",
  "AzureEndpoint": "Endpoint Azure",
  "Toasts": {
    "WebSocketConnectionError": "Wystąpił błąd połączenia WebSocket",
    "WebSocketConnectionClosed": "Połączenie WebSocket zostało zamknięte",
    "WebSocketConnectionAttempt": "Próba połączenia WebSocket...",
    "WebSocketConnectionSuccess": "Połączenie WebSocket zostało nawiązane pomyślnie",
    "FunctionExecuting": "Wykonywanie {{funcName}}",
    "FunctionExecutionFailed": "Nie udało się wykonać {{funcName}}",
    "FirefoxNotSupported": "Ta funkcja nie jest obsługiwana w Firefoxie",
    "SpeechRecognitionError": "Wystąpił błąd rozpoznawania mowy",
    "NoSpeechDetected": "Nie wykryto dźwięku.",
    "PresetSwitching": "Przełączono na {{presetName}}.",
    "WhisperError": "Wystąpił błąd podczas rozpoznawania mowy za pomocą Whisper",
    "UsingTool": "Używanie {{toolName}}",
    "PositionFixed": "Pozycja postaci została ustalona na stałe",
    "PositionUnfixed": "Odblokowano pozycję postaci",
    "PositionReset": "Pozycja postaci została zresetowana",
    "PositionActionFailed": "Nie udało się wykonać operacji na pozycji",
    "MicrophonePermissionDenied": "Dostęp do mikrofonu został odrzucony",
    "CameraPermissionMessage": "Proszę zezwolić na użycie kamery.",
    "PresetLoadFailed": "Nie udało się załadować presetu"
  },
  "ContinuousMic": "Ciągłe wejście mikrofonu",
  "ContinuousMicActive": "Ciągłe wejście mikrofonu aktywne",
  "ContinuousMicModeOn": "Tryb ciągłego wejścia mikrofonu włączony",
  "ContinuousMicModeOff": "Tryb ciągłego wejścia mikrofonu wyłączony",
  "ListeningContinuously": "Oczekiwanie na wejście głosowe...",
  "ContinuousMicInfo": "Automatycznie wznawia wejście mikrofonu po zakończeniu wypowiedzi AI. Automatycznie wysyła po upływie ustawionego czasu ciszy.\nJeśli rozpoznawanie mowy nie nastąpi przed upływem ustawionego czasu, ciągłe wejście mikrofonu zostanie automatycznie wyłączone. Jeśli chcesz, aby zawsze było włączone, ustaw limit czasu rozpoznawania mowy na 0 sekund.",
  "UsingOpenAITTS": "Użyj OpenAI",
  "OpenAITTSInfo": "Używamy OpenAI. Obsługuje wiele języków. Jeśli wybrano OpenAI jako usługę AI, nie musisz ustawiać poniższego klucza API.",
  "OpenAITTSVoice": "Typ głosu",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Prędkość mowy",
  "UsingAzureTTS": "Użyj Azure OpenAI",
  "AzureTTSInfo": "Używamy Azure OpenAI. Obsługuje wiele języków.",
  "SendMessage": {
    "title": "Adapter zewnętrzny AITuberKit",
    "directSendTitle": "Kazać postaci AI mówić bezpośrednio",
    "directSendDescription": "Możesz kazać postaci AI mówić dokładnie to, co wysyłasz. W przypadku wielu wiadomości będą one przetwarzane po kolei.\nUżywany jest model głosowy wybrany w ustawieniach AITuberKit.",
    "aiGenerateTitle": "Wygenerować odpowiedź przez AI, a następnie kazać postaci mówić",
    "aiGenerateDescription": "AI generuje odpowiedź na podstawie wysłanej wiadomości, a postać AI wypowiada tę odpowiedź. W przypadku wielu wiadomości będą one przetwarzane po kolei.\nModel AI i model głosowy są wybierane w ustawieniach AITuberKit.\nMożesz wybrać, czy chcesz używać promptu systemowego AITuberKit, czy niestandardowego promptu systemowego.\nAby załadować poprzednią historię rozmowy, dołącz ciąg \"[conversation_history]\" w dowolnym miejscu promptu systemowego lub wiadomości użytkownika.",
    "useCurrentSystemPrompt": "Użyj promptu systemowego AITuberKit",
    "userInputTitle": "Wysłać dane wejściowe użytkownika",
    "userInputDescription": "Wysłana wiadomość jest przetwarzana tak samo, jakby została wprowadzona z formularza wejściowego AITuberKit. W przypadku wielu wiadomości będą one przetwarzane po kolei.\nModel AI i model głosowy są wybierane w ustawieniach AITuberKit.\nUżywany jest prompt systemowy i historia rozmowy z AITuberKit."
  },
  "CannotUseVoice": "Gdy tryb API w czasie rzeczywistym lub tryb audio jest włączony,\nustawienia syntezy głosu nie są potrzebne.",
  "APIKey": "Klucz API",
  "Preset": "Preset",
  "Cute": "słodki",
  "Energetic": "zdrowy",
  "Cool": "fajny",
  "Mature": "wytrawny",
  "UseAivisCloudAPI": "Użyj Aivis Cloud API",
  "AivisCloudAPIDescription": "Zaznaczenie spowoduje użycie wersji chmurowej Aivis Cloud API.",
  "ModelUUID": "UUID modelu",
  "StyleID": "ID stylu",
  "SpeechSpeed": "Prędkość mówienia",
  "Pitch": "Pitch",
  "TempoDynamics": "Zmiany tempa",
  "PreSilenceDuration": "Czas ciszy przed dźwiękiem",
  "PostSilenceDuration": "Czas ciszy po dźwięku",
  "EmotionalIntensity": "Siła wyrazu emocji",
  "UseStyleName": "Określ za pomocą nazwy stylu",
  "StyleSelectionDescription": "Możesz wybrać albo identyfikator stylu, albo nazwę stylu. Zazwyczaj używa się identyfikatora stylu (0–31).",
  "StyleName": "Nazwa stylu",
  "StyleNamePlaceholder": "Przykład: Normalny",
  "Live2D": {
    "FileInfo": "Umieść folder z modelem Live2D, którego chcesz użyć, w public/live2d. Plik model3.json musi istnieć bezpośrednio w tym folderze.\nJeśli nie pojawia się w opcjach, odśwież stronę lub sprawdź, czy ścieżka folderu jest poprawna.",
    "Info": "Możesz określić emocje i ruchy.\nKażda emocja jest kontrolowana przez prompt. Szczegóły znajdziesz w \"Ustawienia AI => Ustawienia postaci\".",
    "Emotions": "Ustawienia emocji",
    "EmotionInfo": "Emocje można określić oddzielając je przecinkami. W przypadku wielu określeń jedna zostanie wybrana losowo.\nWartości domyślne są przeznaczone dla modeli dostarczanych z AITuberKit. Jeśli używasz własnego modelu, wprowadź wartości odpowiednie dla swojego modelu.\nPo zakończeniu rozmowy wyświetlane jest wyrażenie \"normalne\".",
    "neutralEmotions": "Normalne",
    "happyEmotions": "Szczęśliwe",
    "sadEmotions": "Smutne",
    "angryEmotions": "Złe",
    "relaxedEmotions": "Zrelaksowane",
    "surprisedEmotions": "Zaskoczone",
    "MotionGroups": "Ustawienia grup ruchów",
    "MotionGroupsInfo": "Ruchy są losowo wybierane z wybranej grupy.\nPodobnie jak w przypadku ustawień emocji, dostosuj do własnego modelu.\n\"Bezczynność\" to ruch wyświetlany po zakończeniu rozmowy.",
    "SelectMotionGroup": "Wybierz grupę ruchów",
    "idleMotionGroup": "Bezczynność",
    "neutralMotionGroup": "Normalne",
    "happyMotionGroup": "Szczęśliwe",
    "sadMotionGroup": "Smutne",
    "angryMotionGroup": "Złe",
    "relaxedMotionGroup": "Zrelaksowane",
    "surprisedMotionGroup": "Zaskoczone"
  },
  "PNGTuber": {
    "FileInfo": "Umieść folder z zasobami PNGTuber, których chcesz użyć, w public/pngtuber. Upewnij się, że plik config.json i obrazy PNG znajdują się bezpośrednio w tym folderze.\nJeśli nie pojawia się w opcjach, odśwież stronę lub sprawdź, czy ścieżka folderu jest poprawna.",
    "Sensitivity": "Czułość",
    "SensitivityInfo": "Dostosowuje czułość głośności dla synchronizacji ruchu warg. Wyższe wartości zwiększają częstotliwość otwierania ust.",
    "ChromaKey": "Chroma Key (przezroczystość tła)",
    "ChromaKeyEnabled": "Włącz Chroma Key",
    "ChromaKeyColor": "Kolor klucza (kolor do uczynienia przezroczystym)",
    "ChromaKeyTolerance": "Tolerancja",
    "ChromaKeyToleranceInfo": "Wyższe wartości sprawią, że kolory zbliżone do koloru klucza również staną się przezroczyste.",
    "ChromaKeyPreview": "Podgląd wideo",
    "ChromaKeyPreviewInfo": "Kliknij na wideo, aby wybrać kolor, który chcesz uczynić przezroczystym.",
    "PositionSize": "Pozycja i rozmiar",
    "PositionInfo": "Użyj kółka myszy do powiększania, przeciągnij, aby przesunąć.",
    "ResetPosition": "Resetuj pozycję i rozmiar"
  },
  "UseVideoAsBackground": "Użyj udostępnionego ekranu lub kamery internetowej jako tła",
  "Temperature": "Temperature",
  "MaxTokens": "Maksymalna liczba tokenów",
  "MaxTokensInfo": "Maksymalna liczba tokenów różni się w zależności od używanego modelu AI. Sprawdź specyfikację każdego modelu.",
  "ReasoningMode": "Tryb rozumowania",
  "ReasoningModeInfo": "Włączenie trybu rozumowania umożliwia korzystanie z rozszerzonych procesów myślenia w obsługiwanych modelach. W nieobsługiwanych modelach może nie mieć efektu lub powodować błędy.",
  "ReasoningEffort": "Poziom rozumowania",
  "ReasoningEffortInfo": "Wybierz poziom obliczeń dla rozumowania. Wyższe poziomy zapewniają głębsze myślenie, ale zwiększają czas odpowiedzi i zużycie tokenów.",
  "ReasoningTokenBudget": "Budżet tokenów rozumowania",
  "ReasoningTokenBudgetInfo": "Maksymalna liczba tokenów przydzielonych procesowi rozumowania (myślenia). Używany z Anthropic, Cohere i serią Google Gemini 2.5.",
  "ThinkingProcess": "Proces myślenia",
  "ShowThinkingText": "Zawsze pokazuj proces myślenia",
  "ShowThinkingTextInfo": "Po włączeniu proces myślenia modelu rozumowania będzie zawsze wyświetlany w rozwiniętej formie w historii czatu.",
  "CannotUseParameters": "Funkcja multimodalna nie jest dostępna, gdy włączony jest tryb API w czasie rzeczywistym lub tryb audio. Parametry Temperature i Max Tokens nie mogą być również określone.",
  "PresetQuestions": "Wstępnie ustawione pytania",
  "PresetQuestionsInfo": "Możesz tworzyć i rejestrować wiele wzorców pytań. Zarejestrowane pytania będą wyświetlane jako przyciski w interfejsie użytkownika, które po kliknięciu zostaną wprowadzone w polu czatu.",
  "EnterPresetQuestion": "Wprowadź pytanie",
  "DragToReorder": "Przeciągnij, aby zmienić kolejność",
  "Edit": "Edytuj",
  "EnterClientID": "Wprowadź identyfikator klienta",
  "CustomAPIEndpoint": "Niestandardowy punkt końcowy API",
  "CustomAPIEndpointInfo": "Wprowadź URL punktu końcowego API, do którego będą wysyłane żądania POST.",
  "CustomAPIStream": "Tryb strumieniowy",
  "CustomAPIStreamForced": "Tryb strumieniowy jest obecnie zawsze włączony.",
  "IncludeSystemMessages": "Uwzględnij wiadomości systemowe",
  "CustomAPIHeaders": "Niestandardowe nagłówki",
  "CustomAPIHeadersInfo": "Wprowadź informacje nagłówka, które mają być zawarte w żądaniu API, w formacie JSON.",
  "CustomAPIBody": "Niestandardowy treść",
  "CustomAPIBodyInfo": "Wprowadź informacje treści, które mają być zawarte w żądaniu API, w formacie JSON. Wiadomości są automatycznie dołączane.",
  "CustomAPIDescription": "Uwaga: Wiadomości są automatycznie dołączane do treści żądania. W trybie strumieniowym serwer musi zwracać text/event-stream.",
  "XAIAPIKeyLabel": "Klucz API xAI",
  "OpenRouterAPIKeyLabel": "Klucz API OpenRouter",
  "OpenRouterModelNameInstruction": "Wprowadź identyfikator modelu z OpenRouter (np. \"openai/gpt-4o\", \"mistralai/mistral-large-latest\"). Identyfikator modelu można znaleźć na stronie modelu OpenRouter.",
  "ImageDisplayPosition": "Pozycja wyświetlania obrazu",
  "ImageDisplayPositionDescription": "Wybierz miejsce wyświetlania przesłanego obrazu",
  "InputArea": "Obszar wprowadzania",
  "SideArea": "Panel boczny",
  "NoDisplay": "Wyświetlaj tylko ikonę",
  "RemoveImage": "Usuń obrazek",
  "PasteImageSupported": "Obsługa wklejania obrazów",
  "ImageSizeExceeded": "Rozmiar obrazu przekracza limit 10MB",
  "ImageReadError": "Nie udało się odczytać pliku obrazu",
  "FileSizeError": "Rozmiar pliku przekracza maksymalny rozmiar {{maxSize}}MB.",
  "FileTypeError": "Nieobsługiwany format pliku. Można przesyłać tylko pliki graficzne (PNG, JPEG, GIF, WebP).",
  "ImageDimensionError": "Rozmiar obrazu przekracza maksymalnie {{maxWidth}}x{{maxHeight}} pikseli.",
  "ImageLoadError": "Nie udało się załadować obrazu.",
  "FileReadError": "Nie udało się załadować pliku.",
  "FileProcessError": "Wystąpił błąd podczas przetwarzania pliku.",
  "GenerateNew": "Nowe utworzenie",
  "EnableMultiModal": "Użyj funkcji multimodalnych",
  "EnableMultiModalDescription": "Włącz funkcję przesyłania obrazów. W przypadku modeli nieobsługiwanych obrazy mogą zostać zignorowane.",
  "MultiModalNotSupported": "Wybrany model lub ustawienie nie obsługuje przesyłania obrazów. Włącz funkcję multimodalną lub wybierz obsługiwany model.",
  "MultiModalMode": "Tryb korzystania multimodalnego",
  "MultiModalModeDescription": "Wybierz, kiedy używać funkcji multimodalnych.",
  "MultiModalModeAIDecide": "Decyzja podejmowana przez AI",
  "MultiModalModeAlways": "Zawsze używaj",
  "MultiModalModeNever": "Nie używaj",
  "MultiModalAIDecisionPrompt": "Prompt do oceny AI",
  "MultiModalAIDecisionPromptPlaceholder": "Jesteś asystentem, który ocenia, czy obraz jest powiązany z pytaniem użytkownika lub kontekstem rozmowy. Proszę odpowiedz tylko „tak” lub „nie”, biorąc pod uwagę ostatnią historię rozmowy i wiadomość użytkownika.",
  "CustomApiIncludeMimeType": "Dołącz typ MIME do obrazu",
  "CustomApiIncludeMimeTypeDescription": "Dołącz właściwość mimeType do obiektu obrazu wysyłanego do niestandardowego API.",
  "ImageSettingsDescription": "Możesz przesłać obrazy i umieścić je na ekranie. Możesz wyświetlić jednocześnie do 5 obrazów.",
  "UploadImages": "Prześlij obraz",
  "SupportedFormats": "Obsługiwane formaty",
  "OnlyImageFilesAllowed": "Można przesyłać tylko pliki graficzne.",
  "FileSizeTooLarge": "Rozmiar pliku jest zbyt duży (maksymalnie 100MB).",
  "Uploading": "Przesyłanie...",
  "UploadComplete": "Przesyłanie zakończone",
  "UploadFailed": "Nie udało się przesłać pliku",
  "UploadedImages": "Przesłane obrazy",
  "NoUploadedImages": "Brak przesłanych obrazów",
  "AddToDisplay": "Wyświetl na ekranie",
  "AlreadyDisplayed": "Wyświetlanie",
  "MaximumFiveImagesAllowed": "Można wyświetlić maksymalnie 5 obrazów.",
  "ImageAlreadyPlaced": "Ten obraz jest już wyświetlany.",
  "CurrentlyDisplayedImages": "Obraz aktualnie wyświetlany",
  "NoDisplayedImages": "Obecnie nie ma wyświetlanych obrazów",
  "Position": "Pozycja",
  "Size": "Rozmiar",
  "Remove": "Usuń",
  "Delete": "Usuń",
  "ConfirmDeleteImage": "Czy na pewno chcesz usunąć ten obraz?",
  "DeleteFailed": "Nie udało się usunąć",
  "LayerControl": "Kolejność nakładania się",
  "LayerControlDescription": "Możesz kontrolować kolejność nakładania się obrazów i postaci",
  "BehindCharacter": "Za postacią",
  "InFrontOfCharacter": "Przed postacią",
  "MoveToBack": "Przesuń do tyłu",
  "MoveToFront": "Przesuń do przodu",
  "CharacterLayer": "Postać",
  "LayerPosition": "Pozycja wyświetlania",
  "DragToReorderLayers": "Przeciągnij, aby zmienić kolejność",
  "ImageOrder": "Kolejność obrazów",
  "CharacterLayerPosition": "Pozycja postaci",
  "CharacterPositionDescription": "Możesz przeciągnąć postać, aby dostosować jej pozycję",
  "DragCharacterToMove": "Przeciągnij postać, aby ją przesunąć",
  "ResetCharacterPosition": "Zresetuj pozycję",
  "FixCharacterPosition": "Przypnij pozycję",
  "UnfixCharacterPosition": "Odblokuj pozycję",
  "CharacterPositionFixed": "Pozycja jest zablokowana",
  "LayerOrder": "Kolejność warstw (maksymalnie 5)",
  "LayerOrderDescription": "Możesz dostosować kolejność nakładania się obrazów i postaci za pomocą przeciągania i upuszczania.",
  "Items": "Element",
  "TopLayer": "Na wierzchu",
  "BottomLayer": "Najbardziej z tyłu",
  "MostVisible": "Najbardziej widoczny",
  "LeastVisible": "najmniej widoczny",
  "Presets": "Preset",
  "MemorySettings": "Ustawienia pamięci",
  "MemoryEnabled": "Pamięć długoterminowa",
  "MemoryEnabledInfo": "Po włączeniu pamięci długoterminowej, przeszłe rozmowy zostaną zwektoryzowane i zapisane, co pozwoli postaci AI pamiętać przeszłe rozmowy. Ponieważ używane jest API OpenAI Embeddings, wymagana jest konfiguracja klucza API OpenAI.",
  "MemorySimilarityThreshold": "Próg podobieństwa",
  "MemorySimilarityThresholdInfo": "Zostaną użyte tylko wspomnienia o podobieństwie powyżej tej wartości. Zalecana wartość to 0.6-0.8.",
  "MemorySearchPreview": "Podgląd podobieństwa",
  "MemorySearchPreviewInfo": "Wprowadź zapytanie testowe, aby sprawdzić wyniki podobieństwa z zapisanymi wspomnieniami. Przydatne do dostrajania progu.",
  "MemorySearchPreviewPlaceholder": "Wprowadź zapytanie testowe...",
  "MemorySearchPreviewButton": "Szukaj",
  "MemorySearchPreviewNoResults": "Nie znaleziono pasujących wspomnień (embeddingi mogły jeszcze nie zostać wygenerowane)",
  "MemorySearchLimit": "Limit wyników wyszukiwania",
  "MemorySearchLimitInfo": "Ustaw maksymalną liczbę wyników wyszukiwania.",
  "MemoryMaxContextTokens": "Maksymalna liczba tokenów kontekstu",
  "MemoryMaxContextTokensInfo": "Ustaw maksymalną liczbę tokenów do dodania do kontekstu pamięci.",
  "MemoryClear": "Wyczyść pamięć",
  "MemoryClearConfirm": "Czy na pewno chcesz usunąć wszystkie wspomnienia? Tej operacji nie można cofnąć.",
  "MemoryCount": "Liczba zapisanych wspomnień",
  "MemoryCountValue": "{{count}} elementów",
  "MemoryAPIKeyWarning": "Funkcja pamięci długoterminowej nie jest dostępna, ponieważ klucz API OpenAI nie jest skonfigurowany.",
  "MemoryRestore": "Przywróć pamięć",
  "MemoryRestoreInfo": "Przywróć historię rozmów z plików dziennika rozmów (chat-log-*.json) w folderze logs.",
  "MemoryRestoreSelect": "Wybierz plik",
  "MemoryRestoreConfirm": "Czy chcesz przywrócić te dane pamięci? Istniejąca historia rozmów zostanie nadpisana.",
  "MemoryRestoreSuccess": "Pamięć została przywrócona",
  "MemoryRestoreError": "Nie udało się przywrócić pamięci",
  "VectorizeOnRestore": "Zapisz również w pamięci długoterminowej",
  "VectorizeOnRestoreInfo": "Po włączeniu dane zostaną zwektoryzowane i zapisane w pamięci długoterminowej podczas przywracania. Ta opcja może być włączona tylko wtedy, gdy opcja pamięci długoterminowej jest włączona.",
  "PresenceSettings": "Ustawienia wykrywania obecności",
  "PresenceDetectionEnabled": "Tryb wykrywania obecności",
  "PresenceDetectionEnabledInfo": "Tryb automatycznego wykrywania odwiedzających za pomocą kamery internetowej i powitania ich. Przydatny do pracy autonomicznej na wystawach i w cyfrowych znakach.",
  "PresenceDetectionDisabledInfo": "Wykrywanie obecności nie jest dostępne, gdy włączony jest tryb API w czasie rzeczywistym, tryb audio, tryb połączenia zewnętrznego lub tryb slajdów.",
  "PresenceGreetingPhrases": "Lista wiadomości powitalnych",
  "PresenceGreetingPhrasesInfo": "Zarejestruj wiadomości powitalne i emocje, które AI wypowie po wykryciu odwiedzającego. Jeśli zarejestrowano kilka, jeden zostanie wybrany losowo.",
  "PresenceDepartureTimeout": "Czas wykrycia odejścia",
  "PresenceDepartureTimeoutInfo": "Ustaw czas (w sekundach) od momentu utraty wykrycia twarzy do potwierdzenia odejścia. Po potwierdzeniu zostaną wypowiedziane wiadomości pożegnalne i wyczyszczona historia rozmowy.",
  "PresenceDeparturePhrases": "Lista wiadomości pożegnalnych",
  "PresenceDeparturePhrasesInfo": "Zarejestruj wiadomości i emocje, które AI wypowie przy odejściu odwiedzającego. Jeśli zarejestrowano kilka, jeden zostanie wybrany losowo. Jeśli nie zarejestrowano żadnych, żadna wiadomość nie zostanie wypowiedziana.",
  "PresenceAddPhrase": "Dodaj",
  "PresencePhraseTextPlaceholder": "Wprowadź wiadomość...",
  "PresenceDeletePhrase": "Usuń",
  "PresenceClearChatOnDeparture": "Wyczyść historię rozmowy przy odejściu",
  "PresenceClearChatOnDepartureInfo": "Czyści historię rozmowy przy odejściu odwiedzającego. Zapobiega przeglądaniu poprzedniej rozmowy przez następnego odwiedzającego.",
  "PresenceCooldownTime": "Czas odnowienia",
  "PresenceCooldownTimeInfo": "Ustaw czas (w sekundach) przed wznowieniem wykrywania po powrocie do stanu oczekiwania. Zapobiega wielokrotnemu powitaniu tej samej osoby.",
  "PresenceDetectionSensitivity": "Czułość wykrywania",
  "PresenceDetectionSensitivityInfo": "Wybierz czułość wykrywania twarzy. Wyższa czułość skraca interwał wykrywania, ale zwiększa obciążenie CPU.",
  "PresenceSensitivityLow": "Niska (interwał 500ms)",
  "PresenceSensitivityMedium": "Średnia (interwał 300ms)",
  "PresenceSensitivityHigh": "Wysoka (interwał 150ms)",
  "PresenceDetectionThreshold": "Czas potwierdzenia wykrycia",
  "PresenceDetectionThresholdInfo": "Ustaw czas (w sekundach) od wykrycia twarzy do potwierdzenia jako odwiedzającego. Aby zapobiec fałszywym wykryciom, odwiedzający jest rozpoznawany tylko wtedy, gdy twarz jest wykrywana nieprzerwanie przez określony czas. Ustaw na 0 dla natychmiastowego wykrycia.",
  "PresenceDebugMode": "Tryb debugowania",
  "PresenceDebugModeInfo": "Wyświetla podgląd obrazu z kamery i ramki wykrywania twarzy. Przydatne do sprawdzania ustawień i debugowania.",
  "PresenceTimingSettings": "Ustawienia czasowe",
  "PresenceTimingSettingsInfo": "Dostosuj czasy wykrywania odejścia i odnowienia.",
  "PresenceDetectionSettings": "Ustawienia wykrywania",
  "PresenceDetectionSettingsInfo": "Dostosuj czułość wykrywania twarzy i czas potwierdzenia.",
  "PresenceDeveloperSettings": "Ustawienia deweloperskie",
  "PresenceCameraSettings": "Ustawienia kamery",
  "PresenceCameraSettingsInfo": "Wybierz kamerę do wykrywania obecności.",
  "PresenceSelectedCamera": "Używana kamera",
  "PresenceSelectedCameraInfo": "Wybierz urządzenie kamery do wykrywania obecności. Przydatne, gdy podłączonych jest kilka kamer.",
  "PresenceCameraDefault": "Domyślna (automatyczny wybór)",
  "PresenceCameraRefresh": "Odśwież listę kamer",
  "PresenceCameraPermissionRequired": "Zezwól na dostęp do kamery w przeglądarce, aby pobrać listę kamer.",
  "PresenceStateIdle": "Oczekiwanie",
  "PresenceStateDetected": "Odwiedzający wykryty",
  "PresenceStateGreeting": "Powitanie",
  "PresenceStateConversationReady": "Rozmowa gotowa",
  "PresenceDebugFaceDetected": "Twarz wykryta",
  "PresenceDebugNoFace": "Nie wykryto twarzy",
  "Seconds": "sekund",
  "IdleSettings": "Ustawienia trybu bezczynności",
  "IdleModeEnabled": "Tryb bezczynności",
  "IdleModeEnabledInfo": "Gdy nie ma rozmowy z odwiedzającymi przez dłuższy czas, postać automatycznie mówi w regularnych odstępach. Przydatne do pracy autonomicznej na wystawach i w cyfrowych znakach.",
  "IdleModeDisabledInfo": "Tryb bezczynności nie jest dostępny, gdy włączony jest tryb API w czasie rzeczywistym, tryb audio, tryb połączenia zewnętrznego lub tryb slajdów.",
  "IdleInterval": "Interwał mówienia",
  "IdleIntervalInfo": "Ustaw czas od ostatniej rozmowy do następnego automatycznego wypowiedzenia (od {{min}} do {{max}} sekund).",
  "IdleSpeechSource": "Źródło mowy",
  "IdleSpeechSourceInfo": "Wybierz metodę mówienia w trybie bezczynności.",
  "IdleSpeechSourcePhraseList": "Lista fraz",
  "IdlePlaybackMode": "Tryb odtwarzania",
  "IdlePlaybackModeInfo": "Wybierz kolejność odtwarzania listy fraz.",
  "IdlePlaybackSequential": "Sekwencyjny",
  "IdlePlaybackRandom": "Losowy",
  "IdleDefaultEmotion": "Emocja powitania",
  "IdleDefaultEmotionInfo": "Wybierz ekspresję emocjonalną dla powitań zależnych od pory dnia.",
  "IdlePhrases": "Lista fraz",
  "IdlePhrasesInfo": "Zarejestruj wiadomości i emocje do wypowiedzenia w trybie bezczynności. Jeśli zarejestrowano kilka, zostaną wybrane zgodnie z trybem odtwarzania.",
  "IdleAddPhrase": "Dodaj",
  "IdlePhraseTextPlaceholder": "Wprowadź wiadomość...",
  "IdlePhraseText": "Wiadomość",
  "IdlePhraseEmotion": "Emocja",
  "IdleDeletePhrase": "Usuń",
  "IdleMoveUp": "Przesuń w górę",
  "IdleMoveDown": "Przesuń w dół",
  "IdleTimePeriodEnabled": "Powitania wg pory dnia",
  "IdleTimePeriodEnabledInfo": "Automatycznie zmienia powitania w zależności od pory dnia. Gdy lista fraz jest pusta, te powitania będą używane.",
  "IdleTimePeriodMorning": "Powitanie poranne",
  "IdleTimePeriodAfternoon": "Powitanie popołudniowe",
  "IdleTimePeriodEvening": "Powitanie wieczorne",
  "IdleAiGenerationEnabled": "Automatyczne generowanie AI",
  "IdleAiGenerationEnabledInfo": "Gdy lista fraz jest pusta, AI automatycznie wygeneruje wiadomości.",
  "IdleAiPromptTemplate": "Prompt generowania",
  "IdleAiPromptTemplateHint": "Określ ton postaci i rodzaj wiadomości do wygenerowania.",
  "IdleAiPromptTemplatePlaceholder": "Wygeneruj przyjazne zdanie dla odwiedzających wystawę.",
  "Emotion_neutral": "Neutralny",
  "Emotion_happy": "Szczęśliwy",
  "Emotion_sad": "Smutny",
  "Emotion_angry": "Zły",
  "Emotion_relaxed": "Zrelaksowany",
  "Emotion_surprised": "Zaskoczony",
  "Idle": {
    "Speaking": "Mówi",
    "WaitingPrefix": "Oczekiwanie"
  },
  "Kiosk": {
    "PasscodeTitle": "Wprowadź kod dostępu",
    "PasscodeIncorrect": "Nieprawidłowy kod dostępu",
    "PasscodeLocked": "Tymczasowo zablokowano",
    "PasscodeRemainingAttempts": "Pozostało {{count}} prób",
    "Cancel": "Anuluj",
    "Unlock": "Odblokuj",
    "FullscreenPrompt": "Dotknij, aby uruchomić na pełnym ekranie",
    "ReturnToFullscreen": "Powrót do pełnego ekranu",
    "InputInvalid": "Nieprawidłowe dane wejściowe",
    "RecoveryHint": "Jeśli zostaniesz wielokrotnie zablokowany, usuń klucz \"aituber-kiosk-lockout\" z localStorage w narzędziach deweloperskich przeglądarki."
  },
  "KioskSettings": "Ustawienia trybu kiosku",
  "KioskModeEnabled": "Tryb kiosku",
  "KioskModeEnabledInfo": "Tryb przydatny do pracy autonomicznej na wystawach i w cyfrowych znakach. Po aktywacji dostęp do ekranu ustawień jest ograniczony, a wyświetlanie na pełnym ekranie jest włączone.",
  "KioskPasscode": "Kod dostępu",
  "KioskPasscodeInfo": "Ustaw kod dostępu do tymczasowego odblokowania trybu kiosku. Przytrzymaj klawisz Esc lub dotknij 5 razy z rzędu w prawym górnym rogu ekranu, aby wyświetlić ekran wprowadzania kodu.",
  "KioskPasscodeValidation": "Ustaw co najmniej 4 znaki alfanumeryczne",
  "KioskPasscodeInvalid": "Nieprawidłowy kod dostępu. Wprowadź co najmniej 4 znaki alfanumeryczne.",
  "KioskMaxInputLength": "Maksymalna długość danych wejściowych",
  "KioskMaxInputLengthInfo": "Ogranicza maksymalną liczbę znaków danych wejściowych użytkownika (od {{min}} do {{max}} znaków).",
  "KioskNgWordEnabled": "Filtr zabronionych słów",
  "KioskNgWordEnabledInfo": "Blokuje wysyłanie danych wejściowych użytkownika zawierających zabronione słowa i wyświetla komunikat o błędzie.",
  "KioskNgWords": "Lista zabronionych słów",
  "KioskNgWordsInfo": "Wprowadź zabronione słowa oddzielone przecinkami. Bez rozróżniania wielkości liter, częściowe dopasowanie.",
  "KioskNgWordsPlaceholder": "np.: przemoc, dyskryminacja, nieodpowiednie",
  "Characters": "znaków",
  "DemoModeNotice": "Ta funkcja nie jest dostępna w wersji demonstracyjnej",
  "DemoModeLocalTTSNotice": "TTS z lokalnymi serwerami nie jest dostępny w wersji demonstracyjnej",
  "MemoryRestoreExecute": "Wykonaj przywracanie"
}
