{
  "Description": "O aplikacji",
  "BasedSettings": "Ustawienia podstawowe",
  "AISettings": "Ustawienia AI",
  "CharacterSettings": "Ustawienia postaci",
  "YoutubeSettings": "Ustawienia YouTube",
  "VoiceSettings": "Ustawienia syntezatora mowy",
  "SlideSettings": "Ustawienia slajdów",
  "LogSettings": "Historia rozmów",
  "OtherSettings": "Inne",
  "ExternalLinkageMode": "Tryb integracji zewnętrznej (wersja beta)",
  "YoutubeMode": "Tryb YouTube",
  "YoutubeInfo": "Komentarze zaczynające się od „#” są ignorowane.",
  "YoutubeAPIKey": "Klucz API YouTube",
  "YoutubeLiveID": "ID YouTube Live",
  "ConversationContinuityMode": "Tryb kontynuacji rozmowy (beta)",
  "ConversationContinuityModeInfo": "Tryb, w którym AI automatycznie kontynuuje rozmowę, gdy brak komentarzy. Obecnie obsługiwane są tylko: OpenAI, Anthropic Claude, Google Gemini.",
  "ConversationContinuityModeInfo2": "Ponieważ w jednej odpowiedzi wywoływane są wielokrotnie LLM, może to zwiększyć koszty API. Proszę uważać.",
  "ConversationContinuityModeInfo3": "Działa stosunkowo stabilnie z modelami gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "MaxPastMessages": "Liczba przechowywanych poprzednich wiadomości",
  "StatusOn": "Stan: ON",
  "StatusOff": "Stan: WYŁĄCZONY",
  "Select": "Proszę wybrać",
  "TestVoice": "Przetestuj głos",
  "SelectAIService": "Wybierz usługę AI",
  "LocalLLM": "Lokalny LLM",
  "SelectModel": "Wybierz model",
  "OpenAIAPIKeyLabel": "Klucz API OpenAI",
  "AnthropicAPIKeyLabel": "Klucz API Anthropic",
  "GoogleAPIKeyLabel": "Klucz API Google Gemini",
  "AzureAPIKeyLabel": "Klucz API Azure OpenAI",
  "AzureAPIURL": "URL Azure OpenAI API",
  "GroqAPIKeyLabel": "Klucz API Groq",
  "CohereAPIKeyLabel": "Klucz API Cohere",
  "MistralAIAPIKeyLabel": "Klucz API MistralAI",
  "PerplexityAPIKeyLabel": "Klucz API Perplexity",
  "FireworksAPIKeyLabel": "Klucz API Fireworks",
  "DifyAPIKeyLabel": "Klucz API Dify",
  "DeepSeekAPIKeyLabel": "Klucz API DeepSeek",
  "APIKeyInstruction": "Klucz API można uzyskać za pomocą poniższego linku. Wprowadź uzyskany klucz API do formularza.",
  "LocalLLMInfo": "Należy uruchomić serwer lokalnego LLM.",
  "LocalLLMInfo2": "Wprowadź URL lokalnego LLM (wraz z numerem portu) oraz nazwę modelu.",
  "GroqInfo": "Groq API jest dostępne bezpośrednio przez przeglądarkę.",
  "DifyInfo": "W Dify obsługiwane są tylko chatboty lub typy agentów.",
  "DifyInfo2": "Długość historii rozmów zależy od ustawień chatbota Dify.",
  "DifyInfo3": "Przykład: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Jeśli korzystasz z Dify, ten systemowy prompt nie będzie używany. Ustaw go w chatbotie Dify.",
  "EnterURL": "Wprowadź URL",
  "CharacterModelLabel": "Model postaci",
  "CharacterModelInfo": "W zależności od modelu, ładowanie przy pierwszym wyświetleniu może zająć trochę czasu.",
  "OpenVRM": "Otwórz VRM",
  "BackgroundImage": "Obraz tła",
  "ChangeBackgroundImage": "Zmień obraz tła",
  "CharacterSettingsPrompt": "Prompt postaci",
  "CharacterSettingsInfo": "Ta wartość jest ustawiana jako systemowy prompt.\nBazując na początkowym promptcie, możesz określić tagi emocji, aby kontrolować wyraz twarzy i ruchy postaci. Przykład: [neutral] Dzień dobry! [happy] Miłego dnia!",
  "characterpresetInfo": "Wybranie ustawienia wstępnego powoduje zmianę podpowiedzi znaków.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) dla skrótów.\nWybranie ustawienia wstępnego przy jednoczesnym przytrzymaniu klawisza Shift powoduje zapisanie bieżącego znaku zachęty w ustawieniu wstępnym.",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Wybór silnika syntezatora mowy",
  "VoiceAdjustment": "Dostosowanie głosu",
  "VoiceEngineInstruction": "Wybierz silnik syntezatora mowy, którego chcesz używać.",
  "UsingKoeiromap": "Użyj Koeiromap",
  "KoeiromapInfo": "Używa API Koeiromap firmy Koemotion. Obsługuje tylko język japoński. Szczegóły znajdziesz poniżej.",
  "UsingVoiceVox": "Użyj VOICEVOX",
  "VoiceVoxInfo": "Używa VOICEVOX. Obsługuje tylko język japoński. Ponieważ korzysta z lokalnego API, musisz pobrać aplikację odpowiednią dla Twojego środowiska ze strony poniżej i ją uruchomić.",
  "VoicevoxSpeed": "Szybkość mówienia",
  "VoicevoxPitch": "Wysokość dźwięku",
  "VoicevoxIntonation": "Intonacja",
  "VoicevoxServerUrl": "URL serwera VOICEVOX",
  "UsingAivisSpeech": "Użyj AivisSpeech",
  "AivisSpeechInfo": "Używa AivisSpeech. Obsługuje tylko język japoński. Ponieważ korzysta z lokalnego API, musisz pobrać aplikację odpowiednią dla Twojego środowiska ze strony poniżej i ją uruchomić.",
  "AivisSpeechSpeaker": "Lektor",
  "AivisSpeechSpeed": "Szybkość mówienia",
  "AivisSpeechPitch": "Wysokość dźwięku",
  "AivisSpeechIntonation": "Intonacja",
  "AivisSpeechServerUrl": "URL serwera AivisSpeech",
  "UsingNijiVoice": "Użyj NijiVoice",
  "NijiVoiceInfo": "Używa API NijiVoice. Obsługuje tylko język japoński. Uzyskaj klucz API z poniższego URL.",
  "NijiVoiceApiKey": "Klucz API NijiVoice",
  "NijiVoiceActorId": "ID mówcy",
  "NijiVoiceSpeed": "Szybkość mówienia",
  "NijiVoiceEmotionalLevel": "Poziom emocji",
  "NijiVoiceSoundDuration": "Długość dźwięku",
  "UpdateSpeakerList": "Aktualizuj listę mówców",
  "UsingGoogleTTS": "Użyj Google Text-to-Speech",
  "UsingStyleBertVITS2": "Użyj Style-Bert-VITS2",
  "StyleBertVITS2Info": "Używa Style-Bert-VITS2. Obsługuje tylko japoński, angielski i chiński. Jeśli korzystasz z lokalnego API, musisz pobrać i uruchomić aplikację odpowiednią dla Twojego środowiska ze strony poniżej. W razie potrzeby ustaw także klucz API.",
  "SpeakerSelection": "Wybór typu głosu",
  "EnglishToJapanese": "Czytaj angielskie słowa po japońsku",
  "IncludeTimestampInUserMessage": "Dołącz znacznik czasu do wypowiedzi użytkownika",
  "IncludeTimestampInUserMessageInfo": "Dołączenie znacznika czasu do wypowiedzi użytkownika umożliwia AI uwzględnienie czasu przy generowaniu odpowiedzi.\nProszę dołączyć następujący tekst do systemowego prompta:\n\n„W niektórych przypadkach wejście użytkownika będzie zawierać [timestamp]. Oznacza to, że podany czas reprezentuje czas UTC w momencie żądania, więc wygeneruj odpowiedź, uwzględniając ten czas.”",
  "GoogleTTSInfo": "Używa Google Cloud Text-to-Speech. Obsługuje wiele języków.",
  "AuthFileInstruction": "Wymagany jest klucz API lub plik JSON do autoryzacji. Pobierz go z poniższego linku i, w przypadku pliku JSON, umieść go w katalogu głównym repozytorium jako credentials.json.",
  "LanguageModelURL": "Wybierz model językowy z poniższego URL.",
  "LanguageChoice": "Wybór języka",
  "StyleBeatVITS2ServerURL": "URL serwera",
  "StyleBeatVITS2ApiKey": "Klucz API",
  "StyleBeatVITS2ModelID": "ID modelu",
  "StyleBeatVITS2Style": "Styl",
  "StyleBeatVITS2SdpRatio": "Stosunek SDP/DP",
  "StyleBeatVITS2Length": "Prędkość mówienia",
  "ConversationHistory": "Historia rozmów",
  "ConversationHistoryInfo": "Ostatnie {{count}} rozmów będą przechowywane jako pamięć.",
  "ConversationHistoryReset": "Resetuj historię rozmów",
  "NotConnectedToExternalAssistant": "Nie połączono z zewnętrznym asystentem.",
  "APIKeyNotEntered": "Klucz API nie został wprowadzony.",
  "ChatLog": "Log rozmów",
  "EnterYourQuestion": "Wpisz swoje pytanie",
  "AnswerGenerating": "Generowanie odpowiedzi",
  "AboutThisApplication": "O tej aplikacji",
  "AboutThisApplicationDescription": "Dzięki tej aplikacji możesz rozmawiać z 3D postacią wyłącznie za pomocą przeglądarki internetowej, korzystając z mikrofonu, wprowadzania tekstu i syntezy mowy. Możesz również zmienić postać (VRM), ustawić jej osobowość oraz dostosować głos. <br /> Ustawienia można zmienić poprzez przycisk menu w lewym górnym rogu.",
  "AboutThisApplicationDescription2": "AITuberKit umożliwia rozmowę z postacią AI wyłącznie za pomocą przeglądarki. Aby zmienić postać, ustawić jej osobowość lub dostosować głos, sprawdź odpowiednie ustawienia.",
  "TechnologyIntroduction": "Wprowadzenie do technologii",
  "TechnologyIntroductionDescription1": "Ta aplikacja została stworzona na podstawie zmodyfikowanej wersji <b>ChatVRM</b> firmy pixiv. Oryginalny kod źródłowy jest dostępny",
  "TechnologyIntroductionLink1": "tutaj",
  "TechnologyIntroductionDescription2": "proszę zapoznać się z nim.",
  "TechnologyIntroductionDescription3": "Do wyświetlania i obsługi modeli 3D używane są",
  "TechnologyIntroductionDescription4": ", a do generowania treści rozmów używane są",
  "TechnologyIntroductionDescription5": "różne modele LLM, a do syntezy mowy",
  "TechnologyIntroductionDescription6": "wykorzystuje się różne systemy TTS. Szczegóły znajdziesz w",
  "TechnologyIntroductionLink2": "artykule wyjaśniającym",
  "TechnologyIntroductionDescription7": "zapoznaj się z nim.",
  "SourceCodeDescription1": "Kod źródłowy tej aplikacji jest udostępniony na GitHubie. Można go dowolnie modyfikować i zmieniać.",
  "SourceCodeDescription2": "W sprawach komercyjnego wykorzystania, proszę zapoznać się z README w tym repozytorium.",
  "RepositoryURL": "URL repozytorium:",
  "DontShowIntroductionNextTime": "Nie pokazuj tego dialogu przy następnym uruchomieniu",
  "Close": "Zamknij",
  "Contact": "Kontakt",
  "ContactDescription": "W przypadku pytań dotyczących tej aplikacji proszę kontaktować się za pomocą poniższego adresu e-mail lub konta na Twitterze.",
  "Creator": "Informacje o twórcy",
  "CreatorDescription": "Twórca: Nike",
  "Language": "Ustawienia języka",
  "UsingGSVITTS": "Użyj GSVI TTS",
  "GSVITTSInfo": "Ustawienia GSVI TTS",
  "GSVITTSServerUrl": "URL serwera GSVI TTS",
  "GSVITTSModelID": "ID modelu GSVI TTS",
  "GSVITTSBatchSize": "Rozmiar partii GSVI TTS (1 ~ 100; większa wartość przyspiesza inferencję, ale zbyt duża może spowodować wyczerpanie pamięci)",
  "GSVITTSSpeechRate": "Szybkość mówienia (0.5 ~ 2.0; większa wartość oznacza szybsze tempo)",
  "UsingElevenLabs": "Użyj ElevenLabs",
  "ElevenLabsInfo": "Używa API ElevenLabs. Obsługuje wiele języków. Uzyskaj klucz API z poniższego URL.",
  "ElevenLabsApiKey": "Klucz API ElevenLabs",
  "ElevenLabsVoiceId": "ID głosu ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Wybierz ID głosu z poniższego URL.",
  "CharacterName": "Nazwa postaci",
  "ShowAssistantText": "Pokaż pole odpowiedzi",
  "ShowCharacterName": "Pokaż nazwę postaci w polu odpowiedzi",
  "ShowControlPanel": "Pokaż panel sterowania",
  "ShowControlPanelInfo": "Ekran ustawień można wyświetlić za pomocą Cmd + . (Mac) / Ctrl + . (Windows).\nW przypadku korzystania z telefonu komórkowego można to również zrobić, przytrzymując lewy górny róg ekranu przez około 1 sekundę.",
  "SlideMode": "Tryb slajdów",
  "SelectedSlideDocs": "Wybrane slajdy",
  "SlideModeDescription": "Tryb, w którym AI automatycznie prezentuje slajdy. Aktywny tylko, gdy wybrana usługa AI to OpenAI, Anthropic Claude lub Google Gemini.",
  "PdfConvertLabel": "Konwersja PDF do slajdów",
  "PdfConvertDescription": "Konwertuje PDF do danych używanych w trybie slajdów. Dostępne tylko, gdy wybrana usługa AI to OpenAI, Anthropic Claude lub Google Gemini.",
  "PdfConvertFileUpload": "Wybierz plik PDF",
  "PdfConvertFolderName": "Nazwa folderu do zapisu",
  "PdfConvertModelSelect": "Wybierz model",
  "PdfConvertButton": "Konwertuj PDF do slajdów",
  "PdfConvertLoading": "Konwertowanie...",
  "PdfConvertSuccess": "Konwersja zakończona pomyślnie",
  "PdfConvertError": "Konwersja nie powiodła się",
  "PdfConvertSubmitError": "Sprawdź, czy plik PDF, nazwa folderu i klucz API zostały ustawione.",
  "LocalStorageReset": "Resetuj ustawienia",
  "LocalStorageResetInfo": "Jeśli zmienne środowiskowe są ustawione, mają pierwszeństwo. Strona zostanie przeładowana.",
  "LocalStorageResetButton": "Resetuj ustawienia",
  "Errors": {
    "EmptyAPIKey": "Nie ustawiono klucza API",
    "AIInvalidProperty": "Nieprawidłowe wartości ustawień usługi AI",
    "AIAPIError": "Wystąpił błąd podczas wykonywania API AI",
    "InvalidAIService": "Wybrana usługa AI jest nieprawidłowa",
    "MethodNotAllowed": "Żądanie jest nieprawidłowe",
    "TTSServiceError": "W usłudze TTS {{serviceName}} wystąpił błąd: {{message}}",
    "UnexpectedError": "Wystąpił nieznany błąd",
    "LocalLLMError": "Wystąpił błąd w lokalnym LLM",
    "LocalLLMStreamError": "Wystąpił błąd podczas przetwarzania strumienia lokalnego LLM",
    "LocalLLMConnectionError": "Nie można połączyć się z serwerem lokalnego LLM",
    "LocalLLMNotFound": "Nie znaleziono punktu końcowego lokalnego LLM",
    "LocalLLMAPIError": "Wystąpił błąd w API lokalnego LLM",
    "EmptyLocalLLMURL": "URL lokalnego LLM nie jest ustawiony",
    "CustomAPIError": "Wystąpił błąd w niestandardowym API",
    "InvalidJSON": "Format JSON jest nieprawidłowy"
  },
  "MessageReceiver": "Przyjmowanie poleceń z zewnątrz",
  "MessageReceiverDescription": "Za pomocą API można sterować wypowiedziami postaci AI z zewnątrz.",
  "ClientID": "ID klienta",
  "OpenSendMessagePage": "Otwórz stronę wysyłania wiadomości",
  "RealtimeAPIMode": "Tryb API w czasie rzeczywistym",
  "RealtimeAPIModeContentType": "Typ wysyłki",
  "RealtimeAPIModeVoice": "Typ głosu",
  "AudioMode": "Tryb audio",
  "InputText": "Tekst",
  "InputAudio": "Audio",
  "SearchGrounding": "Użyj funkcji wyszukiwania",
  "SearchGroundingDescription": "Gdy korzystasz z funkcji multimodalnych, funkcja wyszukiwania zostaje automatycznie wyłączona.",
  "UpdateRealtimeAPISettings": "Aktualizuj ustawienia API w czasie rzeczywistym",
  "UpdateRealtimeAPISettingsInfo": "Po zaktualizowaniu klucza API, Azure Endpoint, typu głosu, modelu lub systemowego prompta, naciśnij przycisk aktualizacji, aby rozpocząć nową sesję WebSocket.",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "Wystąpił błąd połączenia WebSocket.",
    "WebSocketConnectionClosed": "Połączenie WebSocket zostało zamknięte",
    "WebSocketConnectionAttempt": "Próba połączenia WebSocket...",
    "WebSocketConnectionSuccess": "Połączenie WebSocket zakończone sukcesem.",
    "FunctionExecuting": "Wykonywanie {{funcName}}.",
    "FunctionExecutionFailed": "Wykonanie {{funcName}} nie powiodło się.",
    "FirefoxNotSupported": "Ta funkcja nie jest obsługiwana w Firefoxie",
    "SpeechRecognitionError": "Wystąpił błąd rozpoznawania mowy",
    "PresetSwitching": "Przełączono na {{presetName}}.",
    "WhisperError": "Wystąpił błąd w rozpoznawaniu mowy przez Whisper"
  },
  "UsingOpenAITTS": "Użyj OpenAI",
  "OpenAITTSInfo": "Używa OpenAI. Obsługuje wiele języków. Jeśli wybrano OpenAI jako usługę AI, nie ma potrzeby ustawiania klucza API poniżej.",
  "OpenAITTSVoice": "Typ głosu",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Szybkość mówienia",
  "UsingAzureTTS": "Użyj Azure OpenAI",
  "AzureTTSInfo": "Używa Azure OpenAI. Obsługuje wiele języków.",
  "SendMessage": {
    "title": "Adapter zewnętrzny AITuberKit",
    "directSendTitle": "Pozwól postaci AI mówić bezpośrednio",
    "directSendDescription": "Wysłane wiadomości zostaną bezpośrednio wypowiedziane przez postać AI. W przypadku wielu wiadomości będą przetwarzane kolejno.\nUżywany jest model głosu wybrany w ustawieniach AITuberKit.",
    "aiGenerateTitle": "Pozwól AI wygenerować odpowiedź, a następnie wypowiedzieć ją",
    "aiGenerateDescription": "AI wygeneruje odpowiedź na podstawie wysłanej wiadomości, a następnie postać AI ją wypowie. W przypadku wielu wiadomości będą przetwarzane kolejno.\nUżywane są modele AI i głosu wybrane w ustawieniach AITuberKit.\nMożesz wybrać, czy używać systemowego prompta AITuberKit, czy niestandardowego prompta.\nJeśli chcesz załadować historię rozmów, dołącz do systemowego prompta lub dowolnej pozycji wiadomości użytkownika ciąg znaków [conversation_history].",
    "useCurrentSystemPrompt": "Użyj systemowego prompta AITuberKit",
    "userInputTitle": "Wyślij dane wejściowe użytkownika",
    "userInputDescription": "Wysłane wiadomości są przetwarzane tak samo, jak gdyby zostały wprowadzone w formularzu AITuberKit. W przypadku wielu wiadomości będą przetwarzane kolejno.\nUżywane są modele AI i głosu wybrane w ustawieniach AITuberKit.\nSystemowy prompt oraz historia rozmów są ustawiane zgodnie z wartościami AITuberKit."
  },
  "CannotUseVoice": "W przypadku włączonego trybu API w czasie rzeczywistym lub trybu audio,\nustawienia syntezatora mowy są zbędne.",
  "Live2D": {
    "FileInfo": "Umieść folder z modelem Live2D, którego chcesz użyć, w katalogu public/live2d. W katalogu tym musi znajdować się plik model3.json.\nJeśli nie pojawi się w opcjach, odśwież stronę lub upewnij się, że ścieżka do folderu jest poprawna.",
    "Info": "Możesz określić emocje i ruchy.\nKażda emocja jest kontrolowana przez prompt. Szczegóły znajdziesz w „Ustawieniach AI => Ustawienia postaci”.",
    "Emotions": "Ustawienia wyrazu twarzy",
    "EmotionInfo": "Emocje można określić jako wiele, oddzielonych przecinkami. Jeśli podasz wiele, będą wybierane losowo.\nWartości początkowe odpowiadają modelom dostarczonym przez AITuberKit. Jeśli używasz własnego modelu, wprowadź odpowiednie wartości.\nPo zakończeniu rozmowy wyświetlany będzie wyraz „normalny”.",
    "neutralEmotions": "Normalny",
    "happyEmotions": "Szczęśliwy",
    "sadEmotions": "Smutny",
    "angryEmotions": "Zły",
    "relaxedEmotions": "Zrelaksowany",
    "MotionGroups": "Ustawienia grup ruchów",
    "MotionGroupsInfo": "Grupy ruchów będą wybierane losowo z wybranej grupy.\nPodobnie jak ustawienia wyrazu twarzy, dostosuj je do swojego modelu.\n„Podczas bezczynności” to ruch wyświetlany po zakończeniu rozmowy.",
    "SelectMotionGroup": "Wybierz grupę ruchów",
    "idleMotionGroup": "Podczas bezczynności",
    "neutralMotionGroup": "Normalny",
    "happyMotionGroup": "Szczęśliwy",
    "sadMotionGroup": "Smutny",
    "angryMotionGroup": "Zły",
    "relaxedMotionGroup": "Zrelaksowany",
    "surprisedEmotions": "Zaskoczenie",
    "surprisedMotionGroup": "Zaskoczenie"
  },
  "UseVideoAsBackground": "Użyj ekranu udostępniania lub kamery internetowej jako tła",
  "Temperature": "Temperatura",
  "MaxTokens": "Maksymalna liczba tokenów",
  "MaxTokensInfo": "Maksymalna liczba tokenów różni się w zależności od używanego modelu AI. Sprawdź specyfikacje każdego modelu.",
  "CannotUseParameters": "W przypadku włączonego trybu API w czasie rzeczywistym lub trybu audio, parametry Temperature i Max Tokens nie mogą być określone.",
  "DocumentationDescription": "Szczegółowe instrukcje i samouczki dotyczące AITuberKit można znaleźć pod poniższym adresem URL.",
  "PresetQuestions": "Wstępnie ustawione pytania",
  "PresetQuestionsInfo": "Możesz wcześniej stworzyć i zarejestrować wiele wzorców pytań. Zarejestrowane pytania będą wyświetlane w formie przycisków na interfejsie użytkownika, a po kliknięciu zostaną ustawione w polu wejściowym czatu.",
  "EnterPresetQuestion": "Proszę wpisać pytanie",
  "DragToReorder": "Przeciągnij, aby zmienić kolejność",
  "ShowSilenceProgressBar": "Wyświetl pasek postępu wykrywania ciszy",
  "CharacterpresetInfo": "Wybierając preset, zmieniasz prompt postaci.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) umożliwia skróty.",
  "SpeechInputSettings": "Ustawienia wejścia głosowego",
  "SpeechRecognitionMode": "Tryb rozpoznawania mowy",
  "SpeechRecognitionModeInfo": "Możesz wybrać tryb rozpoznawania mowy.\n\"Standard przeglądarki\" używa wbudowanego rozpoznawania mowy w przeglądarce. \"OpenAI TTS\" używa API Text to Speech OpenAI.\nOgólnie rzecz biorąc, \"Standard przeglądarki\" ma wyższą dokładność i szybszą prędkość rozpoznawania, dlatego jest zalecany. Jeśli jednak korzystasz z przeglądarki, która nie obsługuje WebSpeech API, takiej jak Firefox, wybierz \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Użyj standardowego rozpoznawania mowy w przeglądarce",
  "WhisperSpeechRecognition": "Użyj rozpoznawania mowy OpenAI TTS",
  "WhisperAPIKeyInfo": "Tryb Whisper wymaga klucza API OpenAI. Proszę skonfigurować klucz API OpenAI w ustawieniach AI.",
  "WhisperTranscriptionModel": "Model transkrypcji",
  "WhisperTranscriptionModelInfo": "Możesz wybrać model używany do rozpoznawania mowy. Modele o wyższej wydajności są bardziej dokładne, ale mogą wiązać się z wyższymi kosztami API.",
  "InitialSpeechTimeout": "Limit czasu rozpoznawania mowy",
  "InitialSpeechTimeoutInfo": "Ustawia czas oczekiwania na wykrycie pierwszej wypowiedzi po rozpoczęciu rozpoznawania mowy. Jeśli w tym czasie nie zostanie wykryta wypowiedź, rozpoznawanie mowy automatycznie się zatrzyma.\nUstawienie na 0 sekund spowoduje, że czas oczekiwania będzie nieograniczony.",
  "Milliseconds": "Milisekundy",
  "ContinuousMic": "Ciągłe wejście mikrofonowe",
  "ContinuousMicActive": "Ciągłe wejście mikrofonowe aktywne",
  "ContinuousMicModeOn": "Tryb ciągłego wejścia mikrofonowego jest włączony",
  "ContinuousMicModeOff": "Tryb ciągłego wejścia mikrofonowego jest wyłączony",
  "ListeningContinuously": "Oczekiwanie na wejście głosowe...",
  "ContinuousMicInfo": "Mikrofon automatycznie wznowi wejście, gdy AI zakończy wypowiedź. Po upływie ustawionego czasu ciszy automatycznie wyśle.\nJeśli czas przekroczy ustawiony czas bez rozpoznawania mowy, ciągłe wejście mikrofonowe automatycznie wyłączy się, dlatego jeśli chcesz, aby było zawsze włączone, ustaw limit czasu rozpoznawania mowy na 0 sekund.",
  "CustomAPIEndpoint": "Niestandardowy punkt końcowy API",
  "CustomAPIEndpointInfo": "Proszę wpisać URL punktu końcowego API, do którego wysyłane są żądania POST.",
  "CustomAPIStream": "Tryb strumieniowy",
  "CustomAPIStreamForced": "Obecnie tryb strumieniowy jest zawsze włączony.",
  "CustomAPIHeaders": "Niestandardowe nagłówki",
  "CustomAPIHeadersInfo": "Proszę wpisać informacje nagłówkowe w formacie JSON, które mają być dołączone do żądania API.",
  "CustomAPIBody": "Niestandardowe ciało",
  "CustomAPIBodyInfo": "Proszę wpisać informacje o ciele w formacie JSON, które mają być dołączone do żądania API. messages będą automatycznie dołączone.",
  "CustomAPIDescription": "Uwaga: Wiadomości są automatycznie dołączane do ciała żądania. W trybie strumieniowym serwer musi zwrócić text/event-stream.",
  "ShowCharacterPresetMenu": "Wyświetl przycisk menu presetów postaci",
  "SpeechRecognitionModeDisabledInfo": "Gdy tryb audio jest włączony, dostępne jest tylko rozpoznawanie mowy w przeglądarce.\nPonadto w trybie API w czasie rzeczywistym dostępne jest tylko rozpoznawanie mowy w przeglądarce, a funkcja limitu czasu rozpoznawania mowy jest wyłączona."
}
