{
  "Description": "关于应用",
  "BasedSettings": "基本设置",
  "AISettings": "AI设置",
  "CharacterSettings": "角色设置",
  "YoutubeSettings": "YouTube设置",
  "VoiceSettings": "合成语音设置",
  "SpeechInputSettings": "语音输入设置",
  "SlideSettings": "幻灯片设置",
  "LogSettings": "对话历史",
  "OtherSettings": "其他",
  "ExternalLinkageMode": "外部链接模式（测试版）",
  "YoutubeMode": "YouTube模式",
  "YoutubeInfo": "以\"#\"开头的评论将被忽略。",
  "YoutubeAPIKey": "YouTube API 密钥",
  "YoutubeLiveID": "YouTube Live ID",
  "ConversationContinuityMode": "对话连续模式（测试版）",
  "ConversationContinuityModeInfo": "这是AI在没有评论时自动尝试继续对话的模式。目前仅支持OpenAI、Anthropic Claude和Google Gemini。",
  "ConversationContinuityModeInfo2": "由于在一次回答中多次调用LLM，API使用费可能会增加。请注意。",
  "ConversationContinuityModeInfo3": "在gpt-4o、gpt-4-turbo、claude-3-opus、claude-3.5-sonnet上运行相对稳定。",
  "MaxPastMessages": "保留过去消息的数量",
  "StatusOn": "状态：开启",
  "StatusOff": "状态：关闭",
  "Select": "请选择",
  "TestVoice": "试听语音",
  "SelectAIService": "选择AI服务",
  "LocalLLM": "本地LLM",
  "SelectModel": "选择模型",
  "OpenAIAPIKeyLabel": "OpenAI API 密钥",
  "AnthropicAPIKeyLabel": "Anthropic API 密钥",
  "GoogleAPIKeyLabel": "Google Gemini API 密钥",
  "AzureAPIKeyLabel": "Azure OpenAI API 密钥",
  "AzureAPIURL": "Azure OpenAI API URL",
  "GroqAPIKeyLabel": "Groq API 密钥",
  "CohereAPIKeyLabel": "Cohere API 密钥",
  "MistralAIAPIKeyLabel": "MistralAI API 密钥",
  "PerplexityAPIKeyLabel": "Perplexity API 密钥",
  "FireworksAPIKeyLabel": "Fireworks API 密钥",
  "DifyAPIKeyLabel": "Dify API 密钥",
  "DeepSeekAPIKeyLabel": "DeepSeek API 密钥",
  "APIKeyInstruction": "可以从以下链接获取API密钥。请将获取的API密钥输入到表单中。",
  "LocalLLMInfo": "需要启动本地LLM服务器。",
  "LocalLLMInfo2": "请输入本地LLM的URL（包括端口号）和模型名称。",
  "GroqInfo": "Groq API直接从浏览器访问。",
  "DifyInfo": "Dify仅支持聊天机器人或代理类型。",
  "DifyInfo2": "对话历史的长度取决于Dify聊天机器人的设置。",
  "DifyInfo3": "例如：https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "使用Dify时，此系统提示不会被使用。请在Dify聊天机器人中设置。",
  "EnterURL": "输入URL",
  "CharacterModelLabel": "角色模型",
  "CharacterModelInfo": "根据模型不同，初始显示时可能需要较长的加载时间。",
  "OpenVRM": "打开VRM",
  "BackgroundImage": "背景图像",
  "ChangeBackgroundImage": "更改背景图像",
  "BackgroundSettings": "背景设置",
  "BackgroundSettingsDescription": "您可以上传并选择应用程序的背景图像。",
  "UploadBackground": "上传背景图像",
  "DefaultBackground": "默认背景",
  "CharacterSettingsPrompt": "角色提示",
  "CharacterSettingsInfo": "此值将设置为系统提示。\n参考初始提示，可以通过指定情感标签来控制角色的表情和动作。例如：[neutral]早上好！[happy]今天辛苦了！",
  "CharacterpresetInfo": "选择预设将更改角色提示。\n可以使用Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows)快捷键。",
  "Characterpreset1": "预设1",
  "Characterpreset2": "预设2",
  "Characterpreset3": "预设3",
  "Characterpreset4": "预设4",
  "Characterpreset5": "预设5",
  "SyntheticVoiceEngineChoice": "选择合成语音引擎",
  "VoiceAdjustment": "语音调整",
  "VoiceEngineInstruction": "请选择要使用的合成语音引擎。",
  "UsingKoeiromap": "使用Koeiromap",
  "KoeiromapInfo": "使用Koemotion的Koeiromap API。仅支持日语。详情请参阅以下内容。",
  "UsingVoiceVox": "使用VOICEVOX",
  "VoiceVoxInfo": "使用VOICEVOX。仅支持日语。使用本地API，因此需要从以下网站下载适合您环境的应用程序并启动。",
  "VoicevoxSpeed": "语速",
  "VoicevoxPitch": "音高",
  "VoicevoxIntonation": "语调",
  "VoicevoxServerUrl": "VOICEVOX 服务器URL",
  "UsingAivisSpeech": "使用AivisSpeech",
  "AivisSpeechInfo": "使用AivisSpeech。仅支持日语。使用本地API，因此需要从以下网站下载适合您环境的应用程序并启动。",
  "AivisSpeechSpeaker": "说话者",
  "AivisSpeechSpeed": "语速",
  "AivisSpeechPitch": "音高",
  "AivisSpeechIntonation": "语调",
  "AivisSpeechServerUrl": "AivisSpeech 服务器URL",
  "UsingNijiVoice": "使用NijiVoice",
  "NijiVoiceInfo": "使用NijiVoice API。仅支持日语。请从以下URL获取API密钥。",
  "NijiVoiceApiKey": "NijiVoice API 密钥",
  "NijiVoiceActorId": "说话者ID",
  "NijiVoiceSpeed": "语速",
  "NijiVoiceEmotionalLevel": "情感级别",
  "NijiVoiceSoundDuration": "语音长度",
  "UpdateSpeakerList": "更新说话者列表",
  "UsingGoogleTTS": "使用Google Text-to-Speech",
  "UsingStyleBertVITS2": "使用Style-Bert-VITS2",
  "StyleBertVITS2Info": "使用Style-Bert-VITS2。仅支持日语、英语和中文。使用本地API时，需要从以下网站下载适合您环境的应用程序并启动。如有必要，请设置API密钥。",
  "SpeakerSelection": "选择语音类型",
  "EnglishToJapanese": "用日语朗读英文单词",
  "IncludeTimestampInUserMessage": "在用户消息中包含时间戳",
  "IncludeTimestampInUserMessageInfo": "在用户消息中包含时间戳，使AI能够考虑时间因素生成响应。\n请在系统提示中包含以下内容：\n\n\"用户输入可能带有[timestamp]标记。这表示请求时的UTC时区时间，请考虑该时间生成回答。\"",
  "GoogleTTSInfo": "使用Google Cloud Text-to-Speech。支持多种语言。",
  "AuthFileInstruction": "需要API密钥或认证用的JSON文件。从以下获取，如果是JSON文件，请将其作为credentials.json放置在存储库的根文件夹中。",
  "LanguageModelURL": "请从以下URL选择语言模型。",
  "LanguageChoice": "语言选择",
  "StyleBeatVITS2ServerURL": "服务器URL",
  "StyleBeatVITS2ApiKey": "API 密钥",
  "StyleBeatVITS2ModelID": "模型ID",
  "StyleBeatVITS2Style": "风格",
  "StyleBeatVITS2SdpRatio": "SDP/DP混合比",
  "StyleBeatVITS2Length": "语速",
  "ConversationHistory": "对话历史",
  "ConversationHistoryInfo": "最近的{{count}}条对话将作为记忆保留。",
  "ConversationHistoryReset": "重置对话历史",
  "NotConnectedToExternalAssistant": "未连接到外部助手。",
  "APIKeyNotEntered": "未输入API密钥。",
  "ChatLog": "对话日志",
  "EnterYourQuestion": "请输入您想问的问题",
  "AnswerGenerating": "正在生成回答",
  "AboutThisApplication": "关于此应用",
  "AboutThisApplicationDescription": "仅使用网页浏览器就能通过麦克风、文本输入和语音合成与3D角色进行对话。可以更改角色(VRM)、性格设置和语音调整。<br />可以从左上角的菜单按钮更改设置。",
  "AboutThisApplicationDescription2": "在AITuberKit中，您可以仅使用网页浏览器就能享受与AI角色的对话。请查看各设置项目以更改角色、性格设置和语音调整。",
  "TechnologyIntroduction": "技术介绍",
  "TechnologyIntroductionDescription1": "此应用是通过修改pixiv社的<b>ChatVRM</b>创建的。原始源代码请查看",
  "TechnologyIntroductionLink1": "这里",
  "TechnologyIntroductionDescription2": "。",
  "TechnologyIntroductionDescription3": "3D模型的显示和操作使用",
  "TechnologyIntroductionDescription4": "，对话生成使用",
  "TechnologyIntroductionDescription5": "等各种LLM，语音合成使用",
  "TechnologyIntroductionDescription6": "等各种TTS。详情请查看",
  "TechnologyIntroductionLink2": "解释文章",
  "TechnologyIntroductionDescription7": "。",
  "SourceCodeDescription1": "此应用的源代码在GitHub上公开。可以自由更改和修改。",
  "SourceCodeDescription2": "关于商业使用，请查看同一存储库的README。",
  "RepositoryURL": "存储库URL：",
  "DontShowIntroductionNextTime": "下次不显示此对话框",
  "Close": "关闭",
  "Contact": "联系我们",
  "ContactDescription": "关于此应用的咨询，请联系以下电子邮件地址或Twitter账号。",
  "Creator": "创建者信息",
  "CreatorDescription": "创建者：Nike",
  "Documentation": "文档",
  "DocumentationDescription": "有关AITuberKit的详细使用方法和教程，请查看以下URL。",
  "Language": "语言设置",
  "UsingGSVITTS": "使用GSVI TTS",
  "GSVITTSInfo": "GSVI TTS设置",
  "GSVITTSServerUrl": "GSVI TTS服务器URL",
  "GSVITTSModelID": "GSVI TTS 模型ID",
  "GSVITTSBatchSize": "GSVI TTS 批处理大小 (1 ~ 100 数值越大推理速度越快，但过大可能耗尽内存)",
  "GSVITTSSpeechRate": "语速 (0.5 ~ 2.0 数值越大越快)",
  "UsingElevenLabs": "使用ElevenLabs",
  "ElevenLabsInfo": "使用ElevenLabs API。支持多种语言。请从以下URL获取API密钥。",
  "ElevenLabsApiKey": "ElevenLabs API密钥",
  "ElevenLabsVoiceId": "ElevenLabs 语音ID",
  "ElevenLabsVoiceIdInfo": "请从以下URL选择语音ID。",
  "CharacterName": "角色名称",
  "ShowAssistantText": "显示回答栏",
  "ShowCharacterName": "在回答栏中显示角色名称",
  "ShowControlPanel": "显示操作面板",
  "ShowControlPanelInfo": "可以通过Cmd + . (Mac) / Ctrl + . (Windows)显示设置屏幕。\n使用智能手机时，也可以长按屏幕左上角（约1秒）。",
  "ShowCharacterPresetMenu": "显示角色预设菜单按钮",
  "SlideMode": "幻灯片模式",
  "SelectedSlideDocs": "使用的幻灯片",
  "SlideModeDescription": "AI自动展示幻灯片的模式。仅在选择OpenAI、Anthropic Claude或Google Gemini AI服务时有效。",
  "PdfConvertLabel": "PDF幻灯片转换",
  "PdfConvertDescription": "将PDF转换为幻灯片模式数据。仅在选择OpenAI、Anthropic Claude或Google Gemini AI服务时可用。",
  "PdfConvertFileUpload": "选择PDF文件",
  "PdfConvertFolderName": "保存文件夹名称",
  "CustomVoiceTextPlaceholder": "请输入要试听的文本",
  "TestVoiceSettings": "语音测试",
  "TestSelectedVoice": "播放",
  "PdfConvertModelSelect": "选择模型",
  "PdfConvertButton": "将PDF转换为幻灯片",
  "PdfConvertLoading": "转换中...",
  "PdfConvertSuccess": "转换完成",
  "PdfConvertError": "转换失败",
  "PdfConvertSubmitError": "请确认已设置PDF文件、文件夹名称和API密钥",
  "LocalStorageReset": "重置设置",
  "LocalStorageResetInfo": "如果设置了环境变量，其值将优先。页面将重新加载。",
  "LocalStorageResetButton": "重置设置",
  "InitialSpeechTimeout": "语音识别超时",
  "InitialSpeechTimeoutInfo": "设置语音识别开始后，检测到第一次发言前的等待时间。如果在此时间内未检测到发言，语音识别将自动停止。\n设置为0秒时，等待时间无限制。",
  "Milliseconds": "毫秒",
  "NoSpeechTimeout": "无声检测超时",
  "NoSpeechTimeoutInfo": "设置语音输入时，在无声状态持续多长时间后自动结束输入。\n设置为0秒时，将禁用因无声检测而自动发送。",
  "ShowSilenceProgressBar": "显示无声检测进度条",
  "SpeechRecognitionMode": "语音识别模式",
  "SpeechRecognitionModeInfo": "可以选择语音识别模式。\n\"浏览器标准\"使用浏览器内置的语音识别。\"OpenAI TTS\"使用OpenAI的Text to Speech API。\n通常推荐使用\"浏览器标准\"，因为其精度更高，识别速度更快。但是，如果您使用Firefox等不支持WebSpeech API的浏览器，请选择\"OpenAI TTS\"。",
  "BrowserSpeechRecognition": "使用浏览器标准语音识别",
  "WhisperSpeechRecognition": "使用OpenAI TTS语音识别",
  "WhisperTranscriptionModel": "转录模型",
  "WhisperTranscriptionModelInfo": "可以选择用于语音识别的模型。性能更高的模型识别精度更高，但API成本可能更高。",
  "SpeechRecognitionModeDisabledInfo": "当音频模式启用时，只能使用浏览器语音识别。\n此外，在实时API模式下只能使用浏览器语音识别，且语音识别超时功能将被禁用。",
  "Errors": {
    "EmptyAPIKey": "未设置API密钥",
    "EmptyLocalLLMURL": "未设置本地LLM的URL",
    "AIInvalidProperty": "AI服务的设置值不正确",
    "AIAPIError": "执行AI API时发生错误",
    "InvalidAIService": "选择的AI服务不正确",
    "MethodNotAllowed": "请求不适当",
    "TTSServiceError": "{{serviceName}} TTS服务发生错误：{{message}}",
    "UnexpectedError": "发生未知错误",
    "LocalLLMError": "本地LLM发生错误",
    "LocalLLMStreamError": "本地LLM的流处理发生错误",
    "LocalLLMConnectionError": "无法连接到本地LLM服务器",
    "LocalLLMNotFound": "找不到本地LLM的端点",
    "LocalLLMAPIError": "本地LLM API发生错误",
    "CustomAPIError": "自定义API发生错误",
    "InvalidJSON": "JSON格式不正确"
  },
  "MessageReceiver": "接受外部指示",
  "MessageReceiverDescription": "可以使用API从外部指示AI角色的发言。",
  "ClientID": "客户端ID",
  "OpenSendMessagePage": "打开消息发送页面",
  "RealtimeAPIMode": "实时API模式",
  "RealtimeAPIModeContentType": "发送类型",
  "RealtimeAPIModeVoice": "语音类型",
  "AudioMode": "音频模式",
  "InputText": "文本",
  "InputAudio": "语音",
  "SearchGrounding": "使用搜索功能",
  "SearchGroundingDescription": "使用多模态功能时，搜索功能将自动禁用。",
  "UpdateRealtimeAPISettings": "更新实时API设置",
  "UpdateRealtimeAPISettingsInfo": "更新API密钥、Azure端点、语音类型、模型或系统提示后，请按更新按钮启动新的WebSocket会话。",
  "AzureEndpoint": "Azure端点",
  "Toasts": {
    "WebSocketConnectionError": "WebSocket连接发生错误",
    "WebSocketConnectionClosed": "WebSocket连接已关闭",
    "WebSocketConnectionAttempt": "正在尝试WebSocket连接...",
    "WebSocketConnectionSuccess": "WebSocket连接成功",
    "FunctionExecuting": "正在执行{{funcName}}",
    "FunctionExecutionFailed": "{{funcName}}执行失败",
    "FirefoxNotSupported": "Firefox不支持此功能",
    "SpeechRecognitionError": "发生语音识别错误",
    "NoSpeechDetected": "未检测到语音。",
    "PresetSwitching": "已切换到{{presetName}}。",
    "WhisperError": "Whisper语音识别发生错误"
  },
  "ContinuousMic": "持续麦克风输入",
  "ContinuousMicActive": "持续麦克风输入中",
  "ContinuousMicModeOn": "持续麦克风输入模式已开启",
  "ContinuousMicModeOff": "持续麦克风输入模式已关闭",
  "ListeningContinuously": "等待语音输入...",
  "ContinuousMicInfo": "AI发言结束时自动重新开始麦克风输入。设定的无声时间过后自动发送。\n如果在设定时间内未进行语音识别，持续麦克风输入将自动关闭，因此如果希望始终保持开启，请将语音识别超时设置为0秒。",
  "UsingOpenAITTS": "使用OpenAI",
  "OpenAITTSInfo": "使用OpenAI。支持多种语言。如果在AI服务中选择了OpenAI，则无需设置以下API密钥。",
  "OpenAITTSVoice": "语音类型",
  "OpenAITTSModel": "模型",
  "OpenAITTSSpeed": "语速",
  "UsingAzureTTS": "使用Azure OpenAI",
  "AzureTTSInfo": "使用Azure OpenAI。支持多种语言。",
  "SendMessage": {
    "title": "AITuberKit 外部适配器",
    "directSendTitle": "让AI角色直接发言",
    "directSendDescription": "可以让AI角色直接发言您发送的消息。多条消息将按顺序处理。\n将使用AITuberKit设置中选择的语音模型。",
    "aiGenerateTitle": "AI生成回答后让角色发言",
    "aiGenerateDescription": "AI会根据您发送的消息生成回答，并让AI角色发言该回答。多条消息将按顺序处理。\n将使用AITuberKit设置中选择的AI模型和语音模型。\n您可以选择使用AITuberKit的系统提示或自定义系统提示。\n如需加载过去的对话历史，请在系统提示或用户消息的任意位置包含[conversation_history]字符串。",
    "useCurrentSystemPrompt": "使用AITuberKit的系统提示",
    "userInputTitle": "发送用户输入",
    "userInputDescription": "发送的消息将与从AITuberKit的输入表单输入时进行相同的处理。多条消息将按顺序处理。\n将使用AITuberKit设置中选择的AI模型和语音模型。\n将使用AITuberKit的系统提示和对话历史。"
  },
  "CannotUseVoice": "当实时API模式或音频模式启用时，\n不需要合成语音设置。",
  "Live2D": {
    "FileInfo": "请将您想使用的Live2D模型文件夹放在public/live2d目录中。该文件夹下必须直接包含model3.json文件。\n如果选项中未显示，请重新加载页面或检查文件夹路径是否正确。",
    "Info": "可以指定情感和动作。\n各种情感通过提示控制。详情请查看\"AI设置 => 角色设置\"。",
    "Emotions": "表情设置",
    "EmotionInfo": "情感可以用逗号分隔指定多个。指定多个时将随机选择。\n初始值适用于AITuberKit提供的模型。使用原创模型时，请输入适合您模型的值。\n对话完成后将显示\"正常\"表情。",
    "neutralEmotions": "正常",
    "happyEmotions": "高兴",
    "sadEmotions": "悲伤",
    "angryEmotions": "愤怒",
    "relaxedEmotions": "放松",
    "surprisedEmotions": "惊讶",
    "MotionGroups": "动作组设置",
    "MotionGroupsInfo": "动作组将从选定的组中随机选择。\n和表情设置一样，请根据您自己的模型进行设置。\n\"空闲时\"是对话完成后显示的动作。",
    "SelectMotionGroup": "选择动作组",
    "idleMotionGroup": "空闲时",
    "neutralMotionGroup": "正常",
    "happyMotionGroup": "高兴",
    "sadMotionGroup": "悲伤",
    "angryMotionGroup": "愤怒",
    "relaxedMotionGroup": "放松",
    "surprisedMotionGroup": "惊讶"
  },
  "UseVideoAsBackground": "使用共享屏幕或网络摄像头作为背景",
  "Temperature": "温度",
  "MaxTokens": "最大令牌数",
  "MaxTokensInfo": "最大令牌数因使用的AI模型而异。请查看各模型的规格。",
  "CannotUseParameters": "当实时API模式或音频模式启用时，无法指定Temperature和Max Tokens参数。",
  "PresetQuestions": "预设问题",
  "PresetQuestionsInfo": "可以预先创建和注册多个问题模式。注册的问题将在用户UI上以按钮形式显示，点击后将设置到聊天输入栏中。",
  "EnterPresetQuestion": "请输入问题",
  "DragToReorder": "拖动改变顺序",
  "CustomAPIEndpoint": "自定义API端点",
  "CustomAPIEndpointInfo": "请输入要发送POST请求的API端点URL。",
  "CustomAPIStream": "流模式",
  "CustomAPIStreamForced": "目前，流模式始终处于启用状态。",
  "CustomAPIHeaders": "自定义头部",
  "CustomAPIHeadersInfo": "请以JSON格式输入要包含在API请求中的头部信息。",
  "CustomAPIBody": "自定义主体",
  "CustomAPIBodyInfo": "请以JSON格式输入要包含在API请求中的主体信息。messages将自动包含。",
  "CustomAPIDescription": "注意：消息将自动包含在请求主体中。在流模式下，服务器需要返回text/event-stream。"
}
