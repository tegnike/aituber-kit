{
  "Description": "Acerca de la aplicación",
  "BasedSettings": "Configuración básica",
  "AISettings": "Configuración de IA",
  "CharacterSettings": "Configuración de personaje",
  "YoutubeSettings": "Configuración de YouTube",
  "VoiceSettings": "Configuración de voz sintética",
  "SlideSettings": "Configuración de diapositivas",
  "LogSettings": "Historial de conversación",
  "OtherSettings": "Otros",
  "ExternalLinkageMode": "Modo de vinculación externa (versión beta)",
  "YoutubeMode": "Modo YouTube",
  "YoutubeInfo": "El primer carácter del comentario es '#' y será ignorado.",
  "YoutubeAPIKey": "Clave API de YouTube",
  "YoutubeLiveID": "ID en directo de YouTube",
  "ConversationContinuityMode": "Modo de continuidad de conversación (Beta)",
  "ConversationContinuityModeInfo": "Cuando no hay comentarios, la IA intenta continuar la conversación. Actualmente solo compatible con OpenAI, Anthropic Claude y Google Gemini.",
  "ConversationContinuityModeInfo2": "Una respuesta llama a LLM varias veces, por lo que el uso de la API puede aumentar. Por favor, tenga esto en cuenta.",
  "ConversationContinuityModeInfo3": "gpt-4, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet funcionan relativamente estables.",
  "MaxPastMessages": "Número de mensajes anteriores a mantener",
  "StatusOn": "Estado: ACTIVADO",
  "StatusOff": "Estado: DESACTIVADO",
  "Select": "Seleccionar",
  "TestVoice": "Probar voz",
  "SelectAIService": "Seleccionar servicio de IA",
  "LocalLLM": "LLM local",
  "SelectModel": "Seleccionar modelo",
  "OpenAIAPIKeyLabel": "Clave API de OpenAI",
  "AnthropicAPIKeyLabel": "Clave API de Anthropic",
  "GoogleAPIKeyLabel": "Clave API de Google Gemini",
  "AzureAPIKeyLabel": "Clave API de Azure OpenAI",
  "AzureAPIURL": "URL API de Azure OpenAI",
  "GroqAPIKeyLabel": "Clave API de Groq",
  "CohereAPIKeyLabel": "Clave API de Cohere",
  "MistralAIAPIKeyLabel": "Clave API de MistralAI",
  "PerplexityAPIKeyLabel": "Clave API de Perplexity",
  "FireworksAPIKeyLabel": "Clave API de Fireworks",
  "DifyAPIKeyLabel": "Clave API de Dify",
  "DeepSeekAPIKeyLabel": "Clave API de DeepSeek",
  "APIKeyInstruction": "Puede obtener la clave API abajo. Ingrese la clave API obtenida en el formulario.",
  "LocalLLMInfo": "El servidor LLM local debe estar en ejecución. La configuración es la siguiente.",
  "LocalLLMInfo2": "Por favor, ingrese la URL del servidor LLM local (incluyendo el número de puerto) y el nombre del modelo.",
  "GroqInfo": "La API de Groq se accede directamente desde el navegador.",
  "DifyInfo": "Dify solo admite tipos de chatbot y agente.",
  "DifyInfo2": "La longitud del historial de conversación depende de las especificaciones de Dify.",
  "DifyInfo3": "Ejemplo: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Si usa Dify, no se utilizará el prompt del sistema. Por favor, configure el chatbot de Dify.",
  "EnterURL": "URL",
  "CharacterModelLabel": "Modelo de personaje",
  "CharacterModelInfo": "El modelo puede tardar en cargar cuando se muestra por primera vez.",
  "OpenVRM": "Abrir VRM",
  "BackgroundImage": "Imagen de fondo",
  "ChangeBackgroundImage": "Cambiar imagen de fondo",
  "CharacterSettingsPrompt": "Prompt de personaje",
  "CharacterSettingsInfo": "Este valor se establece como el prompt del sistema.\nPor favor, consulte el prompt inicial y especifique las etiquetas de emoción para controlar las expresiones y movimientos del personaje. Ejemplo: [neutral]¡Buenos días![happy]¡Hoy también es un día difícil!",
  "characterpresetInfo": "Al seleccionar un preajuste, cambia la indicación de caracteres.\nCmd + Mayús + 1~5 (Mac) / Ctrl + Mayús + 1~5 (Windows) para los atajos.\nSi se selecciona un preajuste mientras se mantiene pulsada la tecla Mayús, se guarda el carácter actual en el preajuste.",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Elegir motor de síntesis de voz",
  "VoiceAdjustment": "Ajuste de voz",
  "VoiceEngineInstruction": "Seleccione el motor de síntesis de voz que desea usar.",
  "UsingKoeiromap": "Koeiromap",
  "KoeiromapInfo": "Usando API Koeiromap de Koemotion. Solo admite japonés. Para más detalles, consulte el enlace de abajo.",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceVoxInfo": "Usando VOICEVOX. Solo admite japonés. Usa una API local, necesita descargar y ejecutar la aplicación que se adapte a su entorno desde el sitio de abajo.",
  "VoicevoxSpeed": "Velocidad",
  "VoicevoxPitch": "Tono",
  "VoicevoxIntonation": "Entonación",
  "UsingAivisSpeech": "AivisSpeech",
  "AivisSpeechInfo": "Usando AivisSpeech. Solo admite japonés. Usa una API local, necesita descargar y ejecutar la aplicación que se adapte a su entorno desde el sitio de abajo.",
  "AivisSpeechSpeaker": "Hablante",
  "AivisSpeechSpeed": "Velocidad",
  "AivisSpeechPitch": "Tono",
  "AivisSpeechIntonation": "Entonación",
  "AivisSpeechServerUrl": "URL del servidor AivisSpeech",
  "UsingNijiVoice": "NijiVoice",
  "NijiVoiceInfo": "Se usa la API de NijiVoice. Solo admite japonés. La clave API se puede obtener desde la URL de abajo.",
  "NijiVoiceApiKey": "Clave API de NijiVoice",
  "NijiVoiceActorId": "ID del actor",
  "NijiVoiceSpeed": "Velocidad del habla",
  "NijiVoiceEmotionalLevel": "Nivel emocional",
  "NijiVoiceSoundDuration": "Duración del sonido",
  "VoicevoxServerUrl": "URL del servidor VOICEVOX",
  "UpdateSpeakerList": "Actualizar lista de hablantes",
  "UsingGoogleTTS": "Usar Google Text-to-Speech",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "StyleBertVITS2Info": "Usando Style-Bert-VITS2. Solo admite japonés, inglés y chino. Si usa una API local, necesita descargar y ejecutar la aplicación que se adapte a su entorno desde el sitio de abajo. También configure una clave API si es necesario.",
  "SpeakerSelection": "Selección de hablante",
  "IncludeTimestampInUserMessage": "Incluir marca de tiempo en el mensaje del usuario",
  "IncludeTimestampInUserMessageInfo": "Al incluir marcas de tiempo en los mensajes del usuario, la IA puede generar respuestas considerando el tiempo.\nPor favor, incluya el siguiente texto en su prompt del sistema:\n\n\"La entrada del usuario puede incluir [timestamp]. Esto representa la hora UTC en el momento de la solicitud, así que por favor genere respuestas considerando esta marca de tiempo.\"",
  "GoogleTTSInfo": "Usando Google Cloud Text-to-Speech. Admite múltiples idiomas.",
  "AuthFileInstruction": "Se requiere una clave API o archivo de autenticación. Obténgalo desde la URL de abajo y colóquelo en la carpeta raíz del repositorio si es un archivo JSON.",
  "LanguageModelURL": "Seleccione el modelo de idioma desde la URL de abajo.",
  "LanguageChoice": "Elección de idioma",
  "StyleBeatVITS2ServerURL": "URL del servidor",
  "StyleBeatVITS2ApiKey": "Clave API",
  "StyleBeatVITS2ModelID": "ID del modelo",
  "StyleBeatVITS2Style": "Estilo",
  "StyleBeatVITS2SdpRatio": "Ratio de mezcla SDP/DP",
  "StyleBeatVITS2Length": "Velocidad del habla",
  "ConversationHistory": "Historial de conversación",
  "ConversationHistoryInfo": "Se recordarán las últimas {{count}} conversaciones.",
  "ConversationHistoryReset": "Restablecer historial de conversación",
  "NotConnectedToExternalAssistant": "No conectado a un asistente externo.",
  "APIKeyNotEntered": "No se ha ingresado la clave API.",
  "ChatLog": "Registro de conversación",
  "EnterYourQuestion": "Ingrese su pregunta aquí",
  "AnswerGenerating": "Generando respuesta",
  "AboutThisApplication": "Acerca de esta aplicación",
  "AboutThisApplicationDescription": "Disfrute de conversaciones con un personaje 3D directamente en su navegador web, usando micrófono o entrada de texto y síntesis de voz. También puede cambiar el personaje (VRM), ajustar su personalidad y modificar su voz.<br />La configuración se puede cambiar desde el botón de menú en la parte superior izquierda.",
  "AboutThisApplicationDescription2": "Si desea cambiar el personaje, consulte la pestaña \"Configuración de personaje\".",
  "TechnologyIntroduction": "Introducción a la tecnología",
  "TechnologyIntroductionDescription1": "Esta aplicación fue creada modificando el <b>ChatVRM</b> de pixiv. El código fuente original se puede encontrar",
  "TechnologyIntroductionLink1": "aquí",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Para mostrar y manipular modelos 3D,",
  "TechnologyIntroductionDescription4": "se utiliza. Para generar texto de conversación, se utilizan varios LLM como",
  "TechnologyIntroductionDescription5": "se utilizan. Para la síntesis de voz, se utilizan varios motores TTS como",
  "TechnologyIntroductionDescription6": "se utilizan. Para más detalles, consulte este",
  "TechnologyIntroductionLink2": "artículo explicativo",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "El código fuente de esta aplicación está disponible públicamente en GitHub. Siéntase libre de modificarlo y adaptarlo como desee.",
  "SourceCodeDescription2": "Para uso comercial, consulte el README del mismo repositorio.",
  "RepositoryURL": "URL del repositorio:",
  "DontShowIntroductionNextTime": "No mostrar este diálogo la próxima vez",
  "Close": "CERRAR",
  "Contact": "Contacto",
  "ContactDescription": "Por favor, contácteme a través del correo electrónico o la cuenta de Twitter de abajo sobre esta aplicación.",
  "Creator": "Creador",
  "CreatorDescription": "Creador: Tegan",
  "Language": "Idioma",
  "UsingGSVITTS": "GSVI TTS",
  "GSVITTSInfo": "Configuración de GSVI TTS",
  "GSVITTSServerUrl": "API endpoint de GSVI TTS",
  "GSVITTSModelID": "ID del modelo GSVI TTS",
  "GSVITTSBatchSize": "Tamaño de lote GSVI TTS (1 ~ 100 Cuanto mayor sea el valor, más rápida será la inferencia, pero puede agotar la memoria si es demasiado grande.)",
  "GSVITTSSpeechRate": "Velocidad del habla (0.5 ~ 2.0 Cuanto mayor sea el valor, más rápido será.)",
  "UsingElevenLabs": "ElevenLabs",
  "ElevenLabsInfo": "Se usa la API de ElevenLabs. Admite múltiples idiomas. La clave API se puede obtener desde la URL de abajo.",
  "ElevenLabsApiKey": "Clave API de ElevenLabs",
  "ElevenLabsVoiceId": "ID de voz de ElevenLabs",
  "ElevenLabsVoiceIdInfo": "El ID de voz se puede seleccionar desde la URL de abajo.",
  "CharacterName": "Nombre del personaje",
  "ShowAssistantText": "Mostrar cuadro de respuesta",
  "ShowCharacterName": "Mostrar nombre del personaje en el cuadro de respuesta",
  "ShowControlPanel": "Mostrar botón de configuración",
  "ShowControlPanelInfo": "La pantalla de configuración se puede mostrar con Cmd + . (Mac) / Ctrl + . (Windows).\nSi está utilizando un teléfono inteligente, también puede hacerlo manteniendo presionado en la esquina superior izquierda de la pantalla (aproximadamente 1 segundo).",
  "SlideMode": "Modo presentación",
  "SelectedSlideDocs": "Documentos de presentación seleccionados",
  "SlideModeDescription": "Este es un modo donde la IA presenta diapositivas automáticamente. Solo está disponible cuando el servicio de IA seleccionado es OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertLabel": "Conversión de diapositivas PDF",
  "PdfConvertDescription": "Convertir PDF a datos de modo presentación. Solo disponible cuando el servicio de IA seleccionado es OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertFileUpload": "Seleccionar archivo PDF",
  "PdfConvertFolderName": "Nombre de la carpeta de guardado",
  "PdfConvertModelSelect": "Seleccionar modelo",
  "PdfConvertButton": "Convertir PDF a diapositivas",
  "PdfConvertLoading": "Convirtiendo...",
  "PdfConvertSuccess": "Conversión completada",
  "PdfConvertError": "Error en la conversión",
  "PdfConvertSubmitError": "Por favor, asegúrese de que el archivo PDF, el nombre de la carpeta y la clave API estén configurados.",
  "LocalStorageReset": "Restablecer configuración",
  "LocalStorageResetInfo": "Las variables de entorno tienen prioridad si están configuradas. La página se recargará.",
  "LocalStorageResetButton": "Restablecer configuración",
  "Errors": {
    "EmptyAPIKey": "La clave API no está configurada",
    "AIInvalidProperty": "La configuración del servicio de IA es incorrecta",
    "AIAPIError": "Ocurrió un error al ejecutar la API de IA",
    "InvalidAIService": "El servicio de IA seleccionado no es válido",
    "MethodNotAllowed": "La solicitud no es apropiada",
    "TTSServiceError": "Ocurrió un error en el servicio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Ocurrió un error inesperado",
    "LocalLLMError": "Error de LLM local",
    "LocalLLMStreamError": "Error de stream de LLM local",
    "LocalLLMConnectionError": "Error de conexión al servidor LLM local",
    "LocalLLMNotFound": "Endpoint de LLM local no encontrado",
    "LocalLLMAPIError": "Error de API de LLM local",
    "EmptyLocalLLMURL": "No se ha configurado la URL del LLM local",
    "CustomAPIError": "Se produjo un error en la API personalizada",
    "InvalidJSON": "El formato JSON no es correcto"
  },
  "MessageReceiver": "Recibir instrucciones desde el exterior",
  "MessageReceiverDescription": "Puede usar la API para hacer que los personajes de IA hablen desde el exterior.",
  "ClientID": "ID de cliente",
  "OpenSendMessagePage": "Abrir página de envío de mensaje",
  "RealtimeAPIMode": "Modo API en tiempo real",
  "RealtimeAPIModeContentType": "Tipo de envío",
  "RealtimeAPIModeVoice": "Tipo de voz",
  "AudioMode": "Modo de audio",
  "InputText": "Texto",
  "InputAudio": "Audio",
  "SearchGrounding": "Usar búsqueda contextual",
  "SearchGroundingDescription": "Al usar la función multimodal, la función de búsqueda se desactiva automáticamente.",
  "UpdateRealtimeAPISettings": "Actualizar configuración de API en tiempo real",
  "UpdateRealtimeAPISettingsInfo": "Al actualizar la clave API, endpoint de Azure, tipo de voz, modelo o prompt del sistema, presione el botón de actualización para iniciar una nueva sesión WebSocket.",
  "AzureEndpoint": "Endpoint de Azure",
  "Toasts": {
    "WebSocketConnectionError": "Error en la conexión WebSocket",
    "WebSocketConnectionClosed": "Conexión WebSocket cerrada",
    "WebSocketConnectionAttempt": "Intentando conexión WebSocket...",
    "WebSocketConnectionSuccess": "Conexión WebSocket exitosa",
    "FunctionExecuting": "Ejecutando {{funcName}}",
    "FunctionExecutionFailed": "La ejecución de {{funcName}} falló",
    "FirefoxNotSupported": "Esta función no está soportada en Firefox",
    "SpeechRecognitionError": "Ocurrió un error de reconocimiento de voz",
    "PresetSwitching": "Se ha cambiado a {{presetName}}.",
    "WhisperError": "Se produjo un error en el reconocimiento de voz por Whisper"
  },
  "UsingOpenAITTS": "Usando OpenAI",
  "OpenAITTSInfo": "Usando OpenAI. Admite múltiples idiomas. Si selecciona OpenAI como servicio de IA, no necesita configurar la clave API abajo.",
  "OpenAITTSVoice": "Tipo de voz",
  "OpenAITTSModel": "Modelo",
  "OpenAITTSSpeed": "Velocidad",
  "UsingAzureTTS": "Usando Azure OpenAI",
  "AzureTTSInfo": "Usando Azure OpenAI. Admite múltiples idiomas.",
  "SendMessage": {
    "title": "Adaptador externo AITuberKit",
    "directSendTitle": "Hablar directamente al personaje de IA",
    "directSendDescription": "Puede enviar el mensaje directamente al personaje de IA. Si se envían múltiples mensajes, se procesan en orden. El modelo de voz es el seleccionado en la configuración de AITuberKit.",
    "aiGenerateTitle": "Generar respuesta de IA y luego hablar",
    "aiGenerateDescription": "La IA genera una respuesta del mensaje enviado y luego la pronuncia. Si se envían múltiples mensajes, se procesan en orden. El modelo de IA y el modelo de voz son los seleccionados en la configuración de AITuberKit. El prompt del sistema puede seleccionarse para usar el prompt del sistema de AITuberKit o un prompt del sistema personalizado. Si desea cargar el historial de conversación anterior, incluya la cadena [conversation_history] en el prompt del sistema o mensaje del usuario.",
    "useCurrentSystemPrompt": "Usar prompt del sistema de AITuberKit",
    "userInputTitle": "Enviar entrada de usuario",
    "userInputDescription": "El mensaje enviado se procesa igual que cuando se ingresa desde el formulario de entrada de AITuberKit. Si se envían múltiples mensajes, se procesan en orden. El modelo de IA y el modelo de voz son los seleccionados en la configuración de AITuberKit. El prompt del sistema y el historial de conversación son los valores configurados en AITuberKit."
  },
  "CannotUseVoice": "Si el modo de API en tiempo real o el modo de audio están habilitados,\nno se necesita la configuración de voz sintética.",
  "Live2D": {
    "FileInfo": "Coloque el modelo Live2D que desea usar en la carpeta public/live2d. El archivo model3.json debe existir en la raíz de esta carpeta.\nSi no se muestra en la selección, por favor recargue la pantalla o verifique si la ruta de la carpeta es correcta.",
    "Info": "Puede especificar emociones y movimientos.\nCada emoción es controlada por el prompt. Para más detalles, consulte \"Configuración de IA => Configuración de personaje\".",
    "Emotions": "Configuración de emociones",
    "EmotionInfo": "Las emociones se pueden especificar en formato separado por comas. Si se especifican múltiples emociones, se seleccionan aleatoriamente.\nEl valor inicial es para el modelo proporcionado por AITuberKit. Si está usando un modelo original, ingrese el valor según su modelo.\nDespués de completar la conversación, se muestra la emoción \"Neutral\".",
    "neutralEmotions": "Neutral",
    "happyEmotions": "Feliz",
    "sadEmotions": "Triste",
    "angryEmotions": "Enojado",
    "relaxedEmotions": "Relajado",
    "MotionGroups": "Configuración de grupos de movimiento",
    "MotionGroupsInfo": "Los grupos de movimiento se seleccionan aleatoriamente del grupo seleccionado.\nIgual que la configuración de emociones, configúrelo según su modelo.\n\"Idle\" es el movimiento mostrado después de completar la conversación.",
    "SelectMotionGroup": "Seleccionar grupo de movimiento",
    "idleMotionGroup": "Inactivo",
    "neutralMotionGroup": "Neutral",
    "happyMotionGroup": "Feliz",
    "sadMotionGroup": "Triste",
    "angryMotionGroup": "Enojado",
    "relaxedMotionGroup": "Relajado",
    "surprisedEmotions": "Sorpresa",
    "surprisedMotionGroup": "Sorpresa"
  },
  "UseVideoAsBackground": "Usar pantalla compartida o webcam como fondo",
  "Temperature": "Temperatura",
  "MaxTokens": "Número máximo de tokens",
  "MaxTokensInfo": "El número máximo de tokens varía según el modelo de IA que esté utilizando. Consulte las especificaciones de cada modelo.",
  "CannotUseParameters": "Si el modo API en tiempo real o el modo de audio están habilitados, no se pueden especificar los parámetros Temperature y Max Tokens.",
  "DocumentationDescription": "Puede ver detalles sobre cómo usar AITuberKit y tutoriales en la siguiente URL.",
  "PresetQuestions": "Preguntas predefinidas",
  "PresetQuestionsInfo": "Puedes crear y registrar múltiples patrones de preguntas por adelantado. Las preguntas registradas se mostrarán en forma de botones en la interfaz de usuario del usuario y se establecerán en el campo de entrada de chat al hacer clic.",
  "EnterPresetQuestion": "Por favor, ingresa una pregunta",
  "DragToReorder": "Arrastra para cambiar el orden",
  "ShowSilenceProgressBar": "Mostrar barra de progreso de detección de silencio",
  "CharacterpresetInfo": "Al seleccionar un preset, se cambiará el prompt del personaje.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) para atajos.",
  "SpeechInputSettings": "Configuración de entrada de voz",
  "SpeechRecognitionMode": "Modo de reconocimiento de voz",
  "SpeechRecognitionModeInfo": "Puedes seleccionar el modo de reconocimiento de voz.\n\"Estándar del navegador\" utiliza el reconocimiento de voz integrado en el navegador. \"OpenAI TTS\" utiliza la API de Texto a Voz de OpenAI.\nGeneralmente, se recomienda \"Estándar del navegador\" ya que tiene mayor precisión y velocidad de reconocimiento. Sin embargo, si estás utilizando un navegador que no es compatible con la API WebSpeech, como Firefox, selecciona \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Usar reconocimiento de voz estándar del navegador",
  "WhisperSpeechRecognition": "Usar reconocimiento de voz OpenAI TTS",
  "WhisperAPIKeyInfo": "El modo Whisper requiere una clave API de OpenAI. Por favor, configura la clave API de OpenAI en la configuración de IA.",
  "WhisperTranscriptionModel": "Modelo de transcripción",
  "WhisperTranscriptionModelInfo": "Puedes seleccionar el modelo que se utilizará para el reconocimiento de voz. Cuanto más avanzado sea el modelo, mayor será la precisión del reconocimiento, pero los costos de la API pueden ser más altos.",
  "InitialSpeechTimeout": "Tiempo de espera de reconocimiento de voz",
  "InitialSpeechTimeoutInfo": "Configura el tiempo de espera hasta que se detecte la primera expresión después de iniciar el reconocimiento de voz. Si no se detecta ninguna expresión dentro de este tiempo, el reconocimiento de voz se detendrá automáticamente.\nSi se establece en 0 segundos, el tiempo de espera será ilimitado.",
  "Milliseconds": "Milisegundos",
  "ContinuousMic": "Entrada de micrófono continua",
  "ContinuousMicActive": "Entrada de micrófono continua activa",
  "ContinuousMicModeOn": "El modo de entrada de micrófono continua está activado",
  "ContinuousMicModeOff": "El modo de entrada de micrófono continua está desactivado",
  "ListeningContinuously": "Esperando entrada de voz...",
  "ContinuousMicInfo": "Reanudará automáticamente la entrada de micrófono cuando la IA termine de hablar. Se enviará automáticamente después de que transcurra el tiempo de silencio configurado.\nSi el tiempo configurado se supera sin que se detecte voz, la entrada de micrófono continua se desactivará automáticamente, por lo que si deseas que esté siempre activada, establece el tiempo de espera de reconocimiento de voz en 0 segundos.",
  "CustomAPIEndpoint": "Endpoint de API personalizada",
  "CustomAPIEndpointInfo": "Por favor, ingresa la URL del endpoint de API al que se enviará la solicitud POST.",
  "CustomAPIStream": "Modo de streaming",
  "CustomAPIStreamForced": "Actualmente, el modo de streaming está siempre habilitado.",
  "CustomAPIHeaders": "Encabezados personalizados",
  "CustomAPIHeadersInfo": "Por favor, ingresa la información de encabezado que se incluirá en la solicitud de API en formato JSON.",
  "CustomAPIBody": "Cuerpo personalizado",
  "CustomAPIBodyInfo": "Por favor, ingresa la información del cuerpo que se incluirá en la solicitud de API en formato JSON. messages se incluirán automáticamente.",
  "CustomAPIDescription": "Nota: Los mensajes se incluirán automáticamente en el cuerpo de la solicitud. En modo de streaming, el servidor debe devolver text/event-stream.",
  "ShowCharacterPresetMenu": "Mostrar botón de menú de preajustes de personaje",
  "SpeechRecognitionModeDisabledInfo": "Si el modo de audio está habilitado, solo se puede usar el reconocimiento de voz del navegador.\nAdemás, en el modo de API en tiempo real, solo se puede usar el reconocimiento de voz del navegador y la función de tiempo de espera de reconocimiento de voz estará desactivada."
}
