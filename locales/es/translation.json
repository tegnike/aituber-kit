{
  "Description": "Acerca de la aplicación",
  "BasedSettings": "Configuración básica",
  "AISettings": "Configuración de IA",
  "CharacterSettings": "Configuración de personaje",
  "YoutubeSettings": "Configuración de YouTube",
  "VoiceSettings": "Configuración de voz sintética",
  "SpeechInputSettings": "Configuración de entrada de voz",
  "SlideSettings": "Configuración de presentación",
  "LogSettings": "Historial de conversación",
  "OtherSettings": "Otros",
  "ExternalLinkageMode": "Modo de conexión externa (beta)",
  "YoutubeMode": "Modo YouTube",
  "YoutubeInfo": "Los comentarios que comienzan con '#' serán ignorados.",
  "YoutubeAPIKey": "Clave API de YouTube",
  "YoutubeLiveID": "ID de YouTube Live",
  "ConversationContinuityMode": "Modo de continuidad de conversación (beta)",
  "ConversationContinuityModeInfo": "Este es un modo donde la IA intenta continuar la conversación cuando no hay comentarios. Actualmente solo compatible con OpenAI, Anthropic Claude y Google Gemini.",
  "ConversationContinuityModeInfo2": "Tenga en cuenta que puede aumentar el costo de uso de API ya que se realizan múltiples llamadas a LLM en una sola respuesta.",
  "ConversationContinuityModeInfo3": "Funciona de manera relativamente estable con gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "MaxPastMessages": "Número de mensajes pasados a retener",
  "StatusOn": "Estado: ACTIVADO",
  "StatusOff": "Estado: DESACTIVADO",
  "Select": "Por favor seleccione",
  "TestVoice": "Probar la voz",
  "SelectAIService": "Seleccionar servicio de IA",
  "LocalLLM": "LLM local",
  "SelectModel": "Seleccionar modelo",
  "OpenAIAPIKeyLabel": "Clave API de OpenAI",
  "AnthropicAPIKeyLabel": "Clave API de Anthropic",
  "GoogleAPIKeyLabel": "Clave API de Google Gemini",
  "AzureAPIKeyLabel": "Clave API de Azure OpenAI",
  "AzureAPIURL": "URL de API de Azure OpenAI",
  "GroqAPIKeyLabel": "Clave API de Groq",
  "CohereAPIKeyLabel": "Clave API de Cohere",
  "MistralAIAPIKeyLabel": "Clave API de MistralAI",
  "PerplexityAPIKeyLabel": "Clave API de Perplexity",
  "FireworksAPIKeyLabel": "Clave API de Fireworks",
  "DifyAPIKeyLabel": "Clave API de Dify",
  "DeepSeekAPIKeyLabel": "Clave API de DeepSeek",
  "APIKeyInstruction": "Puede obtener la clave API desde el siguiente enlace. Por favor, introduzca la clave API obtenida en el formulario.",
  "LocalLLMInfo": "Es necesario iniciar el servidor LLM local.",
  "LocalLLMInfo2": "Introduzca la URL del LLM local (incluyendo el número de puerto) y el nombre del modelo.",
  "GroqInfo": "La API de Groq se accede directamente desde el navegador.",
  "DifyInfo": "En Dify, solo se admiten tipos de chatbot o agente. Si no obtiene una respuesta satisfactoria, elimine el historial de conversaciones y vuelva a hacer la pregunta.",
  "DifyInfo2": "La longitud del historial de conversación depende de la configuración del chatbot Dify.",
  "DifyInfo3": "Ejemplo: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Si está utilizando Dify, este prompt del sistema no se utilizará. Por favor, configúrelo en el chatbot de Dify.",
  "EnterURL": "Introduzca URL",
  "CharacterModelLabel": "Modelo de personaje",
  "CharacterModelInfo": "Algunos modelos pueden tardar en cargarse inicialmente.",
  "OpenVRM": "Abrir VRM",
  "BackgroundImage": "Imagen de fondo",
  "ChangeBackgroundImage": "Cambiar imagen de fondo",
  "BackgroundSettings": "Configuración de fondo",
  "BackgroundSettingsDescription": "Puede subir y seleccionar una imagen de fondo para la aplicación.",
  "UploadBackground": "Subir imagen de fondo",
  "DefaultBackground": "Fondo predeterminado",
  "CharacterSettingsPrompt": "Prompt del personaje",
  "CharacterSettingsInfo": "Este valor se establecerá como prompt del sistema.\nConsultando el prompt inicial, puede controlar las expresiones y movimientos del personaje especificando etiquetas emocionales. Ejemplo: [neutral]¡Buenos días![happy]¡Gracias por tu esfuerzo hoy!",
  "CharacterpresetInfo": "Al seleccionar un preset, el prompt del personaje cambiará.\nPuede usar los atajos Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Selección de motor de voz sintética",
  "VoiceAdjustment": "Ajuste de voz",
  "VoiceEngineInstruction": "Por favor, seleccione el motor de síntesis de voz a utilizar.",
  "UsingKoeiromap": "Usar Koeiromap",
  "KoeiromapInfo": "Utilizando la API Koeiromap de Koemotion. Solo compatible con japonés. Para más detalles, consulte lo siguiente.",
  "UsingVoiceVox": "Usar VOICEVOX",
  "VoiceVoxInfo": "Utilizando VOICEVOX. Solo compatible con japonés. Como se utiliza la API local, debe descargar e iniciar la aplicación adecuada para su entorno desde el siguiente sitio.",
  "VoicevoxSpeed": "Velocidad de habla",
  "VoicevoxPitch": "Tono",
  "VoicevoxIntonation": "Entonación",
  "VoicevoxServerUrl": "URL del servidor VOICEVOX",
  "UsingAivisSpeech": "Usar AivisSpeech",
  "AivisSpeechInfo": "Utilizando AivisSpeech. Solo compatible con japonés. Como se utiliza la API local, debe descargar e iniciar la aplicación adecuada para su entorno desde el siguiente sitio.",
  "AivisSpeechSpeaker": "Hablante",
  "AivisSpeechSpeed": "Velocidad de habla",
  "AivisSpeechPitch": "Tono",
  "AivisSpeechIntonation": "Entonación",
  "AivisSpeechServerUrl": "URL del servidor AivisSpeech",
  "UsingNijiVoice": "Usar NijiVoice",
  "NijiVoiceInfo": "Utilizando la API de NijiVoice. Solo compatible con japonés. Por favor, obtenga la clave API desde la siguiente URL.",
  "NijiVoiceApiKey": "Clave API de NijiVoice",
  "NijiVoiceActorId": "ID del hablante",
  "NijiVoiceSpeed": "Velocidad de habla",
  "NijiVoiceEmotionalLevel": "Nivel emocional",
  "NijiVoiceSoundDuration": "Duración del sonido",
  "UpdateSpeakerList": "Actualizar lista de hablantes",
  "UsingGoogleTTS": "Usar Google Text-to-Speech",
  "UsingStyleBertVITS2": "Usar Style-Bert-VITS2",
  "StyleBertVITS2Info": "Utilizando Style-Bert-VITS2. Solo compatible con japonés, inglés y chino. Si utiliza la API local, debe descargar e iniciar la aplicación adecuada para su entorno desde el siguiente sitio. Configure también la clave API si es necesario.",
  "SpeakerSelection": "Selección de tipo de voz",
  "EnglishToJapanese": "Leer palabras en inglés en japonés",
  "IncludeTimestampInUserMessage": "Incluir marca de tiempo en los mensajes del usuario",
  "IncludeTimestampInUserMessageInfo": "Incluir una marca de tiempo en los mensajes del usuario permite que la IA genere respuestas considerando el tiempo.\nPor favor, incluya el siguiente texto en el prompt del sistema:\n\n\"Las entradas del usuario pueden incluir [timestamp]. Esto representa la hora en zona horaria UTC en el momento de la solicitud, así que por favor genera una respuesta considerando esa hora.\"",
  "GoogleTTSInfo": "Utilizando Google Cloud Text-to-Speech. Compatible con múltiples idiomas.",
  "AuthFileInstruction": "Se requiere una clave API o un archivo JSON de autenticación. Obténgalo del siguiente enlace y, en caso de archivo JSON, colóquelo en la carpeta raíz del repositorio con el nombre credentials.json.",
  "LanguageModelURL": "Por favor, seleccione el modelo de lenguaje en la siguiente URL.",
  "LanguageChoice": "Selección de idioma",
  "StyleBeatVITS2ServerURL": "URL del servidor",
  "StyleBeatVITS2ApiKey": "Clave API",
  "StyleBeatVITS2ModelID": "ID del modelo",
  "StyleBeatVITS2Style": "Estilo",
  "StyleBeatVITS2SdpRatio": "Relación de mezcla SDP/DP",
  "StyleBeatVITS2Length": "Velocidad de habla",
  "ConversationHistory": "Historial de conversación",
  "ConversationHistoryInfo": "Se conservarán los últimos {{count}} mensajes de conversación como memoria.",
  "ConversationHistoryReset": "Reiniciar historial de conversación",
  "NotConnectedToExternalAssistant": "No conectado a asistente externo.",
  "APIKeyNotEntered": "No se ha introducido la clave API.",
  "ChatLog": "Registro de conversación",
  "EnterYourQuestion": "Escribe lo que quieras preguntar",
  "AnswerGenerating": "Generando respuesta",
  "AboutThisApplication": "Acerca de esta aplicación",
  "AboutThisApplicationDescription": "Disfrute de la conversación con personajes 3D en su navegador web, utilizando micrófono, entrada de texto y síntesis de voz. Puede cambiar el personaje (VRM), configurar su personalidad y ajustar la voz.<br />La configuración se puede cambiar desde el botón de menú en la esquina superior izquierda.",
  "AboutThisApplicationDescription2": "Con AITuberKit, puede disfrutar de conversaciones con personajes de IA directamente en su navegador web. Consulte cada elemento de configuración para cambiar el personaje, configurar su personalidad y ajustar la voz.",
  "TechnologyIntroduction": "Introducción tecnológica",
  "TechnologyIntroductionDescription1": "Esta aplicación está creada modificando <b>ChatVRM</b> de pixiv Inc. Puede ver el código fuente original ",
  "TechnologyIntroductionLink1": "aquí",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Para la visualización y manipulación de modelos 3D se utiliza",
  "TechnologyIntroductionDescription4": ", para la generación de texto conversacional",
  "TechnologyIntroductionDescription5": "y otros LLM, y para la síntesis de voz",
  "TechnologyIntroductionDescription6": "y otros TTS. Para más detalles, consulte este",
  "TechnologyIntroductionLink2": "artículo explicativo",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "El código fuente de esta aplicación está disponible en GitHub. Puede modificarlo libremente.",
  "SourceCodeDescription2": "Para el uso comercial, consulte el README en el mismo repositorio.",
  "RepositoryURL": "URL del repositorio:",
  "DontShowIntroductionNextTime": "No mostrar este diálogo la próxima vez",
  "Close": "Cerrar",
  "Contact": "Contacto",
  "ContactDescription": "Para consultas sobre esta aplicación, por favor contacte con la siguiente dirección de correo electrónico o cuenta de Twitter.",
  "Creator": "Información del creador",
  "CreatorDescription": "Creador: Nike",
  "Documentation": "Documentación",
  "DocumentationDescription": "Puede ver instrucciones detalladas y tutoriales de AITuberKit en la siguiente URL.",
  "Language": "Configuración de idioma",
  "UsingGSVITTS": "Usar GSVI TTS",
  "GSVITTSInfo": "Configuración de GSVI TTS",
  "GSVITTSServerUrl": "URL del servidor GSVI TTS",
  "GSVITTSModelID": "ID del modelo GSVI TTS",
  "GSVITTSBatchSize": "Tamaño de lote GSVI TTS (1 ~ 100 cuanto mayor sea el valor, más rápida será la inferencia, pero si es demasiado grande puede agotar la memoria)",
  "GSVITTSSpeechRate": "Velocidad de habla (0.5 ~ 2.0 cuanto mayor sea el valor, más rápido)",
  "UsingElevenLabs": "Usar ElevenLabs",
  "ElevenLabsInfo": "Utilizando la API de ElevenLabs. Compatible con múltiples idiomas. Por favor, obtenga la clave API desde la siguiente URL.",
  "ElevenLabsApiKey": "Clave API de ElevenLabs",
  "ElevenLabsVoiceId": "ID de voz de ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Por favor, seleccione el ID de voz desde la siguiente URL.",
  "CharacterName": "Nombre del personaje",
  "ShowAssistantText": "Mostrar la caja de respuesta",
  "ShowCharacterName": "Mostrar el nombre del personaje en la caja de respuesta",
  "ShowControlPanel": "Mostrar el panel de control",
  "ShowControlPanelInfo": "Puede mostrar la pantalla de configuración con Cmd + . (Mac) / Ctrl + . (Windows).\nSi utiliza un smartphone, también puede hacerlo manteniendo pulsada la esquina superior izquierda de la pantalla (aproximadamente 1 segundo).",
  "ShowCharacterPresetMenu": "Mostrar botón de menú de presets de personaje",
  "SlideMode": "Modo presentación",
  "SelectedSlideDocs": "Presentación a utilizar",
  "SlideModeDescription": "Modo en el que la IA presenta automáticamente diapositivas. Solo válido cuando el servicio de IA seleccionado es OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertLabel": "Conversión de diapositivas PDF",
  "PdfConvertDescription": "Convierte PDF a datos para el modo presentación. Solo disponible cuando el servicio de IA seleccionado es OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertFileUpload": "Seleccionar archivo PDF",
  "PdfConvertFolderName": "Nombre de carpeta de guardado",
  "CustomVoiceTextPlaceholder": "Introduzca el texto que desea escuchar",
  "TestVoiceSettings": "Prueba de voz",
  "TestSelectedVoice": "Reproducir",
  "PdfConvertModelSelect": "Seleccionar modelo",
  "PdfConvertButton": "Convertir PDF a diapositivas",
  "PdfConvertLoading": "Convirtiendo...",
  "PdfConvertSuccess": "Conversión completada",
  "PdfConvertError": "Error en la conversión",
  "PdfConvertSubmitError": "Por favor, verifique que el archivo PDF, el nombre de la carpeta y la clave API estén configurados",
  "LocalStorageReset": "Reiniciar configuración",
  "LocalStorageResetInfo": "Si se establecen variables de entorno, sus valores tendrán prioridad. La página se recargará.",
  "LocalStorageResetButton": "Reiniciar configuración",
  "InitialSpeechTimeout": "Tiempo de espera de reconocimiento de voz",
  "InitialSpeechTimeoutInfo": "Establece el tiempo de espera después de iniciar el reconocimiento de voz hasta que se detecte la primera expresión. Si no se detecta ninguna expresión dentro de este tiempo, el reconocimiento de voz se detendrá automáticamente.\nSi se establece en 0 segundos, el tiempo de espera será ilimitado.",
  "Milliseconds": "milisegundos",
  "NoSpeechTimeout": "Tiempo de espera de detección de silencio",
  "NoSpeechTimeoutInfo": "Establece el tiempo después del cual la entrada se terminará automáticamente cuando se continúe en silencio durante la entrada de voz.\nSi se establece en 0 segundos, se desactivará el envío automático por detección de silencio.",
  "ShowSilenceProgressBar": "Mostrar barra de progreso de detección de silencio",
  "SpeechRecognitionMode": "Modo de reconocimiento de voz",
  "SpeechRecognitionModeInfo": "Puede seleccionar el modo de reconocimiento de voz.\n\"Estándar del navegador\" utiliza el reconocimiento de voz incorporado en el navegador. \"OpenAI TTS\" utiliza la API Text to Speech de OpenAI.\nGeneralmente, se recomienda \"Estándar del navegador\" ya que tiene mayor precisión y velocidad de reconocimiento. Sin embargo, si utiliza un navegador que no es compatible con WebSpeech API como Firefox, seleccione \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Usar reconocimiento de voz estándar del navegador",
  "WhisperSpeechRecognition": "Usar reconocimiento de voz OpenAI TTS",
  "WhisperTranscriptionModel": "Modelo de transcripción",
  "WhisperTranscriptionModelInfo": "Puede seleccionar el modelo a utilizar para el reconocimiento de voz. Los modelos más avanzados ofrecen mayor precisión de reconocimiento, pero pueden tener un mayor costo de API.",
  "SpeechRecognitionModeDisabledInfo": "Cuando el modo de audio está habilitado, solo se puede utilizar el reconocimiento de voz del navegador.\nAdemás, en el modo API en tiempo real, solo se puede utilizar el reconocimiento de voz del navegador y la función de tiempo de espera de reconocimiento de voz estará desactivada.",
  "Errors": {
    "EmptyAPIKey": "No se ha configurado la clave API",
    "EmptyLocalLLMURL": "No se ha configurado la URL del LLM local",
    "AIInvalidProperty": "Los valores de configuración del servicio de IA no son correctos",
    "AIAPIError": "Se ha producido un error al ejecutar la API de IA",
    "InvalidAIService": "El servicio de IA seleccionado no es correcto",
    "MethodNotAllowed": "La solicitud no es apropiada",
    "TTSServiceError": "Se ha producido un error en el servicio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Se ha producido un error desconocido",
    "LocalLLMError": "Se ha producido un error en el LLM local",
    "LocalLLMStreamError": "Se ha producido un error en el procesamiento de stream del LLM local",
    "LocalLLMConnectionError": "No se puede conectar al servidor LLM local",
    "LocalLLMNotFound": "No se encontró el punto final del LLM local",
    "LocalLLMAPIError": "Se ha producido un error en la API del LLM local",
    "CustomAPIError": "Se ha producido un error en la API personalizada",
    "InvalidJSON": "El formato JSON no es correcto"
  },
  "MessageReceiver": "Aceptar instrucciones externas",
  "MessageReceiverDescription": "Puede dar instrucciones para el habla del personaje de IA desde el exterior utilizando API.",
  "ClientID": "ID de cliente",
  "OpenSendMessagePage": "Abrir página de envío de mensajes",
  "RealtimeAPIMode": "Modo API en tiempo real",
  "RealtimeAPIModeContentType": "Tipo de envío",
  "RealtimeAPIModeVoice": "Tipo de voz",
  "AudioMode": "Modo de audio",
  "InputText": "Texto",
  "InputAudio": "Voz",
  "SearchGrounding": "Utilizar función de búsqueda",
  "SearchGroundingDescription": "Cuando se utiliza la función multimodal, la función de búsqueda se desactiva automáticamente.",
  "UpdateRealtimeAPISettings": "Actualizar configuración de API en tiempo real",
  "UpdateRealtimeAPISettingsInfo": "Por favor, pulse el botón de actualización para iniciar una nueva sesión WebSocket cuando actualice la clave API, Azure Endpoint, tipo de voz, modelo o prompt del sistema.",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "Se produjo un error en la conexión WebSocket",
    "WebSocketConnectionClosed": "La conexión WebSocket se ha cerrado",
    "WebSocketConnectionAttempt": "Intentando conectar WebSocket...",
    "WebSocketConnectionSuccess": "Se ha establecido correctamente la conexión WebSocket",
    "FunctionExecuting": "Ejecutando {{funcName}}",
    "FunctionExecutionFailed": "Falló la ejecución de {{funcName}}",
    "FirefoxNotSupported": "Esta función no es compatible con Firefox.",
    "SpeechRecognitionError": "Se produjo un error de reconocimiento de voz",
    "NoSpeechDetected": "No se detectó audio.",
    "PresetSwitching": "Se ha cambiado a {{presetName}}.",
    "WhisperError": "Se produjo un error en el reconocimiento de voz por Whisper",
    "UsingTool": "Usando {{toolName}}"
  },
  "ContinuousMic": "Entrada de micrófono continua",
  "ContinuousMicActive": "Entrada de micrófono continua activa",
  "ContinuousMicModeOn": "Modo de entrada de micrófono continua activado",
  "ContinuousMicModeOff": "Modo de entrada de micrófono continua desactivado",
  "ListeningContinuously": "Esperando entrada de voz...",
  "ContinuousMicInfo": "Reinicia automáticamente la entrada de micrófono cuando finaliza el habla de la IA. Envía automáticamente después de transcurrido el tiempo de silencio configurado.\nSi el reconocimiento de voz no se realiza y se supera el tiempo configurado, la entrada de micrófono continua se desactivará automáticamente. Si desea mantenerla siempre activada, configure el tiempo de espera de reconocimiento de voz a 0 segundos.",
  "UsingOpenAITTS": "Usar OpenAI",
  "OpenAITTSInfo": "Utilizando OpenAI. Compatible con múltiples idiomas. Si ha seleccionado OpenAI como servicio de IA, no es necesario configurar la siguiente clave API.",
  "OpenAITTSVoice": "Tipo de voz",
  "OpenAITTSModel": "Modelo",
  "OpenAITTSSpeed": "Velocidad de habla",
  "UsingAzureTTS": "Usar Azure OpenAI",
  "AzureTTSInfo": "Utilizando Azure OpenAI. Compatible con múltiples idiomas.",
  "SendMessage": {
    "title": "Adaptador externo de AITuberKit",
    "directSendTitle": "Hacer hablar directamente al personaje de IA",
    "directSendDescription": "Puede hacer que el personaje de IA hable directamente el mensaje enviado. Si envía varios, se procesarán en orden.\nSe utilizará el modelo de voz seleccionado en la configuración de AITuberKit.",
    "aiGenerateTitle": "Generar respuesta con IA y luego hacerla hablar",
    "aiGenerateDescription": "La IA generará una respuesta a partir del mensaje enviado, y el personaje de IA hablará esa respuesta. Si envía varios, se procesarán en orden.\nSe utilizarán el modelo de IA y el modelo de voz seleccionados en la configuración de AITuberKit.\nPuede elegir entre utilizar el prompt del sistema de AITuberKit o un prompt del sistema personalizado.\nPara cargar el historial de conversaciones anteriores, incluya la cadena [conversation_history] en cualquier posición del prompt del sistema o mensaje del usuario.",
    "useCurrentSystemPrompt": "Utilizar el prompt del sistema de AITuberKit",
    "userInputTitle": "Enviar entrada de usuario",
    "userInputDescription": "El mensaje enviado será procesado de la misma manera que si se introdujera desde el formulario de entrada de AITuberKit. Si envía varios, se procesarán en orden.\nSe utilizarán el modelo de IA y el modelo de voz seleccionados en la configuración de AITuberKit.\nSe utilizarán el prompt del sistema y el historial de conversación de AITuberKit."
  },
  "CannotUseVoice": "Cuando el modo API en tiempo real o el modo de audio están habilitados,\nno es necesaria la configuración de voz sintética.",
  "Live2D": {
    "FileInfo": "Coloque la carpeta del modelo Live2D que desea utilizar en public/live2d. Debe existir un archivo model3.json directamente en esta carpeta.\nSi no aparece en las opciones, recargue la pantalla o verifique que la ruta de la carpeta sea correcta.",
    "Info": "Puede especificar emociones y movimientos.\nCada emoción se controla con el prompt. Para más detalles, consulte \"Configuración de IA => Configuración de personaje\".",
    "Emotions": "Configuración de expresiones",
    "EmotionInfo": "Las emociones pueden especificarse múltiples veces separadas por comas. Si se especifican varias, se seleccionará una al azar.\nLos valores predeterminados corresponden a los modelos proporcionados con AITuberKit. Si utiliza un modelo original, introduzca valores adecuados para su modelo.\nDespués de completar la conversación, se mostrará la expresión \"normal\".",
    "neutralEmotions": "Normal",
    "happyEmotions": "Feliz",
    "sadEmotions": "Triste",
    "angryEmotions": "Enfadado",
    "relaxedEmotions": "Relajado",
    "surprisedEmotions": "Sorprendido",
    "MotionGroups": "Configuración de grupos de movimiento",
    "MotionGroupsInfo": "Los movimientos se seleccionan aleatoriamente del grupo seleccionado.\nAl igual que con la configuración de expresiones, configúrelo según su modelo.\nEl \"Tiempo de espera\" es el movimiento que se muestra después de completar la conversación.",
    "SelectMotionGroup": "Seleccionar grupo de movimiento",
    "idleMotionGroup": "Tiempo de espera",
    "neutralMotionGroup": "Normal",
    "happyMotionGroup": "Feliz",
    "sadMotionGroup": "Triste",
    "angryMotionGroup": "Enfadado",
    "relaxedMotionGroup": "Relajado",
    "surprisedMotionGroup": "Sorprendido"
  },
  "UseVideoAsBackground": "Usar pantalla compartida o cámara web como fondo",
  "Temperature": "Temperature",
  "MaxTokens": "Número máximo de tokens",
  "MaxTokensInfo": "El número máximo de tokens varía según el modelo de IA utilizado. Verifique las especificaciones de cada modelo.",
  "CannotUseParameters": "Cuando el modo API en tiempo real o el modo de audio están habilitados, no se pueden especificar los parámetros Temperature y Max Tokens.",
  "PresetQuestions": "Preguntas preestablecidas",
  "PresetQuestionsInfo": "Puede crear y registrar previamente múltiples patrones de preguntas. Las preguntas registradas se mostrarán como botones en la interfaz de usuario, y al hacer clic se establecerán en el campo de entrada de chat.",
  "EnterPresetQuestion": "Introduzca una pregunta",
  "DragToReorder": "Arrastre para reordenar",
  "CustomAPIEndpoint": "Punto final de API personalizado",
  "CustomAPIEndpointInfo": "Introduzca la URL del punto final de API al que enviar solicitudes POST.",
  "CustomAPIStream": "Modo streaming",
  "CustomAPIStreamForced": "Actualmente, el modo streaming está siempre habilitado.",
  "IncludeSystemMessages": "Incluir mensajes del sistema",
  "CustomAPIHeaders": "Encabezados personalizados",
  "CustomAPIHeadersInfo": "Introduzca la información de encabezado a incluir en la solicitud API en formato JSON.",
  "CustomAPIBody": "Cuerpo personalizado",
  "CustomAPIBodyInfo": "Introduzca la información del cuerpo a incluir en la solicitud API en formato JSON. Los mensajes se incluirán automáticamente.",
  "CustomAPIDescription": "Nota: Los mensajes se incluyen automáticamente en el cuerpo de la solicitud. En modo streaming, el servidor debe devolver text/event-stream.",
  "EditSlideScripts": "Edición de diálogos",
  "PleaseSelectSlide": "Seleccione una diapositiva"
}
