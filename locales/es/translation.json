{
  "Description": "Acerca de la aplicación",
  "BasedSettings": "Configuración básica",
  "AISettings": "Configuración de IA",
  "CharacterSettings": "Configuración de personaje",
  "YoutubeSettings": "Configuración de YouTube",
  "VoiceSettings": "Configuración de voz sintética",
  "SpeechInputSettings": "Configuración de entrada de voz",
  "SlideSettings": "Configuración de presentación",
  "LogSettings": "Historial de conversación",
  "OtherSettings": "Otros",
  "ExternalLinkageMode": "Modo de conexión externa (beta)",
  "YoutubeMode": "Modo YouTube",
  "YoutubeInfo": "Los comentarios que comienzan con '#' serán ignorados.",
  "YoutubeAPIKey": "Clave API de YouTube",
  "YoutubeLiveID": "ID de YouTube Live",
  "ConversationContinuityMode": "Modo de continuidad de conversación (beta)",
  "ConversationContinuityModeInfo": "Es un modo en el que la IA intenta continuar la conversación por sí misma cuando no hay comentarios. Solo está habilitado si se ha seleccionado un modelo compatible con multimodalidad.",
  "ConversationContinuityModeInfo2": "Tenga en cuenta que puede aumentar el costo de uso de API ya que se realizan múltiples llamadas a LLM en una sola respuesta.",
  "ConversationContinuityModeInfo3": "Dependiendo del modelo seleccionado, puede que no funcione de manera estable.",
  "MaxPastMessages": "Número de mensajes pasados a retener",
  "StatusOn": "Estado: ACTIVADO",
  "StatusOff": "Estado: DESACTIVADO",
  "Select": "Por favor seleccione",
  "TestVoice": "Probar la voz",
  "SelectAIService": "Seleccionar servicio de IA",
  "LocalLLM": "LLM local",
  "SelectModel": "Seleccionar modelo",
  "OpenAIAPIKeyLabel": "Clave API de OpenAI",
  "AnthropicAPIKeyLabel": "Clave API de Anthropic",
  "GoogleAPIKeyLabel": "Clave API de Google Gemini",
  "AzureAPIKeyLabel": "Clave API de Azure OpenAI",
  "AzureAPIURL": "URL de API de Azure OpenAI",
  "GroqAPIKeyLabel": "Clave API de Groq",
  "CohereAPIKeyLabel": "Clave API de Cohere",
  "MistralAIAPIKeyLabel": "Clave API de MistralAI",
  "PerplexityAPIKeyLabel": "Clave API de Perplexity",
  "FireworksAPIKeyLabel": "Clave API de Fireworks",
  "DifyAPIKeyLabel": "Clave API de Dify",
  "DeepSeekAPIKeyLabel": "Clave API de DeepSeek",
  "APIKeyInstruction": "Puede obtener la clave API desde el siguiente enlace. Por favor, introduzca la clave API obtenida en el formulario.",
  "LocalLLMInfo": "Es necesario iniciar el servidor LLM local.",
  "LocalLLMInfo2": "Introduzca la URL del LLM local (incluyendo el número de puerto) y el nombre del modelo.",
  "GroqInfo": "La API de Groq se accede directamente desde el navegador.",
  "DifyInfo": "En Dify, solo se admiten tipos de chatbot o agente. Si no obtiene una respuesta satisfactoria, elimine el historial de conversaciones y vuelva a hacer la pregunta.",
  "DifyInfo2": "La longitud del historial de conversación depende de la configuración del chatbot Dify.",
  "DifyInfo3": "Ejemplo: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Si está utilizando Dify, este prompt del sistema no se utilizará. Por favor, configúrelo en el chatbot de Dify.",
  "EnterURL": "Introduzca URL",
  "CharacterModelLabel": "Modelo de personaje",
  "CharacterModelInfo": "Algunos modelos pueden tardar en cargarse inicialmente.",
  "OpenVRM": "Abrir VRM",
  "ChangeBackgroundImage": "Cambiar imagen de fondo",
  "BackgroundSettings": "Configuración de fondo",
  "BackgroundSettingsDescription": "Puede subir y seleccionar una imagen de fondo para la aplicación.",
  "UploadBackground": "Subir imagen de fondo",
  "DefaultBackground": "Fondo predeterminado",
  "GreenBackground": "Fondo verde",
  "CharacterSettingsPrompt": "Prompt del personaje",
  "CharacterSettingsInfo": "Este valor se establecerá como prompt del sistema.\nConsultando el prompt inicial, puede controlar las expresiones y movimientos del personaje especificando etiquetas emocionales. Ejemplo: [neutral]¡Buenos días![happy]¡Gracias por tu esfuerzo hoy!",
  "CharacterpresetInfo": "Al seleccionar un preset, el prompt del personaje cambiará.\nPuede usar los atajos Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Selección de motor de voz sintética",
  "VoiceAdjustment": "Ajuste de voz",
  "VoiceEngineInstruction": "Por favor, seleccione el motor de síntesis de voz a utilizar.",
  "UsingKoeiromap": "Usar Koeiromap",
  "KoeiromapInfo": "Utilizando la API Koeiromap de Koemotion. Solo compatible con japonés. Para más detalles, consulte lo siguiente.",
  "UsingVoiceVox": "Usar VOICEVOX",
  "VoiceVoxInfo": "Utilizando VOICEVOX. Solo compatible con japonés. Como se utiliza la API local, debe descargar e iniciar la aplicación adecuada para su entorno desde el siguiente sitio.",
  "VoicevoxSpeed": "Velocidad de habla",
  "VoicevoxPitch": "Tono",
  "VoicevoxIntonation": "Entonación",
  "VoicevoxServerUrl": "URL del servidor VOICEVOX",
  "UsingAivisSpeech": "Usar AivisSpeech",
  "AivisSpeechInfo": "Utilizando AivisSpeech. Solo compatible con japonés. Como se utiliza la API local, debe descargar e iniciar la aplicación adecuada para su entorno desde el siguiente sitio.",
  "AivisSpeechSpeaker": "Hablante",
  "AivisSpeechSpeed": "Velocidad de habla",
  "AivisSpeechPitch": "Tono",
  "AivisSpeechServerUrl": "URL del servidor AivisSpeech",
  "UsingNijiVoice": "Usar NijiVoice",
  "NijiVoiceInfo": "Utilizando la API de NijiVoice. Solo compatible con japonés. Por favor, obtenga la clave API desde la siguiente URL.",
  "NijiVoiceApiKey": "Clave API de NijiVoice",
  "NijiVoiceActorId": "ID del hablante",
  "NijiVoiceSpeed": "Velocidad de habla",
  "NijiVoiceEmotionalLevel": "Nivel emocional",
  "NijiVoiceSoundDuration": "Duración del sonido",
  "UpdateSpeakerList": "Actualizar lista de hablantes",
  "UsingGoogleTTS": "Usar Google Text-to-Speech",
  "UsingStyleBertVITS2": "Usar Style-Bert-VITS2",
  "StyleBertVITS2Info": "Utilizando Style-Bert-VITS2. Solo compatible con japonés, inglés y chino. Si utiliza la API local, debe descargar e iniciar la aplicación adecuada para su entorno desde el siguiente sitio. Configure también la clave API si es necesario.",
  "SpeakerSelection": "Selección de tipo de voz",
  "EnglishToJapanese": "Leer palabras en inglés en japonés",
  "IncludeTimestampInUserMessage": "Incluir marca de tiempo en los mensajes del usuario",
  "IncludeTimestampInUserMessageInfo": "Incluir una marca de tiempo en los mensajes del usuario permite que la IA genere respuestas considerando el tiempo.\nPor favor, incluya el siguiente texto en el prompt del sistema:\n\n\"Las entradas del usuario pueden incluir [timestamp]. Esto representa la hora en zona horaria UTC en el momento de la solicitud, así que por favor genera una respuesta considerando esa hora.\"",
  "GoogleTTSInfo": "Utilizando Google Cloud Text-to-Speech. Compatible con múltiples idiomas.",
  "AuthFileInstruction": "Se requiere una clave API o un archivo JSON de autenticación. Obténgalo del siguiente enlace y, en caso de archivo JSON, colóquelo en la carpeta raíz del repositorio con el nombre credentials.json.",
  "LanguageModelURL": "Por favor, seleccione el modelo de lenguaje en la siguiente URL.",
  "LanguageChoice": "Selección de idioma",
  "StyleBeatVITS2ServerURL": "URL del servidor",
  "StyleBeatVITS2ApiKey": "Clave API",
  "StyleBeatVITS2ModelID": "ID del modelo",
  "StyleBeatVITS2Style": "Estilo",
  "StyleBeatVITS2SdpRatio": "Relación de mezcla SDP/DP",
  "StyleBeatVITS2Length": "Velocidad de habla",
  "ConversationHistory": "Historial de conversación",
  "ConversationHistoryInfo": "Se conservarán los últimos {{count}} mensajes de conversación como memoria.",
  "ConversationHistoryReset": "Reiniciar historial de conversación",
  "NotConnectedToExternalAssistant": "No conectado a asistente externo.",
  "APIKeyNotEntered": "No se ha introducido la clave API.",
  "ChatLog": "Registro de conversación",
  "EnterYourQuestion": "Escribe lo que quieras preguntar",
  "AnswerGenerating": "Generando respuesta",
  "AboutThisApplication": "Acerca de esta aplicación",
  "AboutThisApplicationDescription": "Disfrute de la conversación con personajes 3D en su navegador web, utilizando micrófono, entrada de texto y síntesis de voz. Puede cambiar el personaje (VRM), configurar su personalidad y ajustar la voz.<br />La configuración se puede cambiar desde el botón de menú en la esquina superior izquierda.",
  "AboutThisApplicationDescription2": "Con AITuberKit, puede disfrutar de conversaciones con personajes de IA directamente en su navegador web. Consulte cada elemento de configuración para cambiar el personaje, configurar su personalidad y ajustar la voz.",
  "TechnologyIntroduction": "Introducción tecnológica",
  "TechnologyIntroductionDescription1": "Esta aplicación está creada modificando <b>ChatVRM</b> de pixiv Inc. Puede ver el código fuente original ",
  "TechnologyIntroductionLink1": "aquí",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Para la visualización y manipulación de modelos 3D se utiliza",
  "TechnologyIntroductionDescription4": ", para la generación de texto conversacional",
  "TechnologyIntroductionDescription5": "y otros LLM, y para la síntesis de voz",
  "TechnologyIntroductionDescription6": "y otros TTS. Para más detalles, consulte este",
  "TechnologyIntroductionLink2": "artículo explicativo",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "El código fuente de esta aplicación está disponible en GitHub. Puede modificarlo libremente.",
  "SourceCodeDescription2": "Para el uso comercial, consulte el README en el mismo repositorio.",
  "RepositoryURL": "URL del repositorio:",
  "DontShowIntroductionNextTime": "No mostrar este diálogo la próxima vez",
  "Close": "Cerrar",
  "Contact": "Contacto",
  "ContactDescription": "Para consultas sobre esta aplicación, por favor contacte con la siguiente dirección de correo electrónico o cuenta de Twitter.",
  "Creator": "Información del creador",
  "CreatorDescription": "Creador: Nike",
  "Documentation": "Documentación",
  "DocumentationDescription": "Puede ver instrucciones detalladas y tutoriales de AITuberKit en la siguiente URL.",
  "Language": "Configuración de idioma",
  "UsingGSVITTS": "Usar GSVI TTS",
  "GSVITTSInfo": "Configuración de GSVI TTS",
  "GSVITTSServerUrl": "URL del servidor GSVI TTS",
  "GSVITTSModelID": "ID del modelo GSVI TTS",
  "GSVITTSBatchSize": "Tamaño de lote GSVI TTS (1 ~ 100 cuanto mayor sea el valor, más rápida será la inferencia, pero si es demasiado grande puede agotar la memoria)",
  "GSVITTSSpeechRate": "Velocidad de habla (0.5 ~ 2.0 cuanto mayor sea el valor, más rápido)",
  "UsingElevenLabs": "Usar ElevenLabs",
  "ElevenLabsInfo": "Utilizando la API de ElevenLabs. Compatible con múltiples idiomas. Por favor, obtenga la clave API desde la siguiente URL.",
  "ElevenLabsApiKey": "Clave API de ElevenLabs",
  "ElevenLabsVoiceId": "ID de voz de ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Por favor, seleccione el ID de voz desde la siguiente URL.",
  "UsingCartesia": "Usar Cartesia",
  "CartesiaInfo": "Se está utilizando la API de Cartesia. Es compatible con varios idiomas. Por favor, obtenga la clave API desde la siguiente URL.",
  "CartesiaApiKey": "Clave API de Cartesia",
  "CartesiaVoiceId": "Cartesia ID de voz",
  "CartesiaVoiceIdInfo": "Por favor, seleccione su ID de voz desde la siguiente URL.",
  "CharacterName": "Nombre del personaje",
  "ShowAssistantText": "Mostrar la caja de respuesta",
  "ShowCharacterName": "Mostrar el nombre del personaje en la caja de respuesta",
  "ShowControlPanel": "Mostrar el panel de control",
  "ShowControlPanelInfo": "Puede mostrar la pantalla de configuración con Cmd + . (Mac) / Ctrl + . (Windows).\nSi utiliza un smartphone, también puede hacerlo manteniendo pulsada la esquina superior izquierda de la pantalla (aproximadamente 1 segundo).",
  "SlideMode": "Modo presentación",
  "SelectedSlideDocs": "Presentación a utilizar",
  "SlideModeDescription": "Este es un modo en el que la IA presenta automáticamente las diapositivas. Solo está disponible si se ha seleccionado un modelo compatible con multimodalidad.",
  "PdfConvertLabel": "Conversión de diapositivas PDF",
  "PdfConvertDescription": "Convierte el PDF en datos para el modo de diapositivas. Solo está disponible si se ha seleccionado un modelo compatible con multimodalidad.",
  "PdfConvertFileUpload": "Seleccionar archivo PDF",
  "PdfConvertFolderName": "Nombre de carpeta de guardado",
  "CustomVoiceTextPlaceholder": "Introduzca el texto que desea escuchar",
  "TestVoiceSettings": "Prueba de voz",
  "TestSelectedVoice": "Reproducir",
  "PdfConvertModelSelect": "Seleccionar modelo",
  "PdfConvertButton": "Convertir PDF a diapositivas",
  "PdfConvertLoading": "Convirtiendo...",
  "PdfConvertSuccess": "Conversión completada",
  "PdfConvertError": "Error en la conversión",
  "PdfConvertSubmitError": "Por favor, verifique que el archivo PDF, el nombre de la carpeta y la clave API estén configurados",
  "LocalStorageReset": "Reiniciar configuración",
  "LocalStorageResetInfo": "Si se establecen variables de entorno, sus valores tendrán prioridad. La página se recargará.",
  "LocalStorageResetButton": "Reiniciar configuración",
  "InitialSpeechTimeout": "Tiempo de espera de reconocimiento de voz",
  "InitialSpeechTimeoutInfo": "Establece el tiempo de espera después de iniciar el reconocimiento de voz hasta que se detecte la primera expresión. Si no se detecta ninguna expresión dentro de este tiempo, el reconocimiento de voz se detendrá automáticamente.\nSi se establece en 0 segundos, el tiempo de espera será ilimitado.",
  "Milliseconds": "milisegundos",
  "NoSpeechTimeout": "Tiempo de espera de detección de silencio",
  "NoSpeechTimeoutInfo": "Establece el tiempo después del cual la entrada se terminará automáticamente cuando se continúe en silencio durante la entrada de voz.\nSi se establece en 0 segundos, se desactivará el envío automático por detección de silencio.",
  "ShowSilenceProgressBar": "Mostrar barra de progreso de detección de silencio",
  "SpeechRecognitionMode": "Modo de reconocimiento de voz",
  "SpeechRecognitionModeInfo": "Puede seleccionar el modo de reconocimiento de voz.\n\"Estándar del navegador\" utiliza el reconocimiento de voz incorporado en el navegador. \"OpenAI TTS\" utiliza la API Text to Speech de OpenAI.\nGeneralmente, se recomienda \"Estándar del navegador\" ya que tiene mayor precisión y velocidad de reconocimiento. Sin embargo, si utiliza un navegador que no es compatible con WebSpeech API como Firefox, seleccione \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Usar reconocimiento de voz estándar del navegador",
  "WhisperSpeechRecognition": "Usar reconocimiento de voz OpenAI TTS",
  "WhisperTranscriptionModel": "Modelo de transcripción",
  "WhisperTranscriptionModelInfo": "Puede seleccionar el modelo a utilizar para el reconocimiento de voz. Los modelos más avanzados ofrecen mayor precisión de reconocimiento, pero pueden tener un mayor costo de API.",
  "SpeechRecognitionModeDisabledInfo": "Cuando el modo de audio está habilitado, solo se puede utilizar el reconocimiento de voz del navegador.\nAdemás, en el modo API en tiempo real, solo se puede utilizar el reconocimiento de voz del navegador y la función de tiempo de espera de reconocimiento de voz estará desactivada.",
  "Errors": {
    "EmptyAPIKey": "No se ha configurado la clave API",
    "EmptyLocalLLMURL": "No se ha configurado la URL del LLM local",
    "AIInvalidProperty": "Los valores de configuración del servicio de IA no son correctos",
    "AIAPIError": "Se ha producido un error al ejecutar la API de IA",
    "InvalidAIService": "El servicio de IA seleccionado no es correcto",
    "MethodNotAllowed": "La solicitud no es apropiada",
    "TTSServiceError": "Se ha producido un error en el servicio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Se ha producido un error desconocido",
    "LocalLLMError": "Se ha producido un error en el LLM local",
    "LocalLLMStreamError": "Se ha producido un error en el procesamiento de stream del LLM local",
    "LocalLLMConnectionError": "No se puede conectar al servidor LLM local",
    "LocalLLMNotFound": "No se encontró el punto final del LLM local",
    "LocalLLMAPIError": "Se ha producido un error en la API del LLM local",
    "CustomAPIError": "Se ha producido un error en la API personalizada",
    "InvalidJSON": "El formato JSON no es correcto"
  },
  "MessageReceiver": "Aceptar instrucciones externas",
  "MessageReceiverDescription": "Puede dar instrucciones para el habla del personaje de IA desde el exterior utilizando API.",
  "ClientID": "ID de cliente",
  "OpenSendMessagePage": "Abrir página de envío de mensajes",
  "RealtimeAPIMode": "Modo API en tiempo real",
  "RealtimeAPIModeContentType": "Tipo de envío",
  "RealtimeAPIModeVoice": "Tipo de voz",
  "AudioMode": "Modo de audio",
  "InputText": "Texto",
  "InputAudio": "Voz",
  "SearchGrounding": "Utilizar función de búsqueda",
  "SearchGroundingDescription": "Cuando se utiliza la función multimodal, la función de búsqueda se desactiva automáticamente.",
  "UpdateRealtimeAPISettings": "Actualizar configuración de API en tiempo real",
  "UpdateRealtimeAPISettingsInfo": "Por favor, pulse el botón de actualización para iniciar una nueva sesión WebSocket cuando actualice la clave API, Azure Endpoint, tipo de voz, modelo o prompt del sistema.",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "Se produjo un error en la conexión WebSocket",
    "WebSocketConnectionClosed": "La conexión WebSocket se ha cerrado",
    "WebSocketConnectionAttempt": "Intentando conectar WebSocket...",
    "WebSocketConnectionSuccess": "Conexión WebSocket exitosa",
    "FunctionExecuting": "Ejecutando {{funcName}}",
    "FunctionExecutionFailed": "Error al ejecutar {{funcName}}",
    "FirefoxNotSupported": "Esta función no está soportada en Firefox",
    "SpeechRecognitionError": "Se produjo un error de reconocimiento de voz",
    "NoSpeechDetected": "No se detectó audio.",
    "PresetSwitching": "Se ha cambiado a {{presetName}}.",
    "WhisperError": "Se produjo un error en el reconocimiento de voz con Whisper",
    "UsingTool": "Usando {{toolName}}",
    "PositionFixed": "La posición del personaje ha sido fijada",
    "PositionUnfixed": "Se ha liberado la fijación de la posición del personaje",
    "PositionReset": "Se ha restablecido la posición del personaje",
    "PositionActionFailed": "Error al manipular la posición",
    "MicrophonePermissionDenied": "Se denegó el permiso de acceso al micrófono",
    "CameraPermissionMessage": "Por favor, permita el uso de la cámara."
  },
  "ContinuousMic": "Entrada de micrófono continua",
  "ContinuousMicActive": "Entrada de micrófono continua activa",
  "ContinuousMicModeOn": "Modo de entrada de micrófono continua activado",
  "ContinuousMicModeOff": "Modo de entrada de micrófono continua desactivado",
  "ListeningContinuously": "Esperando entrada de voz...",
  "ContinuousMicInfo": "Reinicia automáticamente la entrada de micrófono cuando finaliza el habla de la IA. Envía automáticamente después de transcurrido el tiempo de silencio configurado.\nSi el reconocimiento de voz no se realiza y se supera el tiempo configurado, la entrada de micrófono continua se desactivará automáticamente. Si desea mantenerla siempre activada, configure el tiempo de espera de reconocimiento de voz a 0 segundos.",
  "UsingOpenAITTS": "Usar OpenAI",
  "OpenAITTSInfo": "Utilizando OpenAI. Compatible con múltiples idiomas. Si ha seleccionado OpenAI como servicio de IA, no es necesario configurar la siguiente clave API.",
  "OpenAITTSVoice": "Tipo de voz",
  "OpenAITTSModel": "Modelo",
  "OpenAITTSSpeed": "Velocidad de habla",
  "UsingAzureTTS": "Usar Azure OpenAI",
  "AzureTTSInfo": "Utilizando Azure OpenAI. Compatible con múltiples idiomas.",
  "SendMessage": {
    "title": "Adaptador externo de AITuberKit",
    "directSendTitle": "Hacer hablar directamente al personaje de IA",
    "directSendDescription": "Puede hacer que el personaje de IA hable directamente el mensaje enviado. Si envía varios, se procesarán en orden.\nSe utilizará el modelo de voz seleccionado en la configuración de AITuberKit.",
    "aiGenerateTitle": "Generar respuesta con IA y luego hacerla hablar",
    "aiGenerateDescription": "La IA generará una respuesta a partir del mensaje enviado, y el personaje de IA hablará esa respuesta. Si envía varios, se procesarán en orden.\nSe utilizarán el modelo de IA y el modelo de voz seleccionados en la configuración de AITuberKit.\nPuede elegir entre utilizar el prompt del sistema de AITuberKit o un prompt del sistema personalizado.\nPara cargar el historial de conversaciones anteriores, incluya la cadena [conversation_history] en cualquier posición del prompt del sistema o mensaje del usuario.",
    "useCurrentSystemPrompt": "Utilizar el prompt del sistema de AITuberKit",
    "userInputTitle": "Enviar entrada de usuario",
    "userInputDescription": "El mensaje enviado será procesado de la misma manera que si se introdujera desde el formulario de entrada de AITuberKit. Si envía varios, se procesarán en orden.\nSe utilizarán el modelo de IA y el modelo de voz seleccionados en la configuración de AITuberKit.\nSe utilizarán el prompt del sistema y el historial de conversación de AITuberKit."
  },
  "CannotUseVoice": "Cuando el modo API en tiempo real o el modo de audio están habilitados,\nno es necesaria la configuración de voz sintética.",
  "Live2D": {
    "FileInfo": "Coloque la carpeta del modelo Live2D que desea utilizar en public/live2d. Debe existir un archivo model3.json directamente en esta carpeta.\nSi no aparece en las opciones, recargue la pantalla o verifique que la ruta de la carpeta sea correcta.",
    "Info": "Puede especificar emociones y movimientos.\nCada emoción se controla con el prompt. Para más detalles, consulte \"Configuración de IA => Configuración de personaje\".",
    "Emotions": "Configuración de expresiones",
    "EmotionInfo": "Las emociones pueden especificarse múltiples veces separadas por comas. Si se especifican varias, se seleccionará una al azar.\nLos valores predeterminados corresponden a los modelos proporcionados con AITuberKit. Si utiliza un modelo original, introduzca valores adecuados para su modelo.\nDespués de completar la conversación, se mostrará la expresión \"normal\".",
    "neutralEmotions": "Normal",
    "happyEmotions": "Feliz",
    "sadEmotions": "Triste",
    "angryEmotions": "Enfadado",
    "relaxedEmotions": "Relajado",
    "surprisedEmotions": "Sorprendido",
    "MotionGroups": "Configuración de grupos de movimiento",
    "MotionGroupsInfo": "Los movimientos se seleccionan aleatoriamente del grupo seleccionado.\nAl igual que con la configuración de expresiones, configúrelo según su modelo.\nEl \"Tiempo de espera\" es el movimiento que se muestra después de completar la conversación.",
    "SelectMotionGroup": "Seleccionar grupo de movimiento",
    "idleMotionGroup": "Tiempo de espera",
    "neutralMotionGroup": "Normal",
    "happyMotionGroup": "Feliz",
    "sadMotionGroup": "Triste",
    "angryMotionGroup": "Enfadado",
    "relaxedMotionGroup": "Relajado",
    "surprisedMotionGroup": "Sorprendido"
  },
  "UseVideoAsBackground": "Usar pantalla compartida o cámara web como fondo",
  "Temperature": "Temperature",
  "MaxTokens": "Número máximo de tokens",
  "MaxTokensInfo": "El número máximo de tokens varía según el modelo de IA utilizado. Verifique las especificaciones de cada modelo.",
  "CannotUseParameters": "Cuando el modo API en tiempo real o el modo de audio están habilitados, la función multimodal no está disponible. Además, no se pueden especificar los parámetros Temperature y Max Tokens.",
  "PresetQuestions": "Preguntas preestablecidas",
  "PresetQuestionsInfo": "Puede crear y registrar previamente múltiples patrones de preguntas. Las preguntas registradas se mostrarán como botones en la interfaz de usuario, y al hacer clic se establecerán en el campo de entrada de chat.",
  "EnterPresetQuestion": "Introduzca una pregunta",
  "DragToReorder": "Arrastre para reordenar",
  "CustomAPIEndpoint": "Punto final de API personalizado",
  "CustomAPIEndpointInfo": "Introduzca la URL del punto final de API al que enviar solicitudes POST.",
  "CustomAPIStream": "Modo streaming",
  "CustomAPIStreamForced": "Actualmente, el modo streaming está siempre habilitado.",
  "IncludeSystemMessages": "Incluir mensajes del sistema",
  "CustomAPIHeaders": "Encabezados personalizados",
  "CustomAPIHeadersInfo": "Introduzca la información de encabezado a incluir en la solicitud API en formato JSON.",
  "CustomAPIBody": "Cuerpo personalizado",
  "CustomAPIBodyInfo": "Introduzca la información del cuerpo a incluir en la solicitud API en formato JSON. Los mensajes se incluirán automáticamente.",
  "CustomAPIDescription": "Nota: Los mensajes se incluyen automáticamente en el cuerpo de la solicitud. En modo streaming, el servidor debe devolver text/event-stream.",
  "EditSlideScripts": "Edición de diálogos",
  "PleaseSelectSlide": "Seleccione una diapositiva",
  "XAIAPIKeyLabel": "Clave API de xAI",
  "DynamicRetrievalDescription": "Establece el umbral de tiempo para que el modelo realice la búsqueda. Si es 0, siempre realizará la búsqueda; si es 1, no realizará la búsqueda.",
  "DynamicRetrieval": "Búsqueda dinámica",
  "OpenRouterModelNameInstruction": "Por favor, ingrese el identificador del modelo desde OpenRouter (por ejemplo: \"openai/gpt-4o\", \"mistralai/mistral-large-latest\"). Puede verificar el identificador del modelo en la página del modelo de OpenRouter.",
  "FixPosition": "Fijar posición",
  "ResetPosition": "Restablecer posición",
  "CharacterPosition": "Posición del personaje",
  "DynamicRetrievalThreshold": "Umbral dinámico",
  "CurrentStatus": "Estado actual",
  "PositionNotFixed": "No fijado",
  "PositionFixed": "Fijado",
  "OpenRouterAPIKeyLabel": "Clave API de OpenRouter",
  "CharacterPositionInfo": "Se puede fijar la posición y orientación del personaje. En VRM se guarda la posición de la cámara, en Live2D se guarda la posición del modelo.",
  "UnfixPosition": "Desbloquear fijo",
  "ImageDisplayPosition": "Posición de visualización de la imagen",
  "ImageDisplayPositionDescription": "Seleccione la posición para mostrar la imagen cargada",
  "InputArea": "Área de entrada",
  "SideArea": "Panel lateral",
  "PasteImageSupported": "Soporte para pegar imágenes",
  "ImageSizeExceeded": "El tamaño de la imagen excede el límite de 10MB",
  "ImageReadError": "Error al leer el archivo de imagen",
  "EnterClientID": "Por favor, introduzca el ID del cliente",
  "NoClientIDSet": "No se ha configurado el ID de cliente",
  "Edit": "Editar",
  "GenerateNew": "Crear nuevo",
  "Save": "Guardar",
  "Cancel": "Cancelar",
  "FileSizeError": "El tamaño del archivo supera el máximo de {{maxSize}}MB.",
  "CustomApiIncludeMimeType": "Incluir tipo MIME en la imagen",
  "ThemeMono": "Monocromo",
  "MultiModalMode": "Modo de uso multimodal",
  "CustomModelOff": "Usar modelo personalizado: OFF",
  "ThemeForest": "Bosque",
  "MultiModalModeAIDecide": "Decidir con IA",
  "MultiModalModeNever": "No usar",
  "FileProcessError": "Se produjo un error al procesar el archivo.",
  "ColorTheme": "Tema de color",
  "CustomApiIncludeMimeTypeDescription": "Incluye la propiedad mimeType en el objeto de imagen enviado a la API personalizada.",
  "CustomModelOn": "Usar modelo personalizado: ON",
  "ImageLoadError": "Error al cargar la imagen.",
  "NoDisplay": "Mostrar solo icono",
  "MultiModalNotSupported": "El modelo o configuración seleccionada no admite el envío de imágenes. Active la función multimodal o seleccione un modelo compatible.",
  "ThemeCool": "Genial",
  "ColorThemeInfo": "Puede seleccionar el tema de color de la aplicación. El tema seleccionado se aplicará inmediatamente.",
  "RemoveImage": "Eliminar imagen",
  "MultiModalAIDecisionPrompt": "Prompt para juicio de IA",
  "ThemeOcean": "Océano",
  "FileTypeError": "Formato de archivo no soportado. Solo se pueden subir archivos de imagen (PNG, JPEG, GIF, WebP).",
  "ImageDimensionError": "El tamaño de la imagen supera el máximo de {{maxWidth}}x{{maxHeight}} píxeles.",
  "ThemeSunset": "Atardecer",
  "FileReadError": "Error al cargar el archivo.",
  "EnableMultiModal": "Utilizar funciones multimodales",
  "MultiModalAIDecisionPromptPlaceholder": "Eres un asistente que determina si una imagen está relacionada con la pregunta del usuario o el contexto de la conversación. Considera el historial reciente de la conversación y el mensaje del usuario, y responde solo con \"sí\" o \"no\".",
  "CustomModelPlaceholder": "Introduzca el nombre del modelo personalizado...",
  "MultiModalModeAlways": "Usar siempre",
  "EnableMultiModalDescription": "Habilitar la función de carga de imágenes. En modelos no compatibles, las imágenes pueden ser ignoradas.",
  "ThemeDefault": "Predeterminado",
  "MultiModalModeDescription": "Seleccione cuándo usar la función multimodal.",
  "AivisCloudAPIDashboard": "Panel de control de API de Aivis Cloud",
  "CharacterPositionFixed": "La posición está fija",
  "Position": "Ubicación",
  "NoDisplayedImages": "No hay imágenes para mostrar actualmente",
  "StyleName": "Nombre del estilo",
  "Pitch": "tono",
  "MaximumFiveImagesAllowed": "Solo se pueden mostrar hasta 5 imágenes.",
  "LayerControl": "Orden de apilamiento",
  "ImageAlreadyPlaced": "Esta imagen ya está mostrada.",
  "MostVisible": "Más visible",
  "BottomLayer": "Al fondo",
  "FixCharacterPosition": "Fijar posición",
  "UploadComplete": "Carga completada",
  "Cute": "lindo",
  "StyleNamePlaceholder": "Ejemplo: Normal",
  "UploadFailed": "Error al subir",
  "DeleteFailed": "No se pudo eliminar",
  "TopLayer": "En primer plano",
  "AivisCloudAPIDescription": "Al marcar esta casilla, se utilizará la API de Aivis Cloud en la versión en la nube.",
  "SpeechSpeed": "Velocidad de habla",
  "DragToReorderLayers": "Arrastra para cambiar el orden",
  "MoveToBack": "Mover hacia atrás",
  "AivisSpeechIntonationScale": "Intensidad del estilo",
  "Items": "Elemento",
  "OnlyImageFilesAllowed": "Solo se pueden subir archivos de imagen.",
  "ConfirmDeleteImage": "¿Está seguro de que desea eliminar esta imagen?",
  "LayerControlDescription": "Puedes controlar el orden de superposición de imágenes y personajes",
  "NoUploadedImages": "No hay imágenes cargadas",
  "AddToDisplay": "Mostrar en pantalla",
  "Mature": "sobrio",
  "LayerOrder": "Orden de capas (máximo 5)",
  "UseStyleName": "Especificar por nombre de estilo",
  "UploadedImages": "Imágenes subidas",
  "BehindCharacter": "Detrás del personaje",
  "SupportedFormats": "Formatos compatibles",
  "FileSizeTooLarge": "El tamaño del archivo es demasiado grande (máximo 100MB).",
  "CharacterLayerPosition": "Posición del personaje",
  "UseAivisCloudAPI": "Usar Aivis Cloud API",
  "CharacterLayer": "Personaje",
  "MoveToFront": "Mover hacia adelante",
  "Remove": "Eliminar",
  "Size": "Tamaño",
  "APIKey": "Clave API",
  "PreSilenceDuration": "Tiempo de silencio antes del audio",
  "Preset": "Preajuste",
  "TempoDynamics": "Variación del tempo",
  "LayerPosition": "Posición de visualización",
  "Cool": "genial",
  "ImageSettingsDescription": "Puedes subir imágenes y colocarlas en la pantalla. Puedes mostrar hasta 5 imágenes al mismo tiempo.",
  "DragCharacterToMove": "Arrastra el personaje para moverlo",
  "InFrontOfCharacter": "Delante del personaje",
  "StyleID": "ID de estilo",
  "ImageOrder": "Orden de las imágenes",
  "Presets": "Preajuste",
  "Uploading": "Subiendo...",
  "ModelUUID": "UUID del modelo",
  "UnfixCharacterPosition": "Desbloquear posición fija",
  "LayerOrderDescription": "Puedes ajustar el orden de superposición de imágenes y personajes mediante arrastrar y soltar.",
  "ResetCharacterPosition": "Restablecer posición",
  "Delete": "Eliminar",
  "LeastVisible": "El más invisible",
  "StyleSelectionDescription": "Puede seleccionar ya sea el ID de estilo o el nombre del estilo. Normalmente se utiliza el ID de estilo (0 a 31).",
  "PostSilenceDuration": "Tiempo de silencio después del audio",
  "EmotionalIntensity": "Intensidad de la expresión emocional",
  "UploadImages": "Subir imagen",
  "CurrentlyDisplayedImages": "Imagen actualmente mostrada",
  "AlreadyDisplayed": "Mostrando",
  "CharacterPositionDescription": "Puedes arrastrar el personaje para ajustar su posición",
  "ShowQuickMenu": "Mostrar botón de menú rápido",
  "ImageSettings": "Configuración de imagen",
  "Energetic": "energético",
  "UsingAivisCloudAPI": "Usar Aivis Cloud API",
  "AivisCloudAPIInfo": "Configuración de Aivis Cloud API"
}
