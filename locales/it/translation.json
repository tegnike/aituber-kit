{
  "Description": "Informazioni sull'applicazione",
  "BasedSettings": "Impostazioni di base",
  "AISettings": "Impostazioni AI",
  "CharacterSettings": "Impostazioni del personaggio",
  "YoutubeSettings": "Impostazioni YouTube",
  "VoiceSettings": "Impostazioni voce sintetica",
  "SpeechInputSettings": "Impostazioni input vocale",
  "SlideSettings": "Impostazioni presentazione",
  "LogSettings": "Cronologia conversazioni",
  "OtherSettings": "Altro",
  "ExternalLinkageMode": "Modalità collegamento esterno (Beta)",
  "YoutubeMode": "Modalità YouTube",
  "YoutubeInfo": "I commenti che iniziano con '#' verranno ignorati.",
  "YoutubeAPIKey": "Chiave API YouTube",
  "YoutubeLiveID": "ID YouTube Live",
  "ConversationContinuityMode": "Modalità continuità conversazione (Beta)",
  "ConversationContinuityModeInfo": "Modalità in cui l'AI cerca di continuare la conversazione quando non ci sono commenti. Attualmente supportata solo da OpenAI, Anthropic Claude e Google Gemini.",
  "ConversationContinuityModeInfo2": "Poiché vengono effettuate più chiamate LLM per una singola risposta, le spese API potrebbero aumentare. Si prega di fare attenzione.",
  "ConversationContinuityModeInfo3": "Funziona relativamente in modo stabile con gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "MaxPastMessages": "Numero di messaggi passati da conservare",
  "StatusOn": "Stato: ATTIVO",
  "StatusOff": "Stato: DISATTIVO",
  "Select": "Seleziona",
  "TestVoice": "Testa la voce",
  "SelectAIService": "Seleziona servizio AI",
  "LocalLLM": "LLM locale",
  "SelectModel": "Seleziona modello",
  "OpenAIAPIKeyLabel": "Chiave API OpenAI",
  "AnthropicAPIKeyLabel": "Chiave API Anthropic",
  "GoogleAPIKeyLabel": "Chiave API Google Gemini",
  "AzureAPIKeyLabel": "Chiave API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "GroqAPIKeyLabel": "Chiave API Groq",
  "CohereAPIKeyLabel": "Chiave API Cohere",
  "MistralAIAPIKeyLabel": "Chiave API MistralAI",
  "PerplexityAPIKeyLabel": "Chiave API Perplexity",
  "FireworksAPIKeyLabel": "Chiave API Fireworks",
  "DifyAPIKeyLabel": "Chiave API Dify",
  "DeepSeekAPIKeyLabel": "Chiave API DeepSeek",
  "APIKeyInstruction": "Le chiavi API possono essere ottenute dal link sottostante. Inserisci la chiave API ottenuta nel modulo.",
  "LocalLLMInfo": "È necessario avviare il server LLM locale.",
  "LocalLLMInfo2": "Inserisci l'URL del LLM locale (incluso il numero di porta) e il nome del modello.",
  "GroqInfo": "L'API Groq è accessibile direttamente dal browser.",
  "DifyInfo": "In Dify, sono supportati solo i tipi chatbot o agente. Se non si ottiene una risposta soddisfacente, eliminare la cronologia delle conversazioni e riprovare a fare la domanda.",
  "DifyInfo2": "La lunghezza della cronologia delle conversazioni dipende dalle impostazioni del chatbot Dify.",
  "DifyInfo3": "Esempio: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Quando si utilizza Dify, questo prompt di sistema non viene utilizzato. Configuralo nel chatbot Dify.",
  "EnterURL": "Inserisci URL",
  "CharacterModelLabel": "Modello del personaggio",
  "CharacterModelInfo": "Alcuni modelli potrebbero richiedere più tempo per caricarsi durante la visualizzazione iniziale.",
  "OpenVRM": "Apri VRM",
  "BackgroundImage": "Immagine di sfondo",
  "ChangeBackgroundImage": "Cambia immagine di sfondo",
  "BackgroundSettings": "Impostazioni sfondo",
  "BackgroundSettingsDescription": "Puoi caricare e selezionare un'immagine di sfondo per l'applicazione.",
  "UploadBackground": "Carica immagine di sfondo",
  "DefaultBackground": "Sfondo predefinito",
  "CharacterSettingsPrompt": "Prompt del personaggio",
  "CharacterSettingsInfo": "Questo valore sarà impostato come prompt di sistema.\nFacendo riferimento al prompt iniziale, puoi controllare le espressioni e i movimenti del personaggio specificando tag emotivi. Esempio: [neutral]Buongiorno![happy]Anche oggi hai lavorato duramente!",
  "CharacterpresetInfo": "Selezionando un preset, il prompt del personaggio verrà modificato.\nÈ possibile utilizzare scorciatoie Cmd + Shift + 1~5, (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Selezione motore voce sintetica",
  "VoiceAdjustment": "Regolazione voce",
  "VoiceEngineInstruction": "Seleziona il motore di sintesi vocale da utilizzare.",
  "UsingKoeiromap": "Usa Koeiromap",
  "KoeiromapInfo": "Stiamo utilizzando l'API Koeiromap di Koemotion. Supporta solo il giapponese. Per ulteriori dettagli, consulta il seguente.",
  "UsingVoiceVox": "Usa VOICEVOX",
  "VoiceVoxInfo": "Stiamo utilizzando VOICEVOX. Supporta solo il giapponese. Poiché utilizza un'API locale, è necessario scaricare e avviare l'applicazione appropriata per il tuo ambiente dal sito sottostante.",
  "VoicevoxSpeed": "Velocità del parlato",
  "VoicevoxPitch": "Intonazione",
  "VoicevoxIntonation": "Modulazione",
  "VoicevoxServerUrl": "URL server VOICEVOX",
  "UsingAivisSpeech": "Usa AivisSpeech",
  "AivisSpeechInfo": "Stiamo utilizzando AivisSpeech. Supporta solo il giapponese. Poiché utilizza un'API locale, è necessario scaricare e avviare l'applicazione appropriata per il tuo ambiente dal sito sottostante.",
  "AivisSpeechSpeaker": "Parlante",
  "AivisSpeechSpeed": "Velocità del parlato",
  "AivisSpeechPitch": "Intonazione",
  "AivisSpeechIntonation": "Modulazione",
  "AivisSpeechServerUrl": "URL server AivisSpeech",
  "UsingNijiVoice": "Usa NijiVoice",
  "NijiVoiceInfo": "Stiamo utilizzando l'API NijiVoice. Supporta solo il giapponese. Ottieni la chiave API dall'URL sottostante.",
  "NijiVoiceApiKey": "Chiave API NijiVoice",
  "NijiVoiceActorId": "ID parlante",
  "NijiVoiceSpeed": "Velocità del parlato",
  "NijiVoiceEmotionalLevel": "Livello emotivo",
  "NijiVoiceSoundDuration": "Durata audio",
  "UpdateSpeakerList": "Aggiorna lista parlanti",
  "UsingGoogleTTS": "Usa Google Text-to-Speech",
  "UsingStyleBertVITS2": "Usa Style-Bert-VITS2",
  "StyleBertVITS2Info": "Stiamo utilizzando Style-Bert-VITS2. Supporta solo giapponese, inglese e cinese. Se utilizzi l'API locale, scarica e avvia l'applicazione appropriata per il tuo ambiente dal sito sottostante. Se necessario, configura anche la chiave API.",
  "SpeakerSelection": "Selezione tipo di voce",
  "EnglishToJapanese": "Leggi le parole inglesi in giapponese",
  "IncludeTimestampInUserMessage": "Includi timestamp nei messaggi utente",
  "IncludeTimestampInUserMessageInfo": "Includendo il timestamp nei messaggi utente, l'AI può generare risposte considerando l'orario.\nAggiungere la seguente frase al prompt di sistema:\n\n\"Le richieste utente potrebbero contenere un [timestamp], che rappresenta l'ora corrente nel fuso orario UTC. Considera questo orario quando generi la tua risposta.\"",
  "GoogleTTSInfo": "Stiamo utilizzando Google Cloud Text-to-Speech. Supporta più lingue.",
  "AuthFileInstruction": "È necessaria una chiave API o un file JSON per l'autenticazione. Ottienilo dal link sottostante e, se utilizzi un file JSON, posizionalo nella cartella principale del repository con il nome credentials.json.",
  "LanguageModelURL": "Seleziona il modello linguistico dal seguente URL.",
  "LanguageChoice": "Selezione lingua",
  "StyleBeatVITS2ServerURL": "URL server",
  "StyleBeatVITS2ApiKey": "Chiave API",
  "StyleBeatVITS2ModelID": "ID modello",
  "StyleBeatVITS2Style": "Stile",
  "StyleBeatVITS2SdpRatio": "Rapporto mixaggio SDP/DP",
  "StyleBeatVITS2Length": "Velocità del parlato",
  "ConversationHistory": "Cronologia conversazioni",
  "ConversationHistoryInfo": "Gli ultimi {{count}} messaggi della conversazione vengono conservati come memoria.",
  "ConversationHistoryReset": "Resetta cronologia conversazioni",
  "NotConnectedToExternalAssistant": "Non connesso a un assistente esterno.",
  "APIKeyNotEntered": "Chiave API non inserita.",
  "ChatLog": "Registro chat",
  "EnterYourQuestion": "Inserisci la tua domanda",
  "AnswerGenerating": "Generazione risposta in corso",
  "AboutThisApplication": "Informazioni su questa applicazione",
  "AboutThisApplicationDescription": "Puoi conversare con un personaggio 3D direttamente nel browser web utilizzando microfono, input di testo e sintesi vocale. Puoi modificare il personaggio (VRM), impostare la personalità e regolare la voce.<br />Le impostazioni possono essere modificate dal pulsante menu nell'angolo in alto a sinistra.",
  "AboutThisApplicationDescription2": "Con AITuberKit, puoi divertirti a conversare con un personaggio AI direttamente nel browser web. Controlla le impostazioni corrispondenti per modificare il personaggio, impostare la personalità e regolare la voce.",
  "TechnologyIntroduction": "Introduzione tecnologica",
  "TechnologyIntroductionDescription1": "Questa applicazione è stata creata modificando <b>ChatVRM</b> di pixiv. Il codice sorgente originale è disponibile",
  "TechnologyIntroductionLink1": "qui",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Per la visualizzazione e il controllo del modello 3D utilizziamo",
  "TechnologyIntroductionDescription4": ", per la generazione delle conversazioni",
  "TechnologyIntroductionDescription5": "vari LLM, e per la sintesi vocale",
  "TechnologyIntroductionDescription6": "vari TTS. Per maggiori dettagli, consulta questo",
  "TechnologyIntroductionLink2": "articolo esplicativo",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "Il codice sorgente di questa applicazione è disponibile su GitHub. Puoi modificarlo liberamente.",
  "SourceCodeDescription2": "Per l'uso commerciale, consulta il README nello stesso repository.",
  "RepositoryURL": "URL repository:",
  "DontShowIntroductionNextTime": "Non mostrare questa finestra la prossima volta",
  "Close": "Chiudi",
  "Contact": "Contatti",
  "ContactDescription": "Per domande su questa applicazione, contattaci all'indirizzo email o account Twitter sottostante.",
  "Creator": "Informazioni creatore",
  "CreatorDescription": "Creatore: Nike",
  "Documentation": "Documentazione",
  "DocumentationDescription": "Per istruzioni dettagliate e tutorial su AITuberKit, visita l'URL sottostante.",
  "Language": "Impostazioni lingua",
  "UsingGSVITTS": "Usa GSVI TTS",
  "GSVITTSInfo": "Impostazioni GSVI TTS",
  "GSVITTSServerUrl": "URL server GSVI TTS",
  "GSVITTSModelID": "ID modello GSVI TTS",
  "GSVITTSBatchSize": "Dimensione batch GSVI TTS (1 ~ 100 valori più alti aumentano la velocità di inferenza, ma valori troppo alti possono esaurire la memoria)",
  "GSVITTSSpeechRate": "Velocità parlato (0.5 ~ 2.0 valori più alti = più veloce)",
  "UsingElevenLabs": "Usa ElevenLabs",
  "ElevenLabsInfo": "Stiamo utilizzando l'API ElevenLabs. Supporta più lingue. Ottieni la chiave API dall'URL sottostante.",
  "ElevenLabsApiKey": "Chiave API ElevenLabs",
  "ElevenLabsVoiceId": "ID voce ElevenLabs",
  "ElevenLabsVoiceIdInfo": "Seleziona l'ID voce dall'URL sottostante.",
  "CharacterName": "Nome personaggio",
  "ShowAssistantText": "Mostra area risposta",
  "ShowCharacterName": "Mostra nome personaggio nell'area risposta",
  "ShowControlPanel": "Mostra pannello di controllo",
  "ShowControlPanelInfo": "La schermata delle impostazioni può essere visualizzata con Cmd + . (Mac) / Ctrl + . (Windows).\nSe utilizzi uno smartphone, puoi anche tenere premuto (circa 1 secondo) nell'angolo in alto a sinistra dello schermo.",
  "ShowCharacterPresetMenu": "Mostra pulsante menu preset personaggio",
  "SlideMode": "Modalità presentazione",
  "SelectedSlideDocs": "Slide da utilizzare",
  "SlideModeDescription": "Modalità in cui l'AI presenta automaticamente le slide. Attiva solo quando il servizio AI selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertLabel": "Conversione slide PDF",
  "PdfConvertDescription": "Converti PDF in dati per la modalità presentazione. Disponibile solo quando il servizio AI selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertFileUpload": "Seleziona file PDF",
  "PdfConvertFolderName": "Nome cartella di salvataggio",
  "CustomVoiceTextPlaceholder": "Inserisci il testo che desideri ascoltare",
  "TestVoiceSettings": "Test voce",
  "TestSelectedVoice": "Riproduci",
  "PdfConvertModelSelect": "Seleziona modello",
  "PdfConvertButton": "Converti PDF in slide",
  "PdfConvertLoading": "Conversione in corso...",
  "PdfConvertSuccess": "Conversione completata",
  "PdfConvertError": "Conversione fallita",
  "PdfConvertSubmitError": "Verifica che il file PDF, il nome della cartella e la chiave API siano impostati",
  "LocalStorageReset": "Ripristina impostazioni",
  "LocalStorageResetInfo": "Se sono impostate variabili d'ambiente, quei valori avranno la priorità. La pagina verrà ricaricata.",
  "LocalStorageResetButton": "Ripristina impostazioni",
  "InitialSpeechTimeout": "Timeout riconoscimento vocale",
  "InitialSpeechTimeoutInfo": "Imposta il tempo di attesa per il rilevamento del primo discorso dopo l'avvio del riconoscimento vocale. Se non viene rilevato alcun discorso entro questo tempo, il riconoscimento vocale si interrompe automaticamente.\nImpostando a 0 secondi, il tempo di attesa diventa illimitato.",
  "Milliseconds": "millisecondi",
  "NoSpeechTimeout": "Timeout rilevamento silenzio",
  "NoSpeechTimeoutInfo": "Imposta il tempo dopo il quale l'input viene terminato automaticamente quando c'è silenzio durante l'input vocale.\nImpostando a 0 secondi, disabilita l'invio automatico basato sul rilevamento del silenzio.",
  "ShowSilenceProgressBar": "Mostra barra di progresso rilevamento silenzio",
  "SpeechRecognitionMode": "Modalità riconoscimento vocale",
  "SpeechRecognitionModeInfo": "Puoi selezionare la modalità di riconoscimento vocale.\n\"Standard browser\" utilizza il riconoscimento vocale integrato nel browser. \"OpenAI TTS\" utilizza l'API Text to Speech di OpenAI.\nGeneralmente, \"Standard browser\" è raccomandato perché ha una maggiore precisione e velocità di riconoscimento. Tuttavia, se stai utilizzando un browser come Firefox che non supporta l'API WebSpeech, seleziona \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Usa riconoscimento vocale standard del browser",
  "WhisperSpeechRecognition": "Usa riconoscimento vocale OpenAI TTS",
  "WhisperTranscriptionModel": "Modello di trascrizione",
  "WhisperTranscriptionModelInfo": "Puoi selezionare il modello da utilizzare per il riconoscimento vocale. I modelli più potenti offrono un riconoscimento più preciso, ma potrebbero comportare costi API più elevati.",
  "SpeechRecognitionModeDisabledInfo": "Quando la modalità audio è attiva, è possibile utilizzare solo il riconoscimento vocale del browser.\nInoltre, in modalità API in tempo reale, è possibile utilizzare solo il riconoscimento vocale del browser e la funzione di timeout del riconoscimento vocale è disabilitata.",
  "Errors": {
    "EmptyAPIKey": "Chiave API non impostata",
    "EmptyLocalLLMURL": "URL LLM locale non impostato",
    "AIInvalidProperty": "Valore impostazione servizio AI non valido",
    "AIAPIError": "Si è verificato un errore durante l'esecuzione dell'API AI",
    "InvalidAIService": "Il servizio AI selezionato non è valido",
    "MethodNotAllowed": "La richiesta non è appropriata",
    "TTSServiceError": "Si è verificato un errore nel servizio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Si è verificato un errore sconosciuto",
    "LocalLLMError": "Si è verificato un errore nel LLM locale",
    "LocalLLMStreamError": "Si è verificato un errore nell'elaborazione dello stream del LLM locale",
    "LocalLLMConnectionError": "Impossibile connettersi al server LLM locale",
    "LocalLLMNotFound": "Endpoint LLM locale non trovato",
    "LocalLLMAPIError": "Si è verificato un errore nell'API LLM locale",
    "CustomAPIError": "Si è verificato un errore nell'API personalizzata",
    "InvalidJSON": "Formato JSON non valido"
  },
  "MessageReceiver": "Accetta istruzioni esterne",
  "MessageReceiverDescription": "Puoi istruire esternamente il personaggio AI su cosa dire utilizzando l'API.",
  "ClientID": "ID Cliente",
  "OpenSendMessagePage": "Apri pagina invio messaggi",
  "RealtimeAPIMode": "Modalità API in tempo reale",
  "RealtimeAPIModeContentType": "Tipo di invio",
  "RealtimeAPIModeVoice": "Tipo di voce",
  "AudioMode": "Modalità audio",
  "InputText": "Testo",
  "InputAudio": "Audio",
  "SearchGrounding": "Utilizza funzione di ricerca",
  "SearchGroundingDescription": "Quando si utilizza la funzione multimodale, la funzione di ricerca viene automaticamente disabilitata.",
  "UpdateRealtimeAPISettings": "Aggiorna impostazioni API in tempo reale",
  "UpdateRealtimeAPISettingsInfo": "Quando aggiorni la chiave API, l'endpoint Azure, il tipo di voce, il modello o il prompt di sistema, premi il pulsante di aggiornamento per avviare una nuova sessione WebSocket.",
  "AzureEndpoint": "Endpoint Azure",
  "Toasts": {
    "WebSocketConnectionError": "Si è verificato un errore nella connessione WebSocket",
    "WebSocketConnectionClosed": "La connessione WebSocket è stata chiusa",
    "WebSocketConnectionAttempt": "Tentativo di connessione WebSocket in corso...",
    "WebSocketConnectionSuccess": "Connessione WebSocket riuscita",
    "FunctionExecuting": "Sto eseguendo {{funcName}}",
    "FunctionExecutionFailed": "Impossibile eseguire {{funcName}}",
    "FirefoxNotSupported": "Questa funzione non è supportata in Firefox.",
    "SpeechRecognitionError": "Si è verificato un errore di riconoscimento vocale",
    "NoSpeechDetected": "Audio non rilevato.",
    "PresetSwitching": "È stato cambiato a {{presetName}}.",
    "WhisperError": "Si è verificato un errore nel riconoscimento vocale tramite Whisper",
    "UsingTool": "Utilizzando {{toolName}}"
  },
  "ContinuousMic": "Input microfono continuo",
  "ContinuousMicActive": "Input microfono continuo attivo",
  "ContinuousMicModeOn": "Modalità input microfono continuo attiva",
  "ContinuousMicModeOff": "Modalità input microfono continuo disattiva",
  "ListeningContinuously": "In attesa di input vocale...",
  "ContinuousMicInfo": "Riavvia automaticamente l'input del microfono quando l'AI finisce di parlare. Invia automaticamente dopo il tempo di silenzio impostato.\nSe il riconoscimento vocale non avviene entro il tempo impostato, l'input microfono continuo si disattiva automaticamente. Se desideri mantenerlo sempre attivo, imposta il timeout del riconoscimento vocale a 0 secondi.",
  "UsingOpenAITTS": "Usa OpenAI",
  "OpenAITTSInfo": "Stiamo utilizzando OpenAI. Supporta più lingue. Se hai selezionato OpenAI come servizio AI, non è necessario impostare la chiave API sottostante.",
  "OpenAITTSVoice": "Tipo di voce",
  "OpenAITTSModel": "Modello",
  "OpenAITTSSpeed": "Velocità parlato",
  "UsingAzureTTS": "Usa Azure OpenAI",
  "AzureTTSInfo": "Stiamo utilizzando Azure OpenAI. Supporta più lingue.",
  "SendMessage": {
    "title": "Adattatore esterno AITuberKit",
    "directSendTitle": "Fai parlare direttamente il personaggio AI",
    "directSendDescription": "Puoi far parlare direttamente al personaggio AI il messaggio inviato. Se invii più messaggi, verranno elaborati in ordine.\nViene utilizzato il modello vocale selezionato nelle impostazioni di AITuberKit.",
    "aiGenerateTitle": "Genera una risposta con l'AI e poi falla pronunciare",
    "aiGenerateDescription": "L'AI genererà una risposta dal messaggio inviato e il personaggio AI pronuncerà quella risposta. Se invii più messaggi, verranno elaborati in ordine.\nVengono utilizzati il modello AI e il modello vocale selezionati nelle impostazioni di AITuberKit.\nPuoi scegliere se utilizzare il prompt di sistema di AITuberKit o un prompt di sistema personalizzato.\nPer caricare la cronologia delle conversazioni precedenti, includi la stringa [conversation_history] in qualsiasi posizione nel prompt di sistema o nel messaggio utente.",
    "useCurrentSystemPrompt": "Utilizza il prompt di sistema di AITuberKit",
    "userInputTitle": "Invia input utente",
    "userInputDescription": "Il messaggio inviato verrà elaborato come se fosse stato inserito dal modulo di input di AITuberKit. Se invii più messaggi, verranno elaborati in ordine.\nVengono utilizzati il modello AI e il modello vocale selezionati nelle impostazioni di AITuberKit.\nVengono utilizzati il prompt di sistema e la cronologia delle conversazioni di AITuberKit."
  },
  "CannotUseVoice": "Quando la modalità API in tempo reale o la modalità audio è attiva,\nle impostazioni della voce sintetica non sono necessarie.",
  "Live2D": {
    "FileInfo": "Posiziona la cartella del modello Live2D che desideri utilizzare in public/live2d. È necessario che il file model3.json si trovi direttamente in questa cartella.\nSe non appare nelle opzioni, ricarica la pagina o verifica che il percorso della cartella sia corretto.",
    "Info": "Puoi specificare emozioni e movimenti.\nOgni emozione è controllata dal prompt. Per maggiori dettagli, consulta \"Impostazioni AI => Impostazioni personaggio\".",
    "Emotions": "Impostazioni espressioni",
    "EmotionInfo": "Le emozioni possono essere specificate separandole con virgole. In caso di più specificazioni, verrà selezionata casualmente.\nI valori predefiniti sono compatibili con i modelli forniti da AITuberKit. Se utilizzi un modello originale, inserisci valori adatti al tuo modello.\nDopo il completamento della conversazione, verrà mostrata l'espressione \"normale\".",
    "neutralEmotions": "Normale",
    "happyEmotions": "Felice",
    "sadEmotions": "Triste",
    "angryEmotions": "Arrabbiato",
    "relaxedEmotions": "Rilassato",
    "surprisedEmotions": "Sorpreso",
    "MotionGroups": "Impostazioni gruppi di movimento",
    "MotionGroupsInfo": "I movimenti vengono selezionati casualmente dal gruppo scelto.\nCome per le impostazioni delle espressioni, configurali in base al tuo modello.\n\"Inattivo\" è il movimento mostrato dopo il completamento della conversazione.",
    "SelectMotionGroup": "Seleziona gruppo di movimento",
    "idleMotionGroup": "Inattivo",
    "neutralMotionGroup": "Normale",
    "happyMotionGroup": "Felice",
    "sadMotionGroup": "Triste",
    "angryMotionGroup": "Arrabbiato",
    "relaxedMotionGroup": "Rilassato",
    "surprisedMotionGroup": "Sorpreso"
  },
  "UseVideoAsBackground": "Usa condivisione schermo o webcam come sfondo",
  "Temperature": "Temperatura",
  "MaxTokens": "Numero massimo di token",
  "MaxTokensInfo": "Il numero massimo di token varia in base al modello AI utilizzato. Verifica le specifiche di ciascun modello.",
  "CannotUseParameters": "Quando la modalità API in tempo reale o la modalità audio è attiva, non è possibile specificare i parametri Temperatura e Numero massimo di token.",
  "PresetQuestions": "Domande preimpostate",
  "PresetQuestionsInfo": "Puoi creare e registrare in anticipo più modelli di domande. Le domande registrate verranno visualizzate come pulsanti nell'interfaccia utente e, quando cliccate, verranno inserite nel campo di input della chat.",
  "EnterPresetQuestion": "Inserisci una domanda",
  "DragToReorder": "Trascina per riordinare",
  "CustomAPIEndpoint": "Endpoint API personalizzato",
  "CustomAPIEndpointInfo": "Inserisci l'URL dell'endpoint API a cui inviare le richieste POST.",
  "CustomAPIStream": "Modalità streaming",
  "CustomAPIStreamForced": "Attualmente, la modalità streaming è sempre abilitata.",
  "IncludeSystemMessages": "Includi messaggi del sistema",
  "CustomAPIHeaders": "Header personalizzati",
  "CustomAPIHeadersInfo": "Inserisci in formato JSON le informazioni degli header da includere nella richiesta API.",
  "CustomAPIBody": "Body personalizzato",
  "CustomAPIBodyInfo": "Inserisci in formato JSON le informazioni del body da includere nella richiesta API. I messaggi verranno inclusi automaticamente.",
  "CustomAPIDescription": "Nota: i messaggi verranno inclusi automaticamente nel body della richiesta. In modalità streaming, il server deve restituire text/event-stream.",
  "EditSlideScripts": "Modifica dei dialoghi",
  "PleaseSelectSlide": "Seleziona una diapositiva"
}
