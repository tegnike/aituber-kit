{
  "Description": "Informazioni sull'app",
  "BasedSettings": "Impostazioni di base",
  "AISettings": "Impostazioni AI",
  "CharacterSettings": "Impostazioni del personaggio",
  "YoutubeSettings": "Impostazioni di YouTube",
  "VoiceSettings": "Impostazioni della voce sintetizzata",
  "SlideSettings": "Impostazioni dello slide",
  "LogSettings": "Cronologia delle conversazioni",
  "OtherSettings": "Altro",
  "ExternalLinkageMode": "Modalità di collegamento esterno (versione beta)",
  "YoutubeMode": "Modalità YouTube",
  "YoutubeInfo": "Il primo carattere del commento è '#' e verrà ignorato.",
  "YoutubeAPIKey": "Chiave API YouTube",
  "YoutubeLiveID": "ID diretta YouTube",
  "ConversationContinuityMode": "Modalità continuità conversazione (Beta)",
  "ConversationContinuityModeInfo": "Quando non ci sono commenti, l'IA cerca di continuare la conversazione. Attualmente supportato solo da OpenAI, Anthropic Claude, Google Gemini.",
  "ConversationContinuityModeInfo2": "Una risposta richiede più chiamate LLM, quindi l'utilizzo dell'API potrebbe aumentare. Si prega di tenerne conto.",
  "ConversationContinuityModeInfo3": "gpt-4, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet funzionano in modo relativamente stabile.",
  "MaxPastMessages": "Numero di messaggi passati da mantenere",
  "StatusOn": "Stato: ATTIVO",
  "StatusOff": "Stato: DISATTIVO",
  "Select": "Seleziona",
  "TestVoice": "Test voce",
  "SelectAIService": "Seleziona servizio IA",
  "LocalLLM": "LLM locale",
  "SelectModel": "Seleziona modello",
  "OpenAIAPIKeyLabel": "Chiave API OpenAI",
  "AnthropicAPIKeyLabel": "Chiave API Anthropic",
  "GoogleAPIKeyLabel": "Chiave API Google Gemini",
  "AzureAPIKeyLabel": "Chiave API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "GroqAPIKeyLabel": "Chiave API Groq",
  "CohereAPIKeyLabel": "Chiave API Cohere",
  "MistralAIAPIKeyLabel": "Chiave API MistralAI",
  "PerplexityAPIKeyLabel": "Chiave API Perplexity",
  "FireworksAPIKeyLabel": "Chiave API Fireworks",
  "DifyAPIKeyLabel": "Chiave API Dify",
  "DeepSeekAPIKeyLabel": "Chiave API DeepSeek",
  "APIKeyInstruction": "Puoi ottenere la chiave API qui sotto. Inserisci la chiave API ottenuta nel modulo.",
  "LocalLLMInfo": "Il server LLM locale deve essere in esecuzione. La configurazione è la seguente.",
  "LocalLLMInfo2": "Inserisci l'URL del server LLM locale (incluso il numero di porta) e il nome del modello.",
  "GroqInfo": "L'API Groq è accessibile direttamente dal browser.",
  "DifyInfo": "Dify supporta solo i tipi chatbot e agent.",
  "DifyInfo2": "La lunghezza della cronologia conversazioni dipende dalle specifiche di Dify.",
  "DifyInfo3": "Esempio: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Se usi Dify, il prompt di sistema non verrà utilizzato. Configura il chatbot Dify.",
  "EnterURL": "URL",
  "CharacterModelLabel": "Modello personaggio",
  "CharacterModelInfo": "Il modello potrebbe richiedere tempo per caricarsi alla prima visualizzazione.",
  "OpenVRM": "Apri VRM",
  "BackgroundImage": "Immagine di sfondo",
  "ChangeBackgroundImage": "Cambia immagine di sfondo",
  "CharacterSettingsPrompt": "Prompt personaggio",
  "CharacterSettingsInfo": "Questo valore viene impostato come prompt di sistema.\nFai riferimento al prompt iniziale e specifica i tag delle emozioni per controllare le espressioni e i movimenti del personaggio. Esempio: [neutral]Buongiorno![happy]Anche oggi sarà una giornata impegnativa!",
  "characterpresetInfo": "Selezionando una preimpostazione si cambia la richiesta di caratteri.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) per le scorciatoie.\nSe si seleziona una preimpostazione tenendo premuto il tasto Shift, la richiesta di caratteri corrente viene salvata nella preimpostazione.",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Scegli motore sintesi vocale",
  "VoiceAdjustment": "Regolazione voce",
  "VoiceEngineInstruction": "Seleziona il motore di sintesi vocale che desideri utilizzare.",
  "UsingKoeiromap": "Koeiromap",
  "KoeiromapInfo": "Utilizza l'API Koeiromap di Koemotion. Supporta solo il giapponese. Vedi il link sotto per i dettagli.",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceVoxInfo": "Utilizza VOICEVOX. Supporta solo il giapponese. Usa API locale, devi scaricare e avviare l'applicazione adatta al tuo sistema.",
  "VoicevoxSpeed": "Velocità",
  "VoicevoxPitch": "Tono",
  "VoicevoxIntonation": "Intonazione",
  "UsingAivisSpeech": "AivisSpeech",
  "AivisSpeechInfo": "Utilizza AivisSpeech. Supporta solo il giapponese. Usa API locale, devi scaricare e avviare l'applicazione adatta al tuo sistema.",
  "AivisSpeechSpeaker": "Speaker",
  "AivisSpeechSpeed": "Velocità",
  "AivisSpeechPitch": "Tono",
  "AivisSpeechIntonation": "Intonazione",
  "AivisSpeechServerUrl": "URL server AivisSpeech",
  "UsingNijiVoice": "NijiVoice",
  "NijiVoiceInfo": "Utilizza API NijiVoice. Supporta solo il giapponese. La chiave API può essere ottenuta dall'URL sotto.",
  "NijiVoiceApiKey": "Chiave API NijiVoice",
  "NijiVoiceActorId": "ID attore",
  "NijiVoiceSpeed": "Velocità parlato",
  "NijiVoiceEmotionalLevel": "Livello emotivo",
  "NijiVoiceSoundDuration": "Durata audio",
  "VoicevoxServerUrl": "URL server VOICEVOX",
  "UpdateSpeakerList": "Aggiorna lista speaker",
  "UsingGoogleTTS": "Utilizzare Google Text-to-Speech",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "StyleBertVITS2Info": "Utilizza Style-Bert-VITS2. Supporta solo giapponese, inglese e cinese. Se usi API locale, scarica e avvia l'applicazione adatta. Se necessario, imposta anche la chiave API.",
  "SpeakerSelection": "Selezione speaker",
  "IncludeTimestampInUserMessage": "Includi timestamp nei messaggi utente",
  "IncludeTimestampInUserMessageInfo": "Includere il timestamp aiuta l'IA a generare risposte considerando l'ora di invio.\nInserisci la seguente stringa nel prompt di sistema:\n\n\"L'input dell'utente può includere [timestamp]. Questo è l'orario UTC al momento della richiesta, genera la risposta considerando questa informazione.\"",
  "GoogleTTSInfo": "Utilizza Google Cloud Text-to-Speech. Supporta più lingue.",
  "AuthFileInstruction": "È richiesta una chiave API o file di autenticazione. Ottienila dall'URL sotto e posizionala nella root se è un file JSON.",
  "LanguageModelURL": "Seleziona il modello linguistico dall'URL sotto.",
  "LanguageChoice": "Scelta lingua",
  "StyleBeatVITS2ServerURL": "URL server",
  "StyleBeatVITS2ApiKey": "Chiave API",
  "StyleBeatVITS2ModelID": "ID modello",
  "StyleBeatVITS2Style": "Stile",
  "StyleBeatVITS2SdpRatio": "Rapporto mix SDP/DP",
  "StyleBeatVITS2Length": "Velocità parlato",
  "ConversationHistory": "Cronologia conversazione",
  "ConversationHistoryInfo": "Le ultime {{count}} conversazioni saranno memorizzate come memoria.",
  "ConversationHistoryReset": "Reimposta cronologia conversazione",
  "NotConnectedToExternalAssistant": "Non connesso all'assistente esterno.",
  "APIKeyNotEntered": "Chiave API non inserita.",
  "ChatLog": "Log chat",
  "EnterYourQuestion": "Inserisci qui la tua domanda",
  "AnswerGenerating": "Generazione risposta",
  "AboutThisApplication": "Informazioni sull'applicazione",
  "AboutThisApplicationDescription": "Interagisci con un personaggio 3D direttamente nel browser tramite microfono o testo e sintesi vocale. Puoi cambiare il personaggio (VRM), regolare la personalità e la voce del personaggio.\nLe impostazioni possono essere modificate dal pulsante menu in alto a sinistra.",
  "AboutThisApplicationDescription2": "Se vuoi cambiare personaggio, consulta la scheda \"Impostazioni personaggio\".",
  "TechnologyIntroduction": "Introduzione tecnologia",
  "TechnologyIntroductionDescription1": "Questa applicazione è basata sul progetto <b>ChatVRM</b> di pixiv. Il codice sorgente originale è disponibile",
  "TechnologyIntroductionLink1": "qui",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Per la visualizzazione e manipolazione del modello 3D viene utilizzato",
  "TechnologyIntroductionDescription4": "Per la generazione del testo della conversazione vengono utilizzati vari LLM come",
  "TechnologyIntroductionDescription5": "Per la sintesi vocale vengono utilizzati vari motori TTS come",
  "TechnologyIntroductionDescription6": "Per maggiori dettagli, consulta questo",
  "TechnologyIntroductionLink2": "articolo esplicativo",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "Il codice sorgente di questa applicazione è condiviso su GitHub. Sei libero di modificarlo.",
  "SourceCodeDescription2": "Per l'uso commerciale, consulta il README del repository.",
  "RepositoryURL": "URL repository:",
  "DontShowIntroductionNextTime": "Non mostrare questa finestra la prossima volta",
  "Close": "CHIUDI",
  "Contact": "Contatti",
  "ContactDescription": "Per domande su questa applicazione, contattaci tramite l'indirizzo email o l'account Twitter sotto.",
  "Creator": "Creatore",
  "CreatorDescription": "Creatore: Tegan",
  "Language": "Lingua",
  "UsingGSVITTS": "GSVI TTS",
  "GSVITTSInfo": "Impostazioni GSVI TTS",
  "GSVITTSServerUrl": "Endpoint API GSVI TTS",
  "GSVITTSModelID": "ID modello GSVI TTS",
  "GSVITTSBatchSize": "Dimensione batch GSVI TTS (1 ~ 100 Maggiore è il valore, più veloce sarà l'inferenza, ma potrebbe esaurire la memoria se troppo grande)",
  "GSVITTSSpeechRate": "Velocità parlato (0.5 ~ 2.0 Maggiore è il valore, più veloce sarà)",
  "UsingElevenLabs": "ElevenLabs",
  "ElevenLabsInfo": "Utilizza l'API ElevenLabs. Supporta più lingue. La chiave API può essere ottenuta dall'URL sotto.",
  "ElevenLabsApiKey": "Chiave API ElevenLabs",
  "ElevenLabsVoiceId": "ID voce ElevenLabs",
  "ElevenLabsVoiceIdInfo": "L'ID voce può essere selezionato dall'URL sotto.",
  "CharacterName": "Nome personaggio",
  "ShowAssistantText": "Mostra riquadro risposta",
  "ShowCharacterName": "Mostra nome personaggio nel riquadro risposta",
  "ShowControlPanel": "Mostra pulsante impostazioni",
  "ShowControlPanelInfo": "Puoi visualizzare la schermata delle impostazioni premendo Cmd + . (Mac) / Ctrl + . (Windows).\nSe stai utilizzando uno smartphone, puoi anche tenere premuto il lato sinistro dello schermo per circa 1 secondo.",
  "SlideMode": "Modalità presentazione",
  "SelectedSlideDocs": "Documenti presentazione selezionati",
  "SlideModeDescription": "Questa è una modalità in cui l'IA presenta automaticamente le diapositive. Disponibile solo quando il servizio IA selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertLabel": "Conversione PDF presentazione",
  "PdfConvertDescription": "Converti PDF in dati modalità presentazione. Disponibile solo quando il servizio IA selezionato è OpenAI, Anthropic Claude o Google Gemini.",
  "PdfConvertFileUpload": "Seleziona file PDF",
  "PdfConvertFolderName": "Nome cartella salvataggio",
  "PdfConvertModelSelect": "Seleziona modello",
  "PdfConvertButton": "Converti PDF in presentazione",
  "PdfConvertLoading": "Conversione in corso...",
  "PdfConvertSuccess": "Conversione completata",
  "PdfConvertError": "Errore nella conversione",
  "PdfConvertSubmitError": "Assicurati che il file PDF, il nome della cartella e la chiave API siano configurati.",
  "LocalStorageReset": "Reimposta impostazioni",
  "LocalStorageResetInfo": "Le variabili d'ambiente hanno la priorità se impostate. La pagina verrà ricaricata.",
  "LocalStorageResetButton": "Reimposta impostazioni",
  "Errors": {
    "EmptyAPIKey": "La chiave API non è configurata",
    "AIInvalidProperty": "La configurazione del servizio IA non è corretta",
    "AIAPIError": "Si è verificato un errore durante l'esecuzione dell'API IA",
    "InvalidAIService": "Il servizio IA selezionato non è valido",
    "MethodNotAllowed": "La richiesta non è appropriata",
    "TTSServiceError": "Si è verificato un errore nel servizio TTS {{serviceName}}: {{message}}",
    "UnexpectedError": "Si è verificato un errore imprevisto",
    "LocalLLMError": "Errore LLM locale",
    "LocalLLMStreamError": "Errore stream LLM locale",
    "LocalLLMConnectionError": "Errore connessione al server LLM locale",
    "LocalLLMNotFound": "Endpoint LLM locale non trovato",
    "LocalLLMAPIError": "Errore API LLM locale",
    "EmptyLocalLLMURL": "L'URL del LLM locale non è impostato",
    "CustomAPIError": "Si è verificato un errore nell'API personalizzata",
    "InvalidJSON": "Il formato JSON non è corretto"
  },
  "MessageReceiver": "Ricevi istruzioni dall'esterno",
  "MessageReceiverDescription": "Puoi usare l'API per far parlare i personaggi IA dall'esterno.",
  "ClientID": "ID cliente",
  "OpenSendMessagePage": "Apri pagina invio messaggio",
  "RealtimeAPIMode": "Modalità API in tempo reale",
  "RealtimeAPIModeContentType": "Tipo di invio",
  "RealtimeAPIModeVoice": "Tipo di voce",
  "AudioMode": "Modalità audio",
  "InputText": "Testo",
  "InputAudio": "Audio",
  "SearchGrounding": "Usa ricerca contestuale",
  "SearchGroundingDescription": "Quando si usa la funzione multimodale, la funzione di ricerca viene disattivata automaticamente.",
  "UpdateRealtimeAPISettings": "Aggiorna impostazioni API in tempo reale",
  "UpdateRealtimeAPISettingsInfo": "Quando aggiorni la chiave API, endpoint Azure, tipo di voce, modello o prompt di sistema, premi il pulsante di aggiornamento per avviare una nuova sessione WebSocket.",
  "AzureEndpoint": "Endpoint Azure",
  "Toasts": {
    "WebSocketConnectionError": "Errore connessione WebSocket",
    "WebSocketConnectionClosed": "Connessione WebSocket chiusa",
    "WebSocketConnectionAttempt": "Tentativo connessione WebSocket...",
    "WebSocketConnectionSuccess": "Connessione WebSocket riuscita",
    "FunctionExecuting": "Esecuzione {{funcName}}",
    "FunctionExecutionFailed": "Esecuzione {{funcName}} fallita",
    "FirefoxNotSupported": "Questa funzione non è supportata in Firefox",
    "SpeechRecognitionError": "Si è verificato un errore di riconoscimento vocale",
    "PresetSwitching": "È stato cambiato a {{presetName}}.",
    "WhisperError": "Si è verificato un errore nel riconoscimento vocale tramite Whisper"
  },
  "UsingOpenAITTS": "Usando OpenAI",
  "OpenAITTSInfo": "Usando OpenAI. Supporta più lingue. Se selezioni OpenAI come servizio IA, non devi configurare la chiave API sotto.",
  "OpenAITTSVoice": "Tipo di voce",
  "OpenAITTSModel": "Modello",
  "OpenAITTSSpeed": "Velocità",
  "UsingAzureTTS": "Usando Azure OpenAI",
  "AzureTTSInfo": "Usando Azure OpenAI. Supporta più lingue.",
  "SendMessage": {
    "title": "Adattatore esterno AITuberKit",
    "directSendTitle": "Parla direttamente al personaggio IA",
    "directSendDescription": "Puoi inviare il messaggio direttamente al personaggio IA. Se vengono inviati più messaggi, vengono elaborati in ordine. Il modello vocale è quello selezionato nelle impostazioni di AITuberKit.",
    "aiGenerateTitle": "Genera risposta IA e poi parla",
    "aiGenerateDescription": "L'IA genera una risposta dal messaggio inviato e poi la pronuncia. Se vengono inviati più messaggi, vengono elaborati in ordine. Il modello IA e il modello vocale sono quelli selezionati nelle impostazioni di AITuberKit. Il prompt di sistema può essere selezionato per usare il prompt di sistema di AITuberKit o un prompt di sistema personalizzato. Se vuoi caricare la cronologia conversazioni precedente, includi la stringa [conversation_history] nel prompt di sistema o nel messaggio utente.",
    "useCurrentSystemPrompt": "Usa prompt di sistema AITuberKit",
    "userInputTitle": "Invia input utente",
    "userInputDescription": "Il messaggio inviato viene elaborato come quando viene inserito dal modulo di input di AITuberKit. Se vengono inviati più messaggi, vengono elaborati in ordine. Il modello IA e il modello vocale sono quelli selezionati nelle impostazioni di AITuberKit. Il prompt di sistema e la cronologia conversazioni sono i valori configurati in AITuberKit."
  },
  "CannotUseVoice": "Se la modalità API in tempo reale o la modalità audio è attivata,\nle impostazioni della voce sintetizzata non sono necessarie.",
  "Live2D": {
    "FileInfo": "Posiziona il modello Live2D che vuoi usare nella cartella public/live2d. Il file model3.json deve esistere nella root di questa cartella.\nSe non viene visualizzato nella selezione, ricarica la schermata o verifica che il percorso della cartella sia corretto.",
    "Info": "Puoi specificare emozioni e movimenti.\nOgni emozione è controllata dal prompt. Per maggiori dettagli, consulta \"Impostazioni IA => Impostazioni personaggio\".",
    "Emotions": "Impostazioni emozioni",
    "EmotionInfo": "Le emozioni possono essere specificate in formato separato da virgole. Se vengono specificate più emozioni, vengono selezionate casualmente.\nIl valore iniziale è per il modello fornito da AITuberKit. Se stai usando un modello originale, inserisci il valore secondo il tuo modello.\nDopo il completamento della conversazione, viene mostrata l'emozione \"Neutrale\".",
    "neutralEmotions": "Neutrale",
    "happyEmotions": "Felice",
    "sadEmotions": "Triste",
    "angryEmotions": "Arrabbiato",
    "relaxedEmotions": "Rilassato",
    "MotionGroups": "Impostazioni gruppi movimento",
    "MotionGroupsInfo": "I gruppi di movimento vengono selezionati casualmente dal gruppo selezionato.\nCome per le impostazioni emozioni, configuralo secondo il tuo modello.\n\"Idle\" è il movimento mostrato dopo il completamento della conversazione.",
    "SelectMotionGroup": "Seleziona gruppo movimento",
    "idleMotionGroup": "Inattivo",
    "neutralMotionGroup": "Neutrale",
    "happyMotionGroup": "Felice",
    "sadMotionGroup": "Triste",
    "angryMotionGroup": "Arrabbiato",
    "relaxedMotionGroup": "Rilassato",
    "surprisedEmotions": "Sorpresa",
    "surprisedMotionGroup": "Sorpresa"
  },
  "UseVideoAsBackground": "Usa schermo condiviso o webcam come sfondo",
  "Temperature": "Temperatura",
  "MaxTokens": "Numero massimo di token",
  "MaxTokensInfo": "Il numero massimo di token varia a seconda del modello AI in uso. Controlla le specifiche di ciascun modello.",
  "CannotUseParameters": "Se la modalità API in tempo reale o la modalità audio è attivata, i parametri Temperature e Max Tokens non possono essere specificati.",
  "DocumentationDescription": "Puoi trovare dettagli su come utilizzare AITuberKit e tutorial al seguente URL.",
  "PresetQuestions": "Domande preimpostate",
  "PresetQuestionsInfo": "Puoi creare e registrare in anticipo più modelli di domande. Le domande registrate verranno visualizzate come pulsanti nell'interfaccia utente e, quando cliccate, verranno impostate nella barra di input della chat.",
  "EnterPresetQuestion": "Inserisci una domanda",
  "DragToReorder": "Trascina per riordinare",
  "ShowSilenceProgressBar": "Mostra la barra di avanzamento del rilevamento del silenzio",
  "CharacterpresetInfo": "Selezionando un preset, il prompt del personaggio verrà modificato.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) per utilizzare le scorciatoie.",
  "SpeechInputSettings": "Impostazioni di input vocale",
  "SpeechRecognitionMode": "Modalità di riconoscimento vocale",
  "SpeechRecognitionModeInfo": "Puoi scegliere la modalità di riconoscimento vocale.\n\"Standard del browser\" utilizza il riconoscimento vocale integrato nel browser. \"OpenAI TTS\" utilizza l'API Text to Speech di OpenAI.\nIn generale, si consiglia di utilizzare \"Standard del browser\" poiché offre una maggiore precisione e velocità di riconoscimento. Tuttavia, se stai utilizzando un browser che non supporta l'API WebSpeech come Firefox, scegli \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Utilizza il riconoscimento vocale standard del browser",
  "WhisperSpeechRecognition": "Utilizza il riconoscimento vocale OpenAI TTS",
  "WhisperAPIKeyInfo": "In modalità Whisper è necessaria una chiave API di OpenAI. Si prega di impostare la chiave API di OpenAI nelle impostazioni AI.",
  "WhisperTranscriptionModel": "Modello di trascrizione",
  "WhisperTranscriptionModelInfo": "Puoi scegliere il modello da utilizzare per il riconoscimento vocale. Modelli più performanti possono riconoscere con maggiore precisione, ma potrebbero comportare costi API più elevati.",
  "InitialSpeechTimeout": "Timeout per il riconoscimento vocale",
  "InitialSpeechTimeoutInfo": "Imposta il tempo di attesa fino al rilevamento della prima emissione dopo l'inizio del riconoscimento vocale. Se non viene rilevata alcuna emissione entro questo tempo, il riconoscimento vocale si fermerà automaticamente.\nImpostando a 0 secondi, il tempo di attesa diventa illimitato.",
  "Milliseconds": "Millisecondi",
  "ContinuousMic": "Input microfono continuo",
  "ContinuousMicActive": "Input microfono continuo attivo",
  "ContinuousMicModeOn": "La modalità di input microfono continuo è attivata",
  "ContinuousMicModeOff": "La modalità di input microfono continuo è disattivata",
  "ListeningContinuously": "In attesa di input vocale...",
  "ContinuousMicInfo": "Il microfono riprenderà automaticamente l'input quando l'AI termina di parlare. Verrà inviato automaticamente dopo il tempo di silenzio impostato.\nSe il tempo impostato viene superato senza riconoscimento vocale, l'input microfono continuo si disattiverà automaticamente, quindi se desideri mantenerlo sempre attivo, imposta il timeout per il riconoscimento vocale a 0 secondi.",
  "CustomAPIEndpoint": "Endpoint API personalizzato",
  "CustomAPIEndpointInfo": "Inserisci l'URL dell'endpoint API a cui inviare la richiesta POST.",
  "CustomAPIStream": "Modalità streaming",
  "CustomAPIStreamForced": "Attualmente, la modalità streaming è sempre attivata.",
  "CustomAPIHeaders": "Intestazioni personalizzate",
  "CustomAPIHeadersInfo": "Inserisci le informazioni delle intestazioni da includere nella richiesta API in formato JSON.",
  "CustomAPIBody": "Corpo personalizzato",
  "CustomAPIBodyInfo": "Inserisci le informazioni del corpo da includere nella richiesta API in formato JSON. I messaggi verranno inclusi automaticamente.",
  "CustomAPIDescription": "Nota: i messaggi vengono inclusi automaticamente nel corpo della richiesta. Nella modalità streaming, il server deve restituire text/event-stream.",
  "ShowCharacterPresetMenu": "Mostra il pulsante del menu dei preset del personaggio",
  "SpeechRecognitionModeDisabledInfo": "Se la modalità audio è attivata, è disponibile solo il riconoscimento vocale del browser.\nInoltre, nella modalità API in tempo reale, è disponibile solo il riconoscimento vocale del browser e la funzione di timeout per il riconoscimento vocale sarà disabilitata."
}