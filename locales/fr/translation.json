{
  "Description": "À propos de l'application",
  "BasedSettings": "Paramètres de base",
  "AISettings": "Paramètres de l'IA",
  "CharacterSettings": "Paramètres du personnage",
  "YoutubeSettings": "Paramètres YouTube",
  "VoiceSettings": "Paramètres de synthèse vocale",
  "SlideSettings": "Paramètres de diaporama",
  "LogSettings": "Historique des conversations",
  "OtherSettings": "Autres",
  "ExternalLinkageMode": "Mode de liaison externe (version bêta)",
  "YoutubeMode": "Mode YouTube",
  "YoutubeInfo": "Le premier caractère du commentaire est '#' et sera ignoré.",
  "YoutubeAPIKey": "Clé API YouTube",
  "YoutubeLiveID": "ID en direct YouTube",
  "ConversationContinuityMode": "Mode de continuité de conversation (Beta)",
  "ConversationContinuityModeInfo": "Quand il n'y a pas de commentaire, l'IA essaie de continuer la conversation. Actuellement uniquement OpenAI, Anthropic Claude, Google Gemini sont supportés.",
  "ConversationContinuityModeInfo2": "Une réponse appelle LLM plusieurs fois, donc l'utilisation de l'API peut augmenter. Veuillez en tenir compte.",
  "ConversationContinuityModeInfo3": "gpt-4, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet fonctionnent relativement stablement.",
  "MaxPastMessages": "Nombre de messages passés à conserver",
  "StatusOn": "Statut : ACTIVÉ",
  "StatusOff": "Statut : DÉSACTIVÉ",
  "Select": "Sélectionner",
  "TestVoice": "Tester la voix",
  "SelectAIService": "Sélectionner le service IA",
  "LocalLLM": "LLM local",
  "SelectModel": "Sélectionner le modèle",
  "OpenAIAPIKeyLabel": "Clé API OpenAI",
  "AnthropicAPIKeyLabel": "Clé API Anthropic",
  "GoogleAPIKeyLabel": "Clé API Google Gemini",
  "AzureAPIKeyLabel": "Clé API Azure OpenAI",
  "AzureAPIURL": "URL API Azure OpenAI",
  "GroqAPIKeyLabel": "Clé API Groq",
  "CohereAPIKeyLabel": "Clé API Cohere",
  "MistralAIAPIKeyLabel": "Clé API MistralAI",
  "PerplexityAPIKeyLabel": "Clé API Perplexity",
  "FireworksAPIKeyLabel": "Clé API Fireworks",
  "DifyAPIKeyLabel": "Clé API Dify",
  "DeepSeekAPIKeyLabel": "Clé API DeepSeek",
  "APIKeyInstruction": "Vous pouvez obtenir la clé API ci-dessous. Entrez la clé API obtenue dans le formulaire.",
  "LocalLLMInfo": "Le serveur LLM local doit être en cours d'exécution. La configuration est la suivante.",
  "LocalLLMInfo2": "Veuillez entrer l'URL du serveur LLM local (y compris le numéro de port) et le nom du modèle.",
  "GroqInfo": "L'API Groq est accessible directement depuis le navigateur.",
  "DifyInfo": "Dify ne prend en charge que les types chatbot et agent.",
  "DifyInfo2": "La longueur de l'historique des conversations dépend des spécifications de Dify.",
  "DifyInfo3": "Exemple : https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Si vous utilisez Dify, l'invite système ne sera pas utilisée. Veuillez configurer le chatbot Dify.",
  "EnterURL": "URL",
  "CharacterModelLabel": "Modèle de personnage",
  "CharacterModelInfo": "Le modèle peut prendre du temps à charger lors du premier affichage.",
  "OpenVRM": "Ouvrir VRM",
  "BackgroundImage": "Image de fond",
  "ChangeBackgroundImage": "Changer l'image de fond",
  "CharacterSettingsPrompt": "Invite de personnage",
  "CharacterSettingsInfo": "Cette valeur est définie comme l'invite système.\nVeuillez vous référer à l'invite initiale et spécifier les balises d'émotion pour contrôler les expressions et les mouvements du personnage. Exemple : [neutral]Bonjour![happy]Aujourd'hui est aussi une journée difficile!",
  "characterpresetInfo": "La sélection d'un préréglage modifie l'invite de caractères.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) pour les raccourcis.\nLa sélection d'un préréglage tout en maintenant la touche Shift enfoncée permet d'enregistrer l'invite de caractères actuelle dans le préréglage.",
  "Characterpreset1": "Préréglage 1",
  "Characterpreset2": "Préréglage 2",
  "Characterpreset3": "Préréglage 3",
  "Characterpreset4": "Préréglage 4",
  "Characterpreset5": "Préréglage 5",
  "SyntheticVoiceEngineChoice": "Choisir le moteur de synthèse vocale",
  "VoiceAdjustment": "Ajustement de la voix",
  "VoiceEngineInstruction": "Sélectionnez le moteur de synthèse vocale que vous souhaitez utiliser.",
  "UsingKoeiromap": "Koeiromap",
  "KoeiromapInfo": "Utilisation de l'API Koeiromap de Koemotion. Ne prend en charge que le japonais. Pour plus de détails, veuillez consulter le lien ci-dessous.",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceVoxInfo": "Utilisation de VOICEVOX. Ne prend en charge que le japonais. Utilise une API locale, vous devez télécharger et lancer l'application qui convient à votre environnement depuis le site ci-dessous.",
  "VoicevoxSpeed": "Vitesse",
  "VoicevoxPitch": "Hauteur",
  "VoicevoxIntonation": "Intonation",
  "UsingAivisSpeech": "AivisSpeech",
  "AivisSpeechInfo": "Utilisation d'AivisSpeech. Ne prend en charge que le japonais. Utilise une API locale, vous devez télécharger et lancer l'application qui convient à votre environnement depuis le site ci-dessous.",
  "AivisSpeechSpeaker": "Locuteur",
  "AivisSpeechSpeed": "Vitesse",
  "AivisSpeechPitch": "Hauteur",
  "AivisSpeechIntonation": "Intonation",
  "AivisSpeechServerUrl": "URL du serveur AivisSpeech",
  "UsingNijiVoice": "NijiVoice",
  "NijiVoiceInfo": "L'API NijiVoice est utilisée. Ne prend en charge que le japonais. La clé API peut être obtenue depuis l'URL ci-dessous.",
  "NijiVoiceApiKey": "Clé API NijiVoice",
  "NijiVoiceActorId": "ID de l'acteur",
  "NijiVoiceSpeed": "Vitesse de parole",
  "NijiVoiceEmotionalLevel": "Niveau émotionnel",
  "NijiVoiceSoundDuration": "Durée du son",
  "VoicevoxServerUrl": "URL du serveur VOICEVOX",
  "UpdateSpeakerList": "Mettre à jour la liste des locuteurs",
  "UsingGoogleTTS": "Utiliser Google Text-to-Speech",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "StyleBertVITS2Info": "Utilisation de Style-Bert-VITS2. Ne prend en charge que le japonais, l'anglais et le chinois. Si vous utilisez une API locale, vous devez télécharger et lancer l'application qui convient à votre environnement depuis le site ci-dessous. Veuillez également configurer une clé API si nécessaire.",
  "SpeakerSelection": "Sélection du locuteur",
  "IncludeTimestampInUserMessage": "Inclure l'horodatage dans le message utilisateur",
  "IncludeTimestampInUserMessageInfo": "En incluant des horodatages dans les messages utilisateur, l'IA peut générer des réponses en tenant compte du temps.\nVeuillez inclure le texte suivant dans votre invite système :\n\n\"Les entrées utilisateur peuvent inclure [timestamp]. Cela représente l'heure UTC au moment de la requête, veuillez donc générer des réponses en tenant compte de cet horodatage.\"",
  "GoogleTTSInfo": "Utilisation de Google Cloud Text-to-Speech. Prend en charge plusieurs langues.",
  "AuthFileInstruction": "Une clé API ou un fichier d'authentification est requis. Obtenez-le depuis l'URL ci-dessous et placez-le dans le dossier racine du dépôt s'il s'agit d'un fichier JSON.",
  "LanguageModelURL": "Sélectionnez le modèle de langue depuis l'URL ci-dessous.",
  "LanguageChoice": "Choix de la langue",
  "StyleBeatVITS2ServerURL": "URL du serveur",
  "StyleBeatVITS2ApiKey": "Clé API",
  "StyleBeatVITS2ModelID": "ID du modèle",
  "StyleBeatVITS2Style": "Style",
  "StyleBeatVITS2SdpRatio": "Ratio de mixage SDP/DP",
  "StyleBeatVITS2Length": "Débit de parole",
  "ConversationHistory": "Historique des conversations",
  "ConversationHistoryInfo": "Les {{count}} dernières conversations seront conservées en mémoire.",
  "ConversationHistoryReset": "Réinitialiser l'historique des conversations",
  "NotConnectedToExternalAssistant": "Non connecté à un assistant externe.",
  "APIKeyNotEntered": "La clé API n'est pas saisie.",
  "ChatLog": "Journal des conversations",
  "EnterYourQuestion": "Entrez votre question ici",
  "AnswerGenerating": "Génération de la réponse",
  "AboutThisApplication": "À propos de cette application",
  "AboutThisApplicationDescription": "Profitez de conversations avec un personnage 3D directement dans votre navigateur web, en utilisant le microphone ou la saisie de texte et la synthèse vocale. Vous pouvez également changer le personnage (VRM), ajuster sa personnalité et modifier sa voix.<br />Les paramètres peuvent être modifiés depuis le bouton menu en haut à gauche.",
  "AboutThisApplicationDescription2": "Si vous souhaitez changer le personnage, veuillez consulter l'onglet \"Paramètres de personnage\".",
  "TechnologyIntroduction": "Introduction à la technologie",
  "TechnologyIntroductionDescription1": "Cette application a été créée en modifiant le <b>ChatVRM</b> de pixiv. Le code source original peut être trouvé",
  "TechnologyIntroductionLink1": "ici",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "Pour l'affichage et la manipulation des modèles 3D,",
  "TechnologyIntroductionDescription4": "est utilisé. Pour générer le texte de conversation, divers LLM tels que",
  "TechnologyIntroductionDescription5": "sont utilisés. Pour la synthèse vocale, divers moteurs TTS comme",
  "TechnologyIntroductionDescription6": "sont utilisés. Pour plus de détails, consultez cet",
  "TechnologyIntroductionLink2": "article explicatif",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "Le code source de cette application est disponible publiquement sur GitHub. N'hésitez pas à le modifier et l'adapter comme vous le souhaitez.",
  "SourceCodeDescription2": "Pour une utilisation commerciale, veuillez consulter le README du même dépôt.",
  "RepositoryURL": "URL du dépôt :",
  "DontShowIntroductionNextTime": "Ne plus afficher cette boîte de dialogue",
  "Close": "FERMER",
  "Contact": "Contact",
  "ContactDescription": "Veuillez me contacter via l'adresse e-mail ou le compte Twitter ci-dessous concernant cette application.",
  "Creator": "Créateur",
  "CreatorDescription": "Créateur : Tegan",
  "Language": "Langue",
  "UsingGSVITTS": "GSVI TTS",
  "GSVITTSInfo": "Paramètres GSVI TTS",
  "GSVITTSServerUrl": "API endpoint GSVI TTS",
  "GSVITTSModelID": "ID du modèle GSVI TTS",
  "GSVITTSBatchSize": "Taille du lot GSVI TTS (1 ~ 100 Plus la valeur est grande, plus la vitesse d'inférence est rapide, mais cela peut épuiser la mémoire si trop grand.)",
  "GSVITTSSpeechRate": "Débit de parole (0.5 ~ 2.0 Plus la valeur est grande, plus c'est rapide.)",
  "UsingElevenLabs": "ElevenLabs",
  "ElevenLabsInfo": "L'API ElevenLabs est utilisée. Elle prend en charge plusieurs langues. La clé API peut être obtenue depuis l'URL ci-dessous.",
  "ElevenLabsApiKey": "Clé API ElevenLabs",
  "ElevenLabsVoiceId": "ID de voix ElevenLabs",
  "ElevenLabsVoiceIdInfo": "L'ID de voix peut être sélectionné depuis l'URL ci-dessous.",
  "CharacterName": "Nom du personnage",
  "ShowAssistantText": "Afficher la boîte de réponse",
  "ShowCharacterName": "Afficher le nom du personnage dans la boîte de réponse",
  "ShowControlPanel": "Afficher le bouton des paramètres",
  "ShowControlPanelInfo": "L'écran des paramètres peut être affiché avec Cmd + . (Mac) / Ctrl + . (Windows).\nSi vous utilisez un smartphone, vous pouvez également le faire en maintenant enfoncé le coin supérieur gauche de l'écran (environ 1 seconde).",
  "SlideMode": "Mode diaporama",
  "SelectedSlideDocs": "Documents diaporama sélectionnés",
  "SlideModeDescription": "C'est un mode où l'IA présente automatiquement des diapositives. Il n'est disponible que lorsque le service IA sélectionné est OpenAI, Anthropic Claude ou Google Gemini.",
  "PdfConvertLabel": "Conversion de diapositives PDF",
  "PdfConvertDescription": "Convertir PDF en données de mode diaporama. Disponible uniquement lorsque le service IA sélectionné est OpenAI, Anthropic Claude ou Google Gemini.",
  "PdfConvertFileUpload": "Sélectionner le fichier PDF",
  "PdfConvertFolderName": "Nom du dossier de sauvegarde",
  "PdfConvertModelSelect": "Sélectionner le modèle",
  "PdfConvertButton": "Convertir PDF en diapositives",
  "PdfConvertLoading": "Conversion en cours...",
  "PdfConvertSuccess": "Conversion terminée",
  "PdfConvertError": "Échec de la conversion",
  "PdfConvertSubmitError": "Veuillez vous assurer que le fichier PDF, le nom du dossier et la clé API sont définis.",
  "LocalStorageReset": "Réinitialiser les paramètres",
  "LocalStorageResetInfo": "Les variables d'environnement sont prioritaires si définies. La page sera rechargée.",
  "LocalStorageResetButton": "Réinitialiser les paramètres",
  "Errors": {
    "EmptyAPIKey": "La clé API n'est pas définie",
    "AIInvalidProperty": "Les paramètres du service IA sont incorrects",
    "AIAPIError": "Une erreur s'est produite lors de l'exécution de l'API IA",
    "InvalidAIService": "Le service IA sélectionné n'est pas valide",
    "MethodNotAllowed": "La requête n'est pas appropriée",
    "TTSServiceError": "Une erreur s'est produite dans le service TTS {{serviceName}} : {{message}}",
    "UnexpectedError": "Une erreur inattendue s'est produite",
    "LocalLLMError": "Erreur LLM locale",
    "LocalLLMStreamError": "Erreur de flux LLM local",
    "LocalLLMConnectionError": "Erreur de connexion au serveur LLM local",
    "LocalLLMNotFound": "Point de terminaison LLM local non trouvé",
    "LocalLLMAPIError": "Erreur API LLM locale",
    "EmptyLocalLLMURL": "L'URL du LLM local n'est pas définie",
    "CustomAPIError": "Une erreur s'est produite avec l'API personnalisée",
    "InvalidJSON": "Le format JSON n'est pas correct"
  },
  "MessageReceiver": "Recevoir des instructions de l'extérieur",
  "MessageReceiverDescription": "Vous pouvez utiliser l'API pour faire parler les personnages IA depuis l'extérieur.",
  "ClientID": "ID client",
  "OpenSendMessagePage": "Ouvrir la page d'envoi de message",
  "RealtimeAPIMode": "Mode API en temps réel",
  "RealtimeAPIModeContentType": "Type d'envoi",
  "RealtimeAPIModeVoice": "Type de voix",
  "AudioMode": "Mode audio",
  "InputText": "Texte",
  "InputAudio": "Audio",
  "SearchGrounding": "Utiliser la recherche contextuelle",
  "SearchGroundingDescription": "Lors de l'utilisation de la fonction multimodale, la fonction de recherche est automatiquement désactivée.",
  "UpdateRealtimeAPISettings": "Mettre à jour les paramètres API en temps réel",
  "UpdateRealtimeAPISettingsInfo": "Lors de la mise à jour de la clé API, du point de terminaison Azure, du type de voix, du modèle ou de l'invite système, veuillez appuyer sur le bouton de mise à jour pour démarrer une nouvelle session WebSocket.",
  "AzureEndpoint": "Point de terminaison Azure",
  "Toasts": {
    "WebSocketConnectionError": "Erreur survenue dans la connexion WebSocket",
    "WebSocketConnectionClosed": "Connexion WebSocket fermée",
    "WebSocketConnectionAttempt": "Tentative de connexion WebSocket...",
    "WebSocketConnectionSuccess": "Connexion WebSocket réussie",
    "FunctionExecuting": "Exécution de {{funcName}}",
    "FunctionExecutionFailed": "L'exécution de {{funcName}} a échoué",
    "FirefoxNotSupported": "Cette fonctionnalité n'est pas prise en charge sur Firefox",
    "SpeechRecognitionError": "Une erreur de reconnaissance vocale s'est produite",
    "PresetSwitching": "Vous avez basculé sur {{presetName}}.",
    "WhisperError": "Une erreur s'est produite lors de la reconnaissance vocale avec Whisper"
  },
  "UsingOpenAITTS": "Utilisation d'OpenAI",
  "OpenAITTSInfo": "Utilisation d'OpenAI. Prend en charge plusieurs langues. Si vous sélectionnez OpenAI comme service IA, vous n'avez pas besoin de définir la clé API ci-dessous.",
  "OpenAITTSVoice": "Type de voix",
  "OpenAITTSModel": "Modèle",
  "OpenAITTSSpeed": "Vitesse",
  "UsingAzureTTS": "Utilisation d'Azure OpenAI",
  "AzureTTSInfo": "Utilisation d'Azure OpenAI. Prend en charge plusieurs langues.",
  "SendMessage": {
    "title": "Adaptateur externe AITuberKit",
    "directSendTitle": "Parler directement au personnage IA",
    "directSendDescription": "Vous pouvez envoyer le message directement au personnage IA. Si plusieurs messages sont envoyés, ils sont traités dans l'ordre. Le modèle de voix est celui sélectionné dans les paramètres AITuberKit.",
    "aiGenerateTitle": "Générer une réponse IA puis parler",
    "aiGenerateDescription": "L'IA génère une réponse à partir du message envoyé puis la prononce. Si plusieurs messages sont envoyés, ils sont traités dans l'ordre. Le modèle IA et le modèle de voix sont ceux sélectionnés dans les paramètres AITuberKit. L'invite système peut être sélectionnée pour utiliser l'invite système AITuberKit ou une invite système personnalisée. Si vous voulez charger l'historique des conversations passées, incluez la chaîne [conversation_history] dans l'invite système ou le message utilisateur.",
    "useCurrentSystemPrompt": "Utiliser l'invite système AITuberKit",
    "userInputTitle": "Envoyer une entrée utilisateur",
    "userInputDescription": "Le message envoyé est traité de la même manière que lorsqu'il est saisi depuis le formulaire d'entrée AITuberKit. Si plusieurs messages sont envoyés, ils sont traités dans l'ordre. Le modèle IA et le modèle de voix sont ceux sélectionnés dans les paramètres AITuberKit. L'invite système et l'historique des conversations sont les valeurs définies dans AITuberKit."
  },
  "CannotUseVoice": "En mode API en temps réel ou en mode audio,\nles paramètres de synthèse vocale ne sont pas nécessaires.",
  "Live2D": {
    "FileInfo": "Placez le modèle Live2D que vous souhaitez utiliser dans le dossier public/live2d. Le fichier model3.json doit exister à la racine de ce dossier.\nS'il n'est pas affiché dans la sélection, veuillez recharger l'écran ou vérifier si le chemin du dossier est correct.",
    "Info": "Vous pouvez spécifier les émotions et les mouvements.\nChaque émotion est contrôlée par l'invite. Pour plus de détails, veuillez consulter \"Paramètres IA => Paramètres de personnage\".",
    "Emotions": "Paramètres d'émotion",
    "EmotionInfo": "Les émotions peuvent être spécifiées au format séparé par des virgules. Si plusieurs émotions sont spécifiées, elles sont sélectionnées aléatoirement.\nLa valeur initiale est pour le modèle fourni par AITuberKit. Si vous utilisez un modèle original, veuillez entrer la valeur selon votre modèle.\nAprès la fin de la conversation, l'émotion \"Neutre\" est affichée.",
    "neutralEmotions": "Neutre",
    "happyEmotions": "Heureux",
    "sadEmotions": "Triste",
    "angryEmotions": "En colère",
    "relaxedEmotions": "Détendu",
    "MotionGroups": "Paramètres des groupes de mouvement",
    "MotionGroupsInfo": "Les groupes de mouvement sont sélectionnés aléatoirement dans le groupe sélectionné.\nComme pour les paramètres d'émotion, veuillez les définir selon votre modèle.\n\"Idle\" est le mouvement affiché après la fin de la conversation.",
    "SelectMotionGroup": "Sélectionner le groupe de mouvement",
    "idleMotionGroup": "Inactif",
    "neutralMotionGroup": "Neutre",
    "happyMotionGroup": "Heureux",
    "sadMotionGroup": "Triste",
    "angryMotionGroup": "En colère",
    "relaxedMotionGroup": "Détendu",
    "surprisedEmotions": "Surprise",
    "surprisedMotionGroup": "Surprise"
  },
  "UseVideoAsBackground": "Utiliser l'écran partagé ou la webcam comme arrière-plan",
  "Temperature": "Température",
  "MaxTokens": "Nombre maximal de tokens",
  "MaxTokensInfo": "Le nombre maximal de tokens varie en fonction du modèle AI utilisé. Veuillez vérifier les spécifications de chaque modèle.",
  "CannotUseParameters": "Si le mode API en temps réel ou le mode audio est activé, les paramètres Temperature et Max Tokens ne peuvent pas être spécifiés.",
  "DocumentationDescription": "Vous pouvez consulter des instructions détaillées et des tutoriels sur AITuberKit à l'URL ci-dessous.",
  "PresetQuestions": "Questions prédéfinies",
  "PresetQuestionsInfo": "Vous pouvez créer et enregistrer plusieurs modèles de questions à l'avance. Les questions enregistrées seront affichées sous forme de boutons dans l'interface utilisateur, et en cliquant dessus, elles seront insérées dans le champ de saisie de chat.",
  "EnterPresetQuestion": "Veuillez entrer une question",
  "DragToReorder": "Faites glisser pour réorganiser",
  "ShowSilenceProgressBar": "Afficher la barre de progression de détection de silence",
  "CharacterpresetInfo": "En sélectionnant un préréglage, l'invite de personnage sera modifiée.\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows) pour les raccourcis.",
  "SpeechInputSettings": "Paramètres d'entrée vocale",
  "SpeechRecognitionMode": "Mode de reconnaissance vocale",
  "SpeechRecognitionModeInfo": "Vous pouvez choisir le mode de reconnaissance vocale.\n\"Standard du navigateur\" utilise la reconnaissance vocale intégrée au navigateur. \"OpenAI TTS\" utilise l'API Text to Speech d'OpenAI.\nEn général, le mode \"Standard du navigateur\" est recommandé car il est plus précis et plus rapide. Cependant, si vous utilisez un navigateur qui ne prend pas en charge l'API WebSpeech comme Firefox, choisissez \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Utiliser la reconnaissance vocale standard du navigateur",
  "WhisperSpeechRecognition": "Utiliser la reconnaissance vocale OpenAI TTS",
  "WhisperAPIKeyInfo": "Le mode Whisper nécessite une clé API OpenAI. Veuillez configurer la clé API d'OpenAI dans les paramètres de l'IA.",
  "WhisperTranscriptionModel": "Modèle de transcription",
  "WhisperTranscriptionModelInfo": "Vous pouvez choisir le modèle à utiliser pour la reconnaissance vocale. Plus le modèle est performant, plus il est précis, mais cela peut augmenter le coût de l'API.",
  "InitialSpeechTimeout": "Délai d'expiration de la reconnaissance vocale",
  "InitialSpeechTimeoutInfo": "Définissez le temps d'attente jusqu'à ce que la première parole soit détectée après le début de la reconnaissance vocale. Si aucune parole n'est détectée dans ce délai, la reconnaissance vocale s'arrête automatiquement.\nSi vous le définissez à 0 secondes, le temps d'attente sera illimité.",
  "Milliseconds": "Millisecondes",
  "ContinuousMic": "Entrée microphone continue",
  "ContinuousMicActive": "Entrée microphone continue active",
  "ContinuousMicModeOn": "Le mode d'entrée microphone continue est activé",
  "ContinuousMicModeOff": "Le mode d'entrée microphone continue est désactivé",
  "ListeningContinuously": "En attente d'entrée vocale...",
  "ContinuousMicInfo": "Le microphone se réactivera automatiquement lorsque la parole de l'IA sera terminée. Il sera automatiquement envoyé après le temps de silence défini.\nSi le temps défini est dépassé sans détection de parole, l'entrée microphone continue sera automatiquement désactivée. Si vous souhaitez qu'elle reste toujours activée, définissez le délai d'expiration de la reconnaissance vocale à 0 secondes.",
  "CustomAPIEndpoint": "Point de terminaison API personnalisé",
  "CustomAPIEndpointInfo": "Veuillez entrer l'URL du point de terminaison API où envoyer la requête POST.",
  "CustomAPIStream": "Mode de streaming",
  "CustomAPIStreamForced": "Actuellement, le mode de streaming est toujours activé.",
  "CustomAPIHeaders": "En-têtes personnalisés",
  "CustomAPIHeadersInfo": "Veuillez entrer les informations d'en-tête à inclure dans la requête API au format JSON.",
  "CustomAPIBody": "Corps personnalisé",
  "CustomAPIBodyInfo": "Veuillez entrer les informations du corps à inclure dans la requête API au format JSON. Les messages seront automatiquement inclus.",
  "CustomAPIDescription": "Remarque : les messages sont automatiquement inclus dans le corps de la requête. En mode streaming, le serveur doit renvoyer text/event-stream.",
  "ShowCharacterPresetMenu": "Afficher le bouton du menu des préréglages de personnage",
  "SpeechRecognitionModeDisabledInfo": "Lorsque le mode audio est activé, seule la reconnaissance vocale du navigateur est disponible.\nDe plus, en mode API en temps réel, seule la reconnaissance vocale du navigateur est disponible et la fonction de délai d'expiration de la reconnaissance vocale est désactivée."
}
