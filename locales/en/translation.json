{
  "Description": "■ About the App",
  "BasedSettings": "■ Basic Settings",
  "AISettings": "■ AI Settings",
  "CharacterSettings": "■ Character Settings",
  "YoutubeSettings": "■ YouTube Settings",
  "VoiceSettings": "■ Voice Settings",
  "SlideSettings": "■ Slide Settings",
  "LogSettings": "■ Conversation History",
  "OtherSettings": "■ Others",
  "ExternalLinkageMode": "External Linkage Mode (WebSocket)",
  "YoutubeMode": "YouTube Mode",
  "YoutubeInfo": "Comments starting with '#' are ignored.",
  "YoutubeAPIKey": "YouTube API Key",
  "YoutubeLiveID": "YouTube Live ID",
  "ConversationContinuityMode": "Conversation Continuity Mode (Beta)",
  "ConversationContinuityModeInfo": "This mode allows the AI to continue the conversation on its own when there are no comments. Currently supported by OpenAI, Anthropic Claude, and Google Gemini.",
  "ConversationContinuityModeInfo2": "Since multiple LLM calls are made in one response, API usage fees may increase. Please be careful.",
  "ConversationContinuityModeInfo3": "Works relatively stable with gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "MaxPastMessages": "Number of Past Messages to Retain",
  "StatusOn": "Status: ON",
  "StatusOff": "Status: OFF",
  "Select": "Please select",
  "TestVoice": "Test the Voice",
  "SelectAIService": "Select AI Service",
  "LocalLLM": "Local LLM",
  "SelectModel": "Select Model",
  "OpenAIAPIKeyLabel": "OpenAI API Key",
  "AnthropicAPIKeyLabel": "Anthropic API Key",
  "GoogleAPIKeyLabel": "Google Gemini API Key",
  "AzureAPIKeyLabel": "Azure OpenAI API Key",
  "AzureAPIURL": "Azure OpenAI API URL",
  "GroqAPIKeyLabel": "Groq API Key",
  "CohereAPIKeyLabel": "Cohere API Key",
  "MistralAIAPIKeyLabel": "MistralAI API Key",
  "PerplexityAPIKeyLabel": "Perplexity API Key",
  "FireworksAPIKeyLabel": "Fireworks API Key",
  "DifyAPIKeyLabel": "Dify API Key",
  "DeepSeekAPIKeyLabel": "DeepSeek API Key",
  "APIKeyInstruction": "API keys can be obtained from the link below. Please enter the obtained API key in the form.",
  "LocalLLMInfo": "A local LLM server needs to be running.",
  "LocalLLMInfo2": "Please enter the URL (including port number) and model name of the local LLM.",
  "GroqInfo": "Groq API is accessed directly from the browser.",
  "DifyInfo": "Dify supports only chatbot or agent types.",
  "DifyInfo2": "The length of conversation history depends on the Dify chatbot settings.",
  "DifyInfo3": "Example: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "When using Dify, this system prompt is not used. Please set it in the Dify chatbot.",
  "EnterURL": "Enter URL",
  "CharacterModelLabel": "Character Model",
  "CharacterModelInfo": "Depending on the model, it may take time to load on initial display.",
  "OpenVRM": "Open VRM",
  "BackgroundImage": "Background Image",
  "ChangeBackgroundImage": "Change Background Image",
  "CharacterSettingsPrompt": "Character Prompt",
  "CharacterSettingsInfo": "This value is set as a system prompt.\nBy specifying emotion tags based on the initial prompt, you can control the character's expressions and motions. Example: [neutral]Good morning![happy]Thank you for your hard work today!",
  "CharacterSettingsReset": "Reset Character Settings",
  "SyntheticVoiceEngineChoice": "Select Synthetic Voice Engine",
  "VoiceAdjustment": "Voice Adjustment",
  "VoiceEngineInstruction": "Please select the synthetic voice engine to use.",
  "UsingKoeiromap": "Using Koeiromap",
  "KoeiromapInfo": "Using Koemotion's Koeiromap API. Supports Japanese only. For details, please see below.",
  "UsingVoiceVox": "Using VOICEVOX",
  "VoiceVoxInfo": "Using VOICEVOX. Supports Japanese only. Since it uses a local API, you need to download and start the app suitable for your environment from the site below.",
  "VoicevoxSpeed": "Speech Speed",
  "VoicevoxPitch": "Pitch",
  "VoicevoxIntonation": "Intonation",
  "UsingAivisSpeech": "Using AivisSpeech",
  "AivisSpeechInfo": "Using AivisSpeech. Supports Japanese only. Since it uses a local API, you need to download and start the app suitable for your environment from the site below.",
  "AivisSpeechSpeaker": "Speaker",
  "AivisSpeechSpeed": "Speech Speed",
  "AivisSpeechPitch": "Pitch",
  "AivisSpeechIntonation": "Intonation",
  "AivisSpeechServerUrl": "AivisSpeech Server URL",
  "UsingNijiVoice": "Using Niji Voice",
  "NijiVoiceInfo": "Using Niji Voice API. Supports Japanese only. Please obtain the API key from the URL below.",
  "NijiVoiceApiKey": "Niji Voice API Key",
  "NijiVoiceActorId": "Speaker ID",
  "NijiVoiceSpeed": "Speech Speed",
  "NijiVoiceEmotionalLevel": "Emotional Level",
  "NijiVoiceSoundDuration": "Sound Duration",
  "VoicevoxServerUrl": "VOICEVOX Server URL",
  "UpdateSpeakerList": "Update Speaker List",
  "UsingGoogleTTS": "Using Google TTS",
  "UsingStyleBertVITS2": "Using Style-Bert-VITS2",
  "StyleBertVITS2Info": "Using Style-Bert-VITS2. Supports only Japanese, English, and Chinese. If using a local API, download and start the app suitable for your environment from the site below. Set the API key if necessary.",
  "SpeakerSelection": "Select Voice Type",
  "IncludeTimestampInUserMessage": "Include Timestamp in User Message",
  "IncludeTimestampInUserMessageInfo": "By including a timestamp in the user's message, the AI can generate responses considering the time.\nPlease include the following text in the system prompt.\n\n\"User input may be requested with a [timestamp]. This represents the time in the UTC timezone at the time of the request, so please generate a response considering that time.\"",
  "GoogleTTSInfo": "Using Google Cloud Text-to-Speech. Supports multiple languages.",
  "AuthFileInstruction": "An API key or authentication JSON file is required. Obtain it from below, and if it's a JSON file, place it in the root folder of the repository named credentials.json.",
  "LanguageModelURL": "Select the language model from the URL below.",
  "LanguageChoice": "Language Choice",
  "StyleBeatVITS2ServerURL": "Server URL",
  "StyleBeatVITS2ApiKey": "API Key",
  "StyleBeatVITS2ModelID": "Model ID",
  "StyleBeatVITS2Style": "Style",
  "StyleBeatVITS2SdpRatio": "SDP/DP Mix Ratio",
  "StyleBeatVITS2Length": "Speech Speed",
  "ConversationHistory": "Conversation History",
  "ConversationHistoryInfo": "The last 10 conversation texts are retained as memory.",
  "ConversationHistoryReset": "Reset Conversation History",
  "NotConnectedToExternalAssistant": "Not connected to an external assistant.",
  "APIKeyNotEntered": "API key not entered.",
  "ChatLog": "Chat Log",
  "EnterYourQuestion": "Enter what you want to ask",
  "AnswerGenerating": "Generating Answer",
  "AboutThisApplication": "About This Application",
  "AboutThisApplicationDescription": "Enjoy conversations with 3D characters using a web browser, microphone, text input, and speech synthesis. You can change characters (VRM), set personalities, and adjust voices.<br />Settings can be changed from the menu button at the top left.",
  "AboutThisApplicationDescription2": "With AITuberKit, you can enjoy conversations with AI characters using just a web browser. Check each setting item for character changes, personality settings, and voice adjustments.",
  "TechnologyIntroduction": "Technology Introduction",
  "TechnologyIntroductionDescription1": "This app is created by modifying pixiv's <b>ChatVRM</b>. The original source code can be found",
  "TechnologyIntroductionLink1": "here",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "For displaying and operating 3D models,",
  "TechnologyIntroductionDescription4": ", for generating conversation texts,",
  "TechnologyIntroductionDescription5": "various LLMs, and for speech synthesis,",
  "TechnologyIntroductionDescription6": "various TTS are used. For details, see this",
  "TechnologyIntroductionLink2": "explanatory article",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "The source code of this app is available on GitHub. You can freely modify and alter it.",
  "SourceCodeDescription2": "For commercial use, please refer to the README of the same repository.",
  "RepositoryURL": "Repository URL:",
  "DontShowIntroductionNextTime": "Do not show this dialog next time",
  "Close": "Close",
  "Contact": "Contact",
  "ContactDescription": "For inquiries about this app, please contact the email address or Twitter account below.",
  "Creator": "Creator Information",
  "CreatorDescription": "Creator: Nike",
  "Language": "Language Settings",
  "UsingGSVITTS": "Using GSVI TTS",
  "GSVITTSInfo": "GSVI TTS Settings",
  "GSVITTSServerUrl": "GSVI TTS Server URL",
  "GSVITTSModelID": "GSVI TTS Model ID",
  "GSVITTSBatchSize": "GSVI TTS Batch Size (1 ~ 100, the larger the number, the faster the inference speed, but if too large, it may exhaust memory)",
  "GSVITTSSpeechRate": "Speech Speed (0.5 ~ 2.0, the larger the number, the faster)",
  "UsingElevenLabs": "Using ElevenLabs",
  "ElevenLabsInfo": "Using ElevenLabs API. Supports multiple languages. Please obtain the API key from the URL below.",
  "ElevenLabsApiKey": "ElevenLabs API Key",
  "ElevenLabsVoiceId": "ElevenLabs Voice ID",
  "ElevenLabsVoiceIdInfo": "Select the voice ID from the URL below.",
  "CharacterName": "Character Name",
  "ShowAssistantText": "Show Answer Field",
  "ShowCharacterName": "Show Character Name in Answer Field",
  "ShowControlPanel": "Show Control Panel",
  "ShowControlPanelInfo": "The settings screen can be displayed with Cmd + . (Mac) / Ctrl + . (Windows).",
  "SlideMode": "Slide Mode",
  "SelectedSlideDocs": "Slides to Use",
  "SlideModeDescription": "This mode allows the AI to automatically present slides. It is only valid when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertLabel": "PDF Slide Conversion",
  "PdfConvertDescription": "Convert PDF to data for slide mode. Available only when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertFileUpload": "Select PDF File",
  "PdfConvertFolderName": "Save Folder Name",
  "PdfConvertModelSelect": "Select Model",
  "PdfConvertButton": "Convert PDF to Slide",
  "PdfConvertLoading": "Converting...",
  "PdfConvertSuccess": "Conversion Completed",
  "PdfConvertError": "Conversion Failed",
  "PdfConvertSubmitError": "Please check if the PDF file, folder name, and API key are set",
  "LocalStorageReset": "Reset Settings",
  "LocalStorageResetInfo": "If environment variables are set, those values will take precedence. The page will be reloaded.",
  "LocalStorageResetButton": "Reset Settings",
  "NoSpeechTimeout": "No Speech Detection Timeout",
  "NoSpeechTimeoutInfo": "Set the time until input is automatically ended when silence continues during voice input.\nSetting it to 0 seconds disables automatic sending due to silence detection.",
  "Errors": {
    "EmptyAPIKey": "API key is not set",
    "AIInvalidProperty": "AI service setting value is incorrect",
    "AIAPIError": "An error occurred during AI API execution",
    "InvalidAIService": "The selected AI service is incorrect",
    "MethodNotAllowed": "The request is not appropriate",
    "TTSServiceError": "An error occurred in the {{serviceName}} TTS service: {{message}}",
    "UnexpectedError": "An unknown error occurred",
    "LocalLLMError": "An error occurred in the local LLM",
    "LocalLLMStreamError": "An error occurred in the local LLM stream processing",
    "LocalLLMConnectionError": "Cannot connect to the local LLM server",
    "LocalLLMNotFound": "Local LLM endpoint not found",
    "LocalLLMAPIError": "An error occurred in the local LLM API"
  },
  "MessageReceiver": "Accept Instructions from External",
  "MessageReceiverDescription": "You can instruct the AI character's speech from external using the API.",
  "ClientID": "Client ID",
  "OpenSendMessagePage": "Open Message Sending Page",
  "RealtimeAPIMode": "Real-time API Mode",
  "RealtimeAPIModeContentType": "Send Type",
  "RealtimeAPIModeVoice": "Voice Type",
  "AudioMode": "Audio Mode (Beta)",
  "InputText": "Text",
  "InputAudio": "Audio",
  "SearchGrounding": "Use Search Function",
  "SearchGroundingDescription": "When using multimodal functions, the search function is automatically disabled.",
  "UpdateRealtimeAPISettings": "Update Real-time API Settings",
  "UpdateRealtimeAPISettingsInfo": "When updating the API key, Azure Endpoint, voice type, model, or system prompt, press the update button to start a new WebSocket session.",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "An error occurred in the WebSocket connection",
    "WebSocketConnectionClosed": "WebSocket connection closed",
    "WebSocketConnectionAttempt": "Attempting WebSocket connection...",
    "WebSocketConnectionSuccess": "WebSocket connection successful",
    "FunctionExecuting": "Executing {{funcName}}",
    "FunctionExecutionFailed": "Failed to execute {{funcName}}",
    "FirefoxNotSupported": "This feature is not supported in Firefox",
    "SpeechRecognitionError": "Speech recognition error occurred",
    "NoSpeechDetected": "No speech detected."
  },
  "UsingOpenAITTS": "Using OpenAI",
  "OpenAITTSInfo": "Using OpenAI. Supports multiple languages. If OpenAI is selected in the AI service, there is no need to set the API key below.",
  "OpenAITTSVoice": "Voice Type",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Speech Speed",
  "UsingAzureTTS": "Using Azure OpenAI",
  "AzureTTSInfo": "Using Azure OpenAI. Supports multiple languages.",
  "SendMessage": {
    "title": "AITuberKit External Adapter",
    "directSendTitle": "Make the AI Character Speak Directly",
    "directSendDescription": "You can make the AI character speak the sent message directly. If multiple messages are sent, they will be processed in order.\nThe voice model selected in the AITuberKit settings will be used.",
    "aiGenerateTitle": "Generate a Response with AI and Then Make It Speak",
    "aiGenerateDescription": "The AI generates a response from the sent message and makes the AI character speak it. If multiple messages are sent, they will be processed in order.\nThe AI model and voice model selected in the AITuberKit settings will be used.\nYou can choose to use the AITuberKit system prompt or a custom system prompt.\nIf you want to load past conversation history, include the string [conversation_history] at any position in the system prompt or user message.",
    "useCurrentSystemPrompt": "Use AITuberKit's System Prompt",
    "userInputTitle": "Send User Input",
    "userInputDescription": "The sent message will be processed the same as if it were entered from the AITuberKit input form. If multiple messages are sent, they will be processed in order.\nThe AI model and voice model selected in the AITuberKit settings will be used.\nThe system prompt and conversation history will use the values from AITuberKit."
  },
  "CannotUseVoice": "When Real-time API Mode or Audio Mode is enabled,\nvoice settings are not required.",
  "Live2D": {
    "FileInfo": "Place the folder of the Live2D model you want to use in public/live2d. A model3.json file must exist directly under this folder.\nIf it does not appear in the options, reload the screen or check if the folder path is correct.",
    "Info": "You can specify emotions and motions.\nEach emotion is controlled by prompts. For details, see \"AI Settings => Character Settings\".",
    "Emotions": "Expression Settings",
    "EmotionInfo": "Multiple emotions can be specified separated by commas. If multiple are specified, one will be selected randomly.\nThe initial values correspond to the models prepared by AITuberKit. If using an original model, enter values that match your model.\nAfter the conversation is completed, the \"neutral\" expression will be displayed.",
    "neutralEmotions": "Neutral",
    "happyEmotions": "Happy",
    "sadEmotions": "Sad",
    "angryEmotions": "Angry",
    "relaxedEmotions": "Relaxed",
    "MotionGroups": "Motion Group Settings",
    "MotionGroupsInfo": "Motion groups are randomly selected from the selected group.\nAs with expression settings, set it to match your model.\n\"Idle\" is the motion displayed after the conversation is completed.",
    "SelectMotionGroup": "Select Motion Group",
    "idleMotionGroup": "Idle",
    "neutralMotionGroup": "Neutral",
    "happyMotionGroup": "Happy",
    "sadMotionGroup": "Sad",
    "angryMotionGroup": "Angry",
    "relaxedMotionGroup": "Relaxed"
  },
  "UseVideoAsBackground": "Use Shared Screen or Webcam as Background",
  "Temperature": "Temperature",
  "EnglishToJapanese": "Read English words in Japanese"
}