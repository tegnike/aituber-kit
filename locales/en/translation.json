{
  "Settings": "■ Settings",
  "AISettings": "■ AI Settings",
  "YoutubeSettings": "■ YouTube Settings",
  "VoiceSettings": "■ Voice Settings",
  "SlideSettings": "■ Slide Settings",
  "OtherSettings": "■ Other",
  "ExternalConnectionMode": "External Connection Mode (WebSocket, β version)",
  "YoutubeMode": "YouTube Mode",
  "YoutubeInfo": "The first character of the comment is '#', it is ignored.",
  "YoutubeAPIKey": "YouTube API Key",
  "YoutubeLiveID": "YouTube Live ID",
  "ConversationContinuityMode": "Conversation Continuity Mode (Beta)",
  "ConversationContinuityModeInfo": "When there is no comment, AI tries to continue the conversation. Currently only OpenAI, Anthropic Claude, Google Gemini are supported.",
  "ConversationContinuityModeInfo2": "One answer calls LLM multiple times, so API usage may increase. Please be aware of this.",
  "ConversationContinuityModeInfo3": "gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet work relatively stably.",
  "StatusOn": "Status: ON",
  "StatusOff": "Status: OFF",
  "Select": "Select",
  "TestVoice": "Test Voice",
  "SelectAIService": "Select AI Service",
  "LocalLLM": "Local LLM",
  "SelectModel": "Select Model",
  "OpenAIAPIKeyLabel": "OpenAI API Key",
  "AnthropicAPIKeyLabel": "Anthropic API Key",
  "GoogleAPIKeyLabel": "Google Gemini API Key",
  "AzureAPIKeyLabel": "Azure OpenAI API Key",
  "AzureAPIURL": "Azure OpenAI API URL",
  "GroqAPIKeyLabel": "Groq API Key",
  "CohereAPIKeyLabel": "Cohere API Key",
  "MistralAIAPIKeyLabel": "MistralAI API Key",
  "PerplexityAPIKeyLabel": "Perplexity API Key",
  "FireworksAPIKeyLabel": "Fireworks API Key",
  "DifyAPIKeyLabel": "Dify API Key",
  "APIKeyInstruction": "You can obtain the API key below. Enter the obtained API key into the form.",
  "LocalLLMInfo": "Local LLM server must be running. Setup is as follows.",
  "LocalLLMInfo2": "Please enter the URL of the local LLM server (including port number) and the model name.",
  "GroqInfo": "Groq API is accessed directly from the browser.",
  "DifyInfo": "Dify only supports chatbot and agent type.",
  "DifyInfo2": "The length of the conversation history is dependent on the specifications of Dify.",
  "DifyInfo3": "Example: http://localhost:80/v1/chat-messages",
  "DifyInstruction": "If you are using Dify, the system prompt will not be used. Please set Dify chatbot.",
  "EnterURL": "URL",
  "CharacterModelLabel": "Character Model",
  "OpenVRM": "Open VRM",
  "BackgroundImage": "Background Image",
  "ChangeBackgroundImage": "Change Background Image",
  "CharacterSettingsPrompt": "Character Settings (System Prompt)",
  "CharacterSettingsReset": "Reset Character Settings",
  "SyntheticVoiceEngineChoice": "Choose Synthetic Voice Engine",
  "VoiceAdjustment": "Voice Adjustment",
  "VoiceEngineInstruction": "Select the synthetic voice engine you want to use.",
  "UsingKoeiromap": "Koeiromap",
  "KoeiromapInfo": "Using Koeiromap API from Koemotion. It only supports Japanese. For more details, please refer to the link below.",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceVoxInfo": "Using VOICEVOX. It only supports Japanese. It uses a local API, you need to download and launch the app that suits your environment from the site below.",
  "VoicevoxSpeed": "Speed",
  "VoicevoxPitch": "Pitch",
  "VoicevoxIntonation": "Intonation",
  "UsingGoogleTTS": "Google TTS",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "StyleBertVITS2Info": "Using Style-Bert-VITS2. It supports only Japanese, English, and Chinese. If using a local API, you need to download and launch the app that suits your environment from the site below. Please also set up an API key if necessary.",
  "SpeakerSelection": "Speaker Selection",
  "GoogleTTSInfo": "Using Google Cloud Text-to-Speech. It supports multiple languages.",
  "AuthFileInstruction": "Obtain the authentication JSON file below and place it in the root folder of the repository as 'credentials.json'.",
  "LanguageModelURL": "Select the language model from the URL below.",
  "LanguageChoice": "Language Choice",
  "StyleBeatVITS2ServerURL": "Server URL",
  "StyleBeatVITS2ApiKey": "API Key",
  "StyleBeatVITS2ModelID": "Model ID",
  "StyleBeatVITS2Style": "Style",
  "StyleBeatVITS2SdpRatio": "SDP/DP Mixing Ratio",
  "StyleBeatVITS2Length": "Speech Rate",
  "ConversationHistory": "Conversation History",
  "ConversationHistoryInfo": "The latest 10 conversation texts are stored as memories.",
  "ConversationHistoryReset": "Reset Conversation History",
  "NotConnectedToExternalAssistant": "Not connected to an external assistant.",
  "APIKeyNotEntered": "API key is not entered.",
  "ChatLog": "Conversation Log",
  "EnterYourQuestion": "Enter your question here",
  "AnswerGenerating": "Answer Generating",
  "AboutThisApplication": "About This Application",
  "AboutThisApplicationDescription": "Enjoy conversations with a 3D character right in your web browser, using microphone or text input and voice synthesis. You can also change the character (VRM), adjust its personality, and modify its voice.<br />Settings can be changed from the menu button in the top left.",
  "TechnologyIntroduction": "Technology Introduction",
  "TechnologyIntroductionDescription1": "This app was created by modifying pixiv's <b>ChatVRM</b>. The original source code can be found",
  "TechnologyIntroductionLink1": "here",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "For displaying and manipulating 3D models,",
  "TechnologyIntroductionDescription4": "is used. For generating conversation text, various LLMs such as",
  "TechnologyIntroductionDescription5": "are used. For speech synthesis, various TTS engines like",
  "TechnologyIntroductionDescription6": "are utilized. For more details, please check out this",
  "TechnologyIntroductionLink2": "explanatory article",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "The source code for this app is publicly available on GitHub. Feel free to modify and adapt it as you like.",
  "RepositoryURL": "Repository URL:",
  "DontShowIntroductionNextTime": "Do not show this dialog next time",
  "Close": "CLOSE",
  "Language": "Language",
  "UsingGSVITTS": "GSVI TTS",
  "GSVITTSInfo": "GSVI TTS Settings",
  "GSVITTSServerUrl": "GSVI TTS Endpoint API",
  "GSVITTSModelID": "GSVI TTS Model ID",
  "GSVITTSBatchSize": "GSVI TTS Batch Size (1 ~ 100 The larger the value, the faster the inference speed, but it might exhaust memory if too large.)",
  "GSVITTSSpeechRate": "Speech Rate (0.5 ~ 2.0 The bigger the value, the faster it is.)",
  "UsingElevenLabs": "ElevenLabs",
  "ElevenLabsInfo": "ElevenLabs API is used. It supports multiple languages. API key can be obtained from the URL below.",
  "ElevenLabsApiKey": "ElevenLabs API Key",
  "ElevenLabsVoiceId": "ElevenLabs Voice ID",
  "ElevenLabsVoiceIdInfo": "Voice ID can be selected from the URL below.",
  "CharacterName": "Character name",
  "ShowAssistantText": "Show answer box",
  "ShowCharacterName": "Show character name in the answer box",
  "AdvancedSettings": "Advanced Settings",
  "ShowControlPanel": "Show settings button",
  "ShowControlPanelInfo": "The settings screen can be displayed by pressing Cmd + . (Mac) / Ctrl + . (Windows) .",
  "SlideMode": "Slide Mode",
  "SelectedSlideDocs": "Selected Slide Documents",
  "SlideModeDescription": "This is a mode where AI automatically presents slides. It is only available when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertLabel": "PDF Slide Conversion",
  "PdfConvertDescription": "Convert PDF to slide mode data. Available only when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertFileUpload": "Select PDF file",
  "PdfConvertFolderName": "Save folder name",
  "PdfConvertModelSelect": "Select model",
  "PdfConvertButton": "Convert PDF to slides",
  "PdfConvertLoading": "Converting...",
  "PdfConvertSuccess": "Conversion completed",
  "PdfConvertError": "Conversion failed",
  "PdfConvertSubmitError": "Please make sure the PDF file, folder name, and API key are set.",
  "LocalStorageReset": "Reset settings (page will be reloaded)",
  "Errors": {
    "EmptyAPIKey": "API key is not set",
    "AIInvalidProperty": "AI service settings are incorrect",
    "AIAPIError": "An error occurred while executing the AI API",
    "InvalidAIService": "The selected AI service is not valid",
    "MethodNotAllowed": "The request is not appropriate",
    "TTSServiceError": "An error occurred in the {{serviceName}} TTS service: {{message}}",
    "UnexpectedError": "An unexpected error occurred"
  },
  "MessageReceiver": "Receive instructions from outside",
  "MessageReceiverDescription": "You can use API to instruct AI characters to speak from outside.",
  "ClientID": "Client ID",
  "OpenSendMessagePage": "Open Send Message Page",
  "RealtimeAPIMode": "Realtime API Mode",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "Error occurred in WebSocket connection",
    "WebSocketConnectionClosed": "WebSocket connection closed",
    "WebSocketConnectionAttempt": "Attempting WebSocket connection...",
    "WebSocketConnectionSuccess": "WebSocket connection successful",
    "FunctionExecuting": "Executing {{funcName}}",
    "FunctionExecutionFailed": "Execution of {{funcName}} failed"
  },
  "UsingOpenAITTS": "Using OpenAI",
  "OpenAITTSInfo": "Using OpenAI. It supports multiple languages. If you select OpenAI as the AI service, you do not need to set the API key below.",
  "OpenAITTSVoice": "Voice type",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Speed"
}
