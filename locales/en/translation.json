{
  "Description": "About the App",
  "BasedSettings": "Basic Settings",
  "AISettings": "AI Settings",
  "CharacterSettings": "Character Settings",
  "YoutubeSettings": "YouTube Settings",
  "VoiceSettings": "Voice Synthesis Settings",
  "SpeechInputSettings": "Voice Input Settings",
  "SlideSettings": "Slide Settings",
  "ImageSettings": "Image Settings",
  "LogSettings": "Conversation History",
  "OtherSettings": "Other",
  "ExternalLinkageMode": "External Connection Mode (Beta)",
  "YoutubeMode": "YouTube Mode",
  "YoutubeInfo": "Comments starting with '#' are ignored.",
  "YoutubeAPIKey": "YouTube API Key",
  "YoutubeLiveID": "YouTube Live ID",
  "YoutubeCommentSource": "Comment Source",
  "YoutubeCommentSourceAPI": "YouTube API",
  "YoutubeCommentSourceOneComme": "OneComme",
  "OneCommeInfo": "Retrieves comments using OneComme. OneComme must be running.\nYou can aggregate comments from multiple streaming platforms (YouTube, Twitch, etc.) via OneComme.\nComments starting with '#' are ignored.",
  "OneCommePort": "OneComme Port Number",
  "OneCommeConnected": "Connected to OneComme",
  "OneCommeDisconnected": "Not connected to OneComme",
  "OneCommeConnecting": "Connecting to OneComme...",
  "OneCommeConnectionError": "Failed to connect to OneComme. Please check if OneComme is running.",
  "YoutubeCommentInterval": "Comment Fetch Interval (seconds)",
  "ConversationContinuityMode": "Conversation Continuity Mode (Beta)",
  "ConversationContinuityModeInfo": "This mode allows the AI to continue the conversation on its own when there are no comments. It is only effective when a multimodal-compatible model is selected.",
  "ConversationContinuityModeInfo2": "Since LLM is called multiple times for a single response, API usage fees may increase. Please be aware of this.",
  "ConversationContinuityModeInfo3": "Depending on the selected model, it may not operate stably.",
  "ConversationContinuityNewTopicThreshold": "Rounds Before New Topic Generation",
  "ConversationContinuityNewTopicThresholdInfo": "When there are no comments for this many rounds, the AI will generate a new topic.",
  "ConversationContinuitySleepThreshold": "Rounds Before Sleep",
  "ConversationContinuitySleepThresholdInfo": "When there are no comments for this many rounds, the AI will enter sleep mode.",
  "ConversationContinuityAdvancedPrompts": "Advanced Prompt Settings",
  "ConversationContinuityAdvancedPromptsInfo": "You can customize the prompts used in conversation continuity mode. Use the 'Reset to Default' button to restore the initial values.",
  "ResetToDefault": "Reset to Default",
  "ConversationContinuityPromptEvaluate": "1. Continuation Evaluation Prompt",
  "ConversationContinuityPromptEvaluateInfo": "A prompt that determines whether the streamer should continue speaking based on the conversation context. This text is sent as a system prompt, followed by recent conversation history as user/assistant messages. The AI returns the evaluation result in JSON format.",
  "ConversationContinuityPromptContinuation": "2. Continuation Guidelines",
  "ConversationContinuityPromptContinuationInfo": "Guidelines for naturally continuing the conversation when there are no comments. Combined with character settings as additional system prompt instructions, sent to the AI along with recent conversation history.",
  "ConversationContinuityPromptSelectComment": "3. Comment Selection Prompt",
  "ConversationContinuityPromptSelectCommentInfo": "An instruction prompt for selecting the most appropriate comment for the conversation flow. This text plus conversation history becomes the system prompt, and the comment list is sent as a user message to the AI.",
  "ConversationContinuityPromptNewTopic": "4. New Topic Generation Prompt",
  "ConversationContinuityPromptNewTopicInfo": "An instruction prompt for generating a new related topic from the conversation. This text is sent as a system prompt, followed by recent conversation history as user/assistant messages. The AI returns topic keywords.",
  "ConversationContinuityPromptSleep": "5. Sleep Guidelines",
  "ConversationContinuityPromptSleepInfo": "Guidelines for generating sleep dialogue when there are no comments from viewers. Combined with character settings as additional system prompt instructions, sent to the AI along with recent conversation history.",
  "MaxPastMessages": "Number of Past Messages to Keep",
  "UseCustomModel": "Use Custom Model",
  "CustomModelPlaceholder": "Enter custom model name...",
  "Select": "Please select",
  "TestVoice": "Test Voice",
  "SelectAIService": "Select AI Service",
  "LocalLLM": "Local LLM",
  "SelectModel": "Select Model",
  "OpenAIAPIKeyLabel": "OpenAI API Key",
  "AnthropicAPIKeyLabel": "Anthropic API Key",
  "GoogleAPIKeyLabel": "Google Gemini API Key",
  "AzureAPIKeyLabel": "Azure OpenAI API Key",
  "AzureAPIURL": "Azure OpenAI API URL",
  "GroqAPIKeyLabel": "Groq API Key",
  "CohereAPIKeyLabel": "Cohere API Key",
  "MistralAIAPIKeyLabel": "MistralAI API Key",
  "PerplexityAPIKeyLabel": "Perplexity API Key",
  "FireworksAPIKeyLabel": "Fireworks API Key",
  "DifyAPIKeyLabel": "Dify API Key",
  "DeepSeekAPIKeyLabel": "DeepSeek API Key",
  "APIKeyInstruction": "API keys can be obtained from the links below. Enter the obtained API key in the form.",
  "LocalLLMInfo": "You need to have a local LLM server running.",
  "LocalLLMInfo2": "Please enter the URL of your local LLM (including port number) and the model name.",
  "GroqInfo": "Groq API is accessed directly from the browser.",
  "DifyInfo": "Dify only supports chatbot or agent types. If you do not receive a satisfactory answer, please delete the conversation history and ask again.",
  "DifyInfo2": "The length of conversation history depends on the Dify chatbot settings.",
  "DifyInfo3": "Example: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "If you are using Dify, this system prompt is not used. Please set it in the Dify chatbot.",
  "EnterURL": "Enter URL",
  "CharacterModelLabel": "Character Model",
  "CharacterModelInfo": "Some models may take time to load during initial display.",
  "OpenVRM": "Open VRM",
  "CharacterPosition": "Character Position",
  "CharacterPositionInfo": "You can fix the character's position and orientation. For VRM, the camera position is saved; for Live2D, the model position is saved.",
  "FixPosition": "Fix position",
  "UnfixPosition": "Unlock fixed position",
  "ResetPosition": "Reset position",
  "Save": "Save",
  "CurrentStatus": "Current status",
  "PositionFixed": "Fixing",
  "PositionNotFixed": "Unpinned",
  "ChangeBackgroundImage": "Change Background Image",
  "BackgroundSettings": "Background Settings",
  "BackgroundSettingsDescription": "You can upload and select background images for the application.",
  "Cancel": "Cancel",
  "UploadBackground": "Upload Background Image",
  "DefaultBackground": "Default Background",
  "GreenBackground": "Greenback",
  "CharacterSettingsPrompt": "Character Prompt",
  "CharacterSettingsInfo": "This value is set as the system prompt.\nReferring to the initial prompt, you can control the character's expressions and motions by specifying emotion tags. Example: [neutral]Good morning![happy]Thank you for your hard work today!",
  "CharacterpresetInfo": "Selecting a preset will change the character prompt.\nShortcuts are available with Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Select Voice Synthesis Engine",
  "VoiceAdjustment": "Voice Adjustment",
  "VoiceEngineInstruction": "Please select the voice synthesis engine to use.",
  "UsingKoeiromap": "Use Koeiromap",
  "KoeiromapInfo": "Using Koeiromap API from Koemotion. Supports Japanese only. See below for details.",
  "UsingVoiceVox": "Use VOICEVOX",
  "VoiceVoxInfo": "Using VOICEVOX. Supports Japanese only. Since it uses a local API, you need to download and run the appropriate app for your environment from the site below.",
  "VoicevoxSpeed": "Speaking Speed",
  "VoicevoxPitch": "Pitch",
  "VoicevoxIntonation": "Intonation",
  "VoicevoxServerUrl": "VOICEVOX Server URL",
  "UsingAivisSpeech": "Use AivisSpeech",
  "UsingAivisCloudAPI": "Use Aivis Cloud API",
  "AivisCloudAPIInfo": "Aivis Cloud API Settings",
  "AivisCloudAPIDashboard": "Aivis Cloud API Dashboard",
  "AivisSpeechInfo": "Using AivisSpeech. Supports Japanese only. Since it uses a local API, you need to download and run the appropriate app for your environment from the site below.",
  "AivisSpeechSpeaker": "Speaker",
  "AivisSpeechSpeed": "Speaking Speed",
  "AivisSpeechPitch": "Pitch",
  "AivisSpeechIntonationScale": "Style Strength",
  "AivisSpeechServerUrl": "AivisSpeech Server URL",
  "NoClientIDSet": "Client ID is not set",
  "UpdateSpeakerList": "Update Speaker List",
  "UsingGoogleTTS": "Use Google Text-to-Speech",
  "UsingStyleBertVITS2": "Use Style-Bert-VITS2",
  "StyleBertVITS2Info": "Using Style-Bert-VITS2. Supports Japanese, English, and Chinese only. If using a local API, you need to download and run the appropriate app for your environment from the site below. Set up the API key if necessary.",
  "SpeakerSelection": "Voice Type Selection",
  "EnglishToJapanese": "Read English words in Japanese",
  "IncludeTimestampInUserMessage": "Include timestamp in user messages",
  "IncludeTimestampInUserMessageInfo": "Including a timestamp in user messages allows the AI to generate responses considering the time.\nPlease include the following text in your system prompt:\n\n\"User input may be requested with a [timestamp], which represents the time in UTC timezone at the time of the request, so please generate a response considering that time.\"",
  "GoogleTTSInfo": "Using Google Cloud Text-to-Speech. Supports multiple languages.",
  "AuthFileInstruction": "An API key or authentication JSON file is required. Obtain it from below, and if it's a JSON file, place it in the root folder of the repository as 'credentials.json'.",
  "LanguageModelURL": "Please select a language model from the URL below.",
  "LanguageChoice": "Language Selection",
  "StyleBeatVITS2ServerURL": "Server URL",
  "StyleBeatVITS2ApiKey": "API Key",
  "StyleBeatVITS2ModelID": "Model ID",
  "StyleBeatVITS2Style": "Style",
  "StyleBeatVITS2SdpRatio": "SDP/DP Mix Ratio",
  "StyleBeatVITS2Length": "Speaking Speed",
  "ConversationHistory": "Conversation History",
  "ConversationHistoryInfo": "The most recent {{count}} conversation sentences are retained as memory.",
  "ConversationHistoryReset": "Reset Conversation History",
  "NotConnectedToExternalAssistant": "Not connected to external assistant.",
  "APIKeyNotEntered": "API key has not been entered.",
  "ChatLog": "Conversation Log",
  "EnterYourQuestion": "Enter what you want to ask",
  "AnswerGenerating": "Generating answer",
  "AboutThisApplication": "About This Application",
  "AboutThisApplicationDescription": "You can enjoy conversations with 3D characters in a web browser using microphone, text input, and voice synthesis. You can change the character (VRM), personality settings, and voice adjustments.<br />Settings can be changed from the menu button in the top left.",
  "AboutThisApplicationDescription2": "With AITuberKit, you can enjoy conversations with AI characters in a web browser. Please check each setting item for changing characters, personality settings, and voice adjustments.",
  "TechnologyIntroduction": "Technology Introduction",
  "TechnologyIntroductionDescription1": "This app is created by modifying pixiv's <b>ChatVRM</b>. The original source code is",
  "TechnologyIntroductionLink1": "here",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "For 3D model display and operation,",
  "TechnologyIntroductionDescription4": ", for conversation generation,",
  "TechnologyIntroductionDescription5": "and various LLMs, for voice synthesis,",
  "TechnologyIntroductionDescription6": "and various TTS services are used. For details, please see this",
  "TechnologyIntroductionLink2": "explanatory article",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "The source code of this app is available on GitHub. You can freely modify and alter it.",
  "SourceCodeDescription2": "For commercial use, please refer to the README in the same repository.",
  "RepositoryURL": "Repository URL:",
  "DontShowIntroductionNextTime": "Don't show this dialog next time",
  "Close": "Close",
  "Contact": "Contact",
  "ContactDescription": "For inquiries about this app, please contact the email address or Twitter account below.",
  "Creator": "Creator Information",
  "CreatorDescription": "Creator: Nike",
  "Documentation": "Documentation",
  "DocumentationDescription": "For detailed usage and tutorials of AITuberKit, please visit the URL below.",
  "Language": "Language Settings",
  "UsingGSVITTS": "Use GSVI TTS",
  "GSVITTSInfo": "GSVI TTS Settings",
  "GSVITTSServerUrl": "GSVI TTS Server URL",
  "GSVITTSModelID": "GSVI TTS Model ID",
  "GSVITTSBatchSize": "GSVI TTS Batch Size (1 ~ 100 The larger the value, the faster the inference speed, but if it's too large, it may exhaust memory)",
  "GSVITTSSpeechRate": "Speaking Speed (0.5 ~ 2.0 The larger the value, the faster)",
  "UsingElevenLabs": "Use ElevenLabs",
  "ElevenLabsInfo": "Using ElevenLabs API. Supports multiple languages. Please get an API key from the URL below.",
  "ElevenLabsApiKey": "ElevenLabs API Key",
  "ElevenLabsVoiceId": "ElevenLabs Voice ID",
  "ElevenLabsVoiceIdInfo": "Please select a Voice ID from the URL below.",
  "UsingCartesia": "Use Cartesia",
  "CartesiaInfo": "Using the Cartesia API. Supports multiple languages. Please obtain the API key from the URL below.",
  "CartesiaApiKey": "Cartesia API Key",
  "CartesiaVoiceId": "Cartesia Voice ID",
  "CartesiaVoiceIdInfo": "Please select the Voice ID from the URL below.",
  "CharacterName": "Character Name",
  "UserDisplayName": "User Display Name",
  "ShowAssistantText": "Show answer field",
  "ShowCharacterName": "Show character name in answer field",
  "ShowControlPanel": "Show control panel",
  "ShowControlPanelInfo": "The settings screen can be displayed with Cmd + . (Mac) / Ctrl + . (Windows).\nIf you are using a smartphone, you can also long press (about 1 second) the top left of the screen.",
  "ColorTheme": "Color Theme",
  "ColorThemeInfo": "You can select the application's color theme. The selected theme will be applied immediately.",
  "ThemeDefault": "Default",
  "ThemeMono": "Monochrome",
  "ThemeCool": "Cool",
  "ThemeOcean": "Ocean",
  "ThemeForest": "Forest",
  "ThemeSunset": "Sunset",
  "ShowQuickMenu": "Show quick menu button",
  "SlideMode": "Slide Mode",
  "SelectedSlideDocs": "Slides to use",
  "EditSlideScripts": "Edit Dialogue",
  "PleaseSelectSlide": "Please select a slide",
  "SlideModeDescription": "This is a mode where AI automatically presents slides. It is only available when a multimodal-compatible model is selected.",
  "PdfConvertLabel": "PDF Slide Conversion",
  "PdfConvertDescription": "Convert the PDF into data for slide mode. Available only when a multimodal-compatible model is selected.",
  "PdfConvertFileUpload": "Select PDF file",
  "PdfConvertFolderName": "Save folder name",
  "CustomVoiceTextPlaceholder": "Enter text you want to hear",
  "TestVoiceSettings": "Voice Test",
  "TestSelectedVoice": "Play",
  "PdfConvertModelSelect": "Select model",
  "PdfConvertButton": "Convert PDF to slides",
  "PdfConvertLoading": "Converting...",
  "PdfConvertSuccess": "Conversion complete",
  "PdfConvertError": "Conversion failed",
  "PdfConvertSubmitError": "Please check that the PDF file, folder name, and API key are set",
  "LocalStorageReset": "Reset settings",
  "LocalStorageResetInfo": "If environment variables are set, those values take precedence. The page will be reloaded.",
  "LocalStorageResetButton": "Reset Settings",
  "InitialSpeechTimeout": "Voice recognition timeout",
  "InitialSpeechTimeoutInfo": "Set the waiting time for the first utterance to be detected after voice recognition starts. If no utterance is detected within this time, voice recognition will automatically stop.\nIf set to 0 seconds, the waiting time is unlimited.",
  "Milliseconds": "milliseconds",
  "NoSpeechTimeout": "Silence detection timeout",
  "NoSpeechTimeoutInfo": "Set the time to automatically end input when no sound is detected during voice input.\nIf set to 0 seconds, automatic submission by silence detection is disabled.",
  "ShowSilenceProgressBar": "Show silence detection progress bar",
  "SpeechRecognitionMode": "Voice recognition mode",
  "SpeechRecognitionModeInfo": "You can select the voice recognition mode.\n'Browser standard' uses the browser's built-in voice recognition. 'OpenAI TTS' uses OpenAI's Text to Speech API.\nGenerally, 'Browser standard' is recommended as it has higher accuracy and faster recognition speed. However, if you are using a browser that does not support WebSpeech API, such as Firefox, please select 'OpenAI TTS'.",
  "BrowserSpeechRecognition": "Use browser standard voice recognition",
  "WhisperSpeechRecognition": "Use OpenAI TTS voice recognition",
  "WhisperTranscriptionModel": "Transcription model",
  "WhisperTranscriptionModelInfo": "You can select the model to use for voice recognition. More advanced models can recognize with higher accuracy, but may incur higher API costs.",
  "SpeechRecognitionModeDisabledInfo": "If audio mode is enabled, only browser voice recognition can be used.\nAlso, in real-time API mode, only browser voice recognition can be used, and the voice recognition timeout function is disabled.",
  "Errors": {
    "EmptyAPIKey": "API key is not set",
    "EmptyLocalLLMURL": "Local LLM URL is not set",
    "AIInvalidProperty": "AI service setting value is incorrect",
    "AIAPIError": "An error occurred during AI API execution",
    "InvalidAIService": "Selected AI service is incorrect",
    "MethodNotAllowed": "Request is not appropriate",
    "TTSServiceError": "An error occurred in {{serviceName}} TTS service: {{message}}",
    "UnexpectedError": "An unknown error occurred",
    "LocalLLMError": "An error occurred in local LLM",
    "LocalLLMStreamError": "An error occurred in local LLM stream processing",
    "LocalLLMConnectionError": "Cannot connect to local LLM server",
    "LocalLLMNotFound": "Local LLM endpoint not found",
    "LocalLLMAPIError": "An error occurred in local LLM API",
    "CustomAPIError": "An error occurred in custom API",
    "InvalidJSON": "JSON format is incorrect"
  },
  "MessageReceiver": "Accept instructions from external sources",
  "MessageReceiverDescription": "You can instruct the AI character's speech from external sources using API.",
  "ClientID": "Client ID",
  "OpenSendMessagePage": "Open message sending page",
  "RealtimeAPIMode": "Real-time API mode",
  "RealtimeAPIModeContentType": "Submission type",
  "RealtimeAPIModeVoice": "Voice type",
  "AudioMode": "Audio mode",
  "InputText": "Text",
  "InputAudio": "Audio",
  "SearchGrounding": "Use search function",
  "SearchGroundingDescription": "When using multimodal features, the search function is automatically disabled.",
  "DynamicRetrieval": "Dynamic Search",
  "DynamicRetrievalDescription": "Sets the threshold for when the model performs a search. If 0, the search is always performed; if 1, the search is never performed.",
  "DynamicRetrievalThreshold": "Dynamic threshold",
  "UpdateRealtimeAPISettings": "Update real-time API settings",
  "UpdateRealtimeAPISettingsInfo": "When you update the API key, Azure Endpoint, voice type, model, or system prompt, press the update button to start a new WebSocket session.",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "An error occurred in the WebSocket connection",
    "WebSocketConnectionClosed": "WebSocket connection has been closed",
    "WebSocketConnectionAttempt": "Attempting WebSocket connection...",
    "WebSocketConnectionSuccess": "WebSocket connection succeeded",
    "FunctionExecuting": "Executing {{funcName}}",
    "FunctionExecutionFailed": "Failed to execute {{funcName}}",
    "FirefoxNotSupported": "This feature is not supported in Firefox",
    "SpeechRecognitionError": "A voice recognition error has occurred",
    "NoSpeechDetected": "No audio was detected.",
    "PresetSwitching": "Switched to {{presetName}}.",
    "WhisperError": "An error occurred during speech recognition with Whisper",
    "UsingTool": "Using {{toolName}}",
    "PositionFixed": "Character position has been fixed",
    "PositionUnfixed": "Character position lock has been released",
    "PositionReset": "Character position has been reset",
    "PositionActionFailed": "Failed to manipulate position",
    "MicrophonePermissionDenied": "Permission to access the microphone was denied",
    "CameraPermissionMessage": "Please allow the use of the camera.",
    "PresetLoadFailed": "Failed to load preset"
  },
  "ContinuousMic": "Continuous microphone input",
  "ContinuousMicActive": "Continuous microphone input active",
  "ContinuousMicModeOn": "Continuous microphone input mode is on",
  "ContinuousMicModeOff": "Continuous microphone input mode is off",
  "ListeningContinuously": "Waiting for voice input...",
  "ContinuousMicInfo": "The microphone input will automatically restart when the AI finishes speaking. It will automatically submit after the set silence time elapses.\nIf voice recognition does not occur and the set time is exceeded, continuous microphone input will automatically turn OFF, so if you want to keep it ON at all times, set the voice recognition timeout to 0 seconds.",
  "UsingOpenAITTS": "Use OpenAI",
  "OpenAITTSInfo": "Using OpenAI. Supports multiple languages. If you have selected OpenAI in the AI service, you do not need to set the API key below.",
  "OpenAITTSVoice": "Voice type",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Speaking speed",
  "UsingAzureTTS": "Use Azure OpenAI",
  "AzureTTSInfo": "Using Azure OpenAI. Supports multiple languages.",
  "SendMessage": {
    "title": "AITuberKit External Adapter",
    "directSendTitle": "Make AI character speak directly",
    "directSendDescription": "You can make the AI character speak the sent message directly. If multiple messages are sent, they will be processed in order.\nThe voice model selected in the AITuberKit settings will be used.",
    "aiGenerateTitle": "Generate a response with AI and then make it speak",
    "aiGenerateDescription": "AI generates a response from the sent message, and the AI character speaks that response. If multiple messages are sent, they will be processed in order.\nThe AI model and voice model selected in the AITuberKit settings will be used.\nYou can choose to use the AITuberKit system prompt or a custom system prompt.\nIf you want to load past conversation history, include the string [conversation_history] anywhere in the system prompt or user message.",
    "useCurrentSystemPrompt": "Use AITuberKit's system prompt",
    "userInputTitle": "Send user input",
    "userInputDescription": "The sent message will be processed the same as if it were entered from the AITuberKit input form. If multiple messages are sent, they will be processed in order.\nThe AI model and voice model selected in the AITuberKit settings will be used.\nThe system prompt and conversation history from AITuberKit will be used."
  },
  "CannotUseVoice": "If real-time API mode or audio mode is enabled,\nvoice synthesis settings are not necessary.",
  "APIKey": "API Key",
  "Preset": "Preset",
  "Cute": "cute",
  "Energetic": "Energetic",
  "Cool": "cool",
  "Mature": "subtle",
  "UseAivisCloudAPI": "Use Aivis Cloud API",
  "AivisCloudAPIDescription": "Checking this will use the cloud version of the Aivis Cloud API.",
  "ModelUUID": "Model UUID",
  "StyleID": "Style ID",
  "SpeechSpeed": "Speech rate",
  "Pitch": "Pitch",
  "TempoDynamics": "Tempo variations",
  "PreSilenceDuration": "Silent time before audio",
  "PostSilenceDuration": "Silent time after audio",
  "EmotionalIntensity": "Intensity of emotional expression",
  "UseStyleName": "Specify by style name",
  "StyleSelectionDescription": "You can select either the style ID or the style name. Usually, the style ID (0 to 31) is used.",
  "StyleName": "Style Name",
  "StyleNamePlaceholder": "Example: Normal",
  "Live2D": {
    "FileInfo": "Please place the Live2D model folder you want to use in public/live2d. A model3.json file must exist directly under this folder.\nIf it does not appear in the selection, please reload the screen or check if the folder path is correct.",
    "Info": "You can specify emotions and motions.\nEach emotion is controlled by the prompt. For details, please see 'AI Settings => Character Settings'.",
    "Emotions": "Expression settings",
    "EmotionInfo": "Multiple emotions can be specified with commas. If multiple are specified, one will be randomly selected.\nThe default values correspond to the models prepared by AITuberKit. If you are using your original model, please enter values that match your model.\nAfter the conversation is completed, the 'neutral' expression will be displayed.",
    "neutralEmotions": "Neutral",
    "happyEmotions": "Happy",
    "sadEmotions": "Sad",
    "angryEmotions": "Angry",
    "relaxedEmotions": "Relaxed",
    "surprisedEmotions": "Surprised",
    "MotionGroups": "Motion group settings",
    "MotionGroupsInfo": "Motion groups are randomly selected from the selected group.\nLike the expression settings, please set according to your own model.\n'Idle' is the motion displayed after the conversation is completed.",
    "SelectMotionGroup": "Select motion group",
    "idleMotionGroup": "Idle",
    "neutralMotionGroup": "Neutral",
    "happyMotionGroup": "Happy",
    "sadMotionGroup": "Sad",
    "angryMotionGroup": "Angry",
    "relaxedMotionGroup": "Relaxed",
    "surprisedMotionGroup": "Surprised"
  },
  "PNGTuber": {
    "FileInfo": "Please place the PNGTuber asset folder you want to use in public/pngtuber. Each folder requires the following files:\n• *_mouthless_h264.mp4 (mouthless background video)\n• mouth_track.json (mouth position tracking data)\n• mouth/ folder (mouth sprites: closed.png, open.png are required, half.png, e.png, u.png are optional)",
    "Sensitivity": "Sensitivity",
    "SensitivityInfo": "Adjusts the volume sensitivity for lip sync. Higher values make it respond to quieter sounds.",
    "ChromaKey": "Chroma Key (Background Transparency)",
    "ChromaKeyEnabled": "Enable Chroma Key",
    "ChromaKeyColor": "Key Color (color to make transparent)",
    "ChromaKeyTolerance": "Tolerance",
    "ChromaKeyToleranceInfo": "Higher values make colors closer to the key color also transparent.",
    "ChromaKeyPreview": "Video Preview",
    "ChromaKeyPreviewInfo": "Click on the video to select the color you want to make transparent.",
    "PositionSize": "Position and Size",
    "PositionInfo": "Use mouse wheel to zoom, drag to move.",
    "ResetPosition": "Reset Position and Size"
  },
  "UseVideoAsBackground": "Use shared screen or webcam as background",
  "Temperature": "Temperature",
  "MaxTokens": "Maximum tokens",
  "MaxTokensInfo": "The maximum number of tokens varies depending on the AI model being used. Please check the specifications of each model.",
  "ReasoningMode": "Reasoning Mode",
  "ReasoningModeInfo": "Enabling reasoning mode allows the use of extended thinking processes with supported models. For unsupported models, it may have no effect or cause errors.",
  "ReasoningEffort": "Reasoning Effort",
  "ReasoningEffortInfo": "Select the level of computation for reasoning. Higher levels produce deeper thinking but increase response time and token usage.",
  "ReasoningTokenBudget": "Reasoning Token Budget",
  "ReasoningTokenBudgetInfo": "The maximum number of tokens allocated to the reasoning (thinking) process. Used with Anthropic, Cohere, and Google Gemini 2.5 series.",
  "ThinkingProcess": "Thinking Process",
  "ShowThinkingText": "Always Show Thinking Process",
  "ShowThinkingTextInfo": "When enabled, the reasoning model's thinking process will always be displayed expanded in the chat history.",
  "CannotUseParameters": "When Real-time API mode or Audio mode is enabled, multimodal features are not available. Also, the Temperature and Max Tokens parameters cannot be specified.",
  "PresetQuestions": "Preset questions",
  "PresetQuestionsInfo": "You can create and register multiple question patterns in advance. Registered questions will be displayed as buttons on the user UI, and clicking them will set them in the chat input field.",
  "EnterPresetQuestion": "Please enter a question",
  "DragToReorder": "Drag to change order",
  "Edit": "Edit",
  "EnterClientID": "Please enter the client ID",
  "CustomAPIEndpoint": "Custom API endpoint",
  "CustomAPIEndpointInfo": "Enter the URL of the API endpoint to send POST requests to.",
  "CustomAPIStream": "Streaming mode",
  "CustomAPIStreamForced": "Currently, streaming mode is always enabled.",
  "IncludeSystemMessages": "Include System Messages",
  "CustomAPIHeaders": "Custom headers",
  "CustomAPIHeadersInfo": "Enter header information to include in API requests in JSON format.",
  "CustomAPIBody": "Custom body",
  "CustomAPIBodyInfo": "Enter body information to include in API requests in JSON format. messages will be automatically included.",
  "CustomAPIDescription": "Note: Messages are automatically included in the request body. In streaming mode, the server must return text/event-stream.",
  "XAIAPIKeyLabel": "xAI API Key",
  "OpenRouterAPIKeyLabel": "OpenRouter API Key",
  "OpenRouterModelNameInstruction": "Please enter the model identifier from OpenRouter (e.g., \"openai/gpt-4o\", \"mistralai/mistral-large-latest\"). You can check the model identifier on the OpenRouter model page.",
  "ImageDisplayPosition": "Image display position",
  "ImageDisplayPositionDescription": "Please select the position to display the uploaded image",
  "InputArea": "Input area",
  "SideArea": "Side Panel",
  "NoDisplay": "Icon only display",
  "RemoveImage": "Delete image",
  "PasteImageSupported": "Image paste support",
  "ImageSizeExceeded": "Image size exceeds the 10MB limit",
  "ImageReadError": "Failed to read image file",
  "FileSizeError": "The file size exceeds the maximum of {{maxSize}}MB.",
  "FileTypeError": "Unsupported file format. Only image files (PNG, JPEG, GIF, WebP) can be uploaded.",
  "ImageDimensionError": "The image size exceeds the maximum of {{maxWidth}}x{{maxHeight}} pixels.",
  "ImageLoadError": "Failed to load image.",
  "FileReadError": "Failed to load the file.",
  "FileProcessError": "An error occurred while processing the file.",
  "GenerateNew": "Create New",
  "EnableMultiModal": "Use multimodal features",
  "EnableMultiModalDescription": "Enable the image upload feature. For unsupported models, images may be ignored.",
  "MultiModalNotSupported": "The selected model or settings do not support image sending. Please enable multimodal features or select a compatible model.",
  "MultiModalMode": "Multimodal usage mode",
  "MultiModalModeDescription": "Please select when to use the multimodal feature.",
  "MultiModalModeAIDecide": "Decide with AI",
  "MultiModalModeAlways": "Always use",
  "MultiModalModeNever": "Do not use",
  "MultiModalAIDecisionPrompt": "Prompt for AI judgment",
  "MultiModalAIDecisionPromptPlaceholder": "You are an assistant who determines whether an image is relevant to the user's question or the context of the conversation. Please answer only with \"yes\" or \"no\" considering the recent conversation history and the user's message.",
  "CustomApiIncludeMimeType": "Include MIME type in image",
  "CustomApiIncludeMimeTypeDescription": "Include the mimeType property in the image object sent to the custom API.",
  "ImageSettingsDescription": "You can upload images and place them on the screen. You can display up to 5 images simultaneously.",
  "UploadImages": "Upload Image",
  "SupportedFormats": "Supported formats",
  "OnlyImageFilesAllowed": "Only image files can be uploaded.",
  "FileSizeTooLarge": "The file size is too large (maximum 100MB).",
  "Uploading": "Uploading...",
  "UploadComplete": "Upload complete",
  "UploadFailed": "Upload failed",
  "UploadedImages": "Uploaded image",
  "NoUploadedImages": "No uploaded images available",
  "AddToDisplay": "Display on screen",
  "AlreadyDisplayed": "Displaying",
  "MaximumFiveImagesAllowed": "You can only display up to 5 images.",
  "ImageAlreadyPlaced": "This image is already displayed.",
  "CurrentlyDisplayedImages": "Currently displayed image",
  "NoDisplayedImages": "There are no images currently displayed",
  "Position": "Position",
  "Size": "Size",
  "Remove": "Delete",
  "Delete": "Delete",
  "ConfirmDeleteImage": "Are you sure you want to delete this image?",
  "DeleteFailed": "Failed to delete",
  "LayerControl": "Stacking order",
  "LayerControlDescription": "You can control the layering order of images and characters",
  "BehindCharacter": "Behind the character",
  "InFrontOfCharacter": "In front of the character",
  "MoveToBack": "Move backward",
  "MoveToFront": "Move forward",
  "CharacterLayer": "Character",
  "LayerPosition": "Display position",
  "DragToReorderLayers": "Drag to reorder",
  "ImageOrder": "Image order",
  "CharacterLayerPosition": "Character Position",
  "CharacterPositionDescription": "You can drag the character to adjust its position",
  "DragCharacterToMove": "Drag and move the character",
  "ResetCharacterPosition": "Reset position",
  "FixCharacterPosition": "Fix position",
  "UnfixCharacterPosition": "Unlock position fixed",
  "CharacterPositionFixed": "Position is fixed",
  "LayerOrder": "Layer order (up to 5)",
  "LayerOrderDescription": "You can adjust the layering order of images and characters by drag & drop.",
  "Items": "Item",
  "TopLayer": "Frontmost",
  "BottomLayer": "Send to back",
  "MostVisible": "Most visible",
  "LeastVisible": "Most invisible",
  "Presets": "Preset",
  "MemorySettings": "Memory Settings",
  "MemoryEnabled": "Long-term Memory",
  "MemoryEnabledInfo": "Enabling long-term memory will vectorize and store past conversations, and add relevant memories to the context. This uses the OpenAI Embedding API, so an API key is required.",
  "MemorySimilarityThreshold": "Similarity Threshold",
  "MemorySimilarityThresholdInfo": "Only memories with similarity above this value will be used in search results. Higher values use only more relevant memories.",
  "MemorySearchPreview": "Similarity Preview",
  "MemorySearchPreviewInfo": "Enter a test search query to check similarity scores with stored memories. Useful for adjusting the threshold.",
  "MemorySearchPreviewPlaceholder": "Enter a test search query...",
  "MemorySearchPreviewButton": "Search",
  "MemorySearchPreviewNoResults": "No matching memories found (embeddings may not have been generated yet)",
  "MemorySearchLimit": "Search Result Limit",
  "MemorySearchLimitInfo": "Set the maximum number of search results.",
  "MemoryMaxContextTokens": "Maximum Context Tokens",
  "MemoryMaxContextTokensInfo": "Set the maximum number of tokens to add to the memory context.",
  "MemoryClear": "Clear Memory",
  "MemoryClearConfirm": "Are you sure you want to delete all memories? This action cannot be undone.",
  "MemoryCount": "Stored Memory Count",
  "MemoryCountValue": "{{count}} items",
  "MemoryAPIKeyWarning": "Long-term memory function is not available because OpenAI API key is not set.",
  "MemoryRestore": "Restore Memory",
  "MemoryRestoreInfo": "Restore conversation history from conversation log files (chat-log-*.json) in the logs folder.",
  "MemoryRestoreSelect": "Select File",
  "MemoryRestoreConfirm": "Do you want to restore this memory data? Existing conversation history will be overwritten.",
  "MemoryRestoreSuccess": "Memory has been restored",
  "MemoryRestoreError": "Failed to restore memory",
  "VectorizeOnRestore": "Also save to long-term memory",
  "VectorizeOnRestoreInfo": "When ON, the data will be vectorized and saved to long-term memory during restoration. If the file has vector data, it will be restored without calling the API; otherwise, it will be vectorized using the OpenAI API. Cannot be used when long-term memory is OFF.",
  "PresenceSettings": "Presence Detection Settings",
  "PresenceDetectionEnabled": "Presence Detection Mode",
  "PresenceDetectionEnabledInfo": "A mode that automatically detects visitors using a webcam and starts greeting them. Useful for unattended operation at exhibitions and digital signage.",
  "PresenceDetectionDisabledInfo": "Presence detection cannot be used when Real-time API mode, Audio mode, External connection mode, or Slide mode is enabled.",
  "PresenceGreetingPhrases": "Greeting Message List",
  "PresenceGreetingPhrasesInfo": "Register greeting messages and emotions that the AI will speak when a visitor is detected. If multiple are registered, one will be selected randomly.",
  "PresenceDepartureTimeout": "Departure Detection Time",
  "PresenceDepartureTimeoutInfo": "Set the time (in seconds) from when a face is no longer detected until it is determined as a departure. After departure is determined, departure messages will be spoken and conversation history will be cleared.",
  "PresenceDeparturePhrases": "Departure Message List",
  "PresenceDeparturePhrasesInfo": "Register messages and emotions that the AI will speak when a visitor departs. If multiple are registered, one will be selected randomly. If none are registered, no message will be spoken.",
  "PresenceAddPhrase": "Add",
  "PresencePhraseTextPlaceholder": "Enter message...",
  "PresenceDeletePhrase": "Delete",
  "PresenceClearChatOnDeparture": "Clear conversation history on departure",
  "PresenceClearChatOnDepartureInfo": "Clears the conversation history when a visitor departs. This prevents the next visitor from seeing the previous conversation.",
  "PresenceCooldownTime": "Cooldown Time",
  "PresenceCooldownTimeInfo": "Set the time (in seconds) before detection resumes after returning to idle state. Prevents the same person from being greeted repeatedly.",
  "PresenceDetectionSensitivity": "Detection Sensitivity",
  "PresenceDetectionSensitivityInfo": "Select the sensitivity for face detection. Higher sensitivity shortens the detection interval but increases CPU load.",
  "PresenceSensitivityLow": "Low (500ms interval)",
  "PresenceSensitivityMedium": "Medium (300ms interval)",
  "PresenceSensitivityHigh": "High (150ms interval)",
  "PresenceDetectionThreshold": "Detection Confirmation Time",
  "PresenceDetectionThresholdInfo": "Set the time (in seconds) from when a face is detected until it is confirmed as a visitor. To prevent false positives, a visitor is only recognized when a face is detected continuously for a certain period. Set to 0 for immediate detection.",
  "PresenceDebugMode": "Debug Mode",
  "PresenceDebugModeInfo": "Displays a preview of the camera feed and face detection frame. Useful for checking settings and debugging.",
  "PresenceTimingSettings": "Timing Settings",
  "PresenceTimingSettingsInfo": "Adjust the timing for departure detection and cooldown.",
  "PresenceDetectionSettings": "Detection Settings",
  "PresenceDetectionSettingsInfo": "Adjust face detection sensitivity and confirmation time.",
  "PresenceDeveloperSettings": "Developer Settings",
  "PresenceCameraSettings": "Camera Settings",
  "PresenceCameraSettingsInfo": "Select the camera to use for presence detection.",
  "PresenceSelectedCamera": "Camera to Use",
  "PresenceSelectedCameraInfo": "Select the camera device to use for presence detection. Useful when multiple cameras are connected.",
  "PresenceCameraDefault": "Default (Auto-select)",
  "PresenceCameraRefresh": "Refresh Camera List",
  "PresenceCameraPermissionRequired": "Please allow camera access in your browser to retrieve the camera list.",
  "PresenceStateIdle": "Idle",
  "PresenceStateDetected": "Visitor Detected",
  "PresenceStateGreeting": "Greeting",
  "PresenceStateConversationReady": "Conversation Ready",
  "PresenceDebugFaceDetected": "Face Detected",
  "PresenceDebugNoFace": "No Face Detected",
  "Seconds": "seconds",
  "IdleSettings": "Idle Mode Settings",
  "IdleModeEnabled": "Idle Mode",
  "IdleModeEnabledInfo": "When there is no conversation with visitors for an extended period, the character will automatically speak periodically. Useful for unattended operation at exhibitions and digital signage.",
  "IdleModeDisabledInfo": "Idle mode cannot be used when Real-time API mode, Audio mode, External connection mode, or Slide mode is enabled.",
  "IdleInterval": "Speech Interval",
  "IdleIntervalInfo": "Set the time from the last conversation to the next automatic speech ({{min}} to {{max}} seconds).",
  "IdleSpeechSource": "Speech Source",
  "IdleSpeechSourceInfo": "Select the speech method during idle time.",
  "IdleSpeechSourcePhraseList": "Phrase List",
  "IdlePlaybackMode": "Playback Mode",
  "IdlePlaybackModeInfo": "Select the playback order for the phrase list.",
  "IdlePlaybackSequential": "Sequential",
  "IdlePlaybackRandom": "Random",
  "IdleDefaultEmotion": "Greeting Emotion",
  "IdleDefaultEmotionInfo": "Select the emotion expression used for time-based greetings.",
  "IdlePhrases": "Phrase List",
  "IdlePhrasesInfo": "Register messages and emotions to speak during idle time. If multiple are registered, they will be selected according to the playback mode.",
  "IdleAddPhrase": "Add",
  "IdlePhraseTextPlaceholder": "Enter message...",
  "IdlePhraseText": "Message",
  "IdlePhraseEmotion": "Emotion",
  "IdleDeletePhrase": "Delete",
  "IdleMoveUp": "Move Up",
  "IdleMoveDown": "Move Down",
  "IdleTimePeriodEnabled": "Time-based Greetings",
  "IdleTimePeriodEnabledInfo": "Automatically switches greetings based on the time of day. When the phrase list is empty, these greetings will be used.",
  "IdleTimePeriodMorning": "Morning Greeting",
  "IdleTimePeriodAfternoon": "Afternoon Greeting",
  "IdleTimePeriodEvening": "Evening Greeting",
  "IdleAiGenerationEnabled": "AI Auto-generation",
  "IdleAiGenerationEnabledInfo": "When the phrase list is empty, AI will automatically generate messages.",
  "IdleAiPromptTemplate": "Generation Prompt",
  "IdleAiPromptTemplateHint": "Specify the character's tone and what kind of messages to generate.",
  "IdleAiPromptTemplatePlaceholder": "Generate a friendly one-liner for exhibition visitors.",
  "Emotion_neutral": "Neutral",
  "Emotion_happy": "Happy",
  "Emotion_sad": "Sad",
  "Emotion_angry": "Angry",
  "Emotion_relaxed": "Relaxed",
  "Emotion_surprised": "Surprised",
  "Idle": {
    "Speaking": "Speaking",
    "WaitingPrefix": "Waiting"
  },
  "Kiosk": {
    "PasscodeTitle": "Enter Passcode",
    "PasscodeIncorrect": "Incorrect passcode",
    "PasscodeLocked": "Temporarily locked",
    "PasscodeRemainingAttempts": "{{count}} attempts remaining",
    "Cancel": "Cancel",
    "Unlock": "Unlock",
    "FullscreenPrompt": "Tap to start in fullscreen",
    "ReturnToFullscreen": "Return to fullscreen",
    "InputInvalid": "Invalid input",
    "RecoveryHint": "If you are locked out repeatedly, delete the \"aituber-kiosk-lockout\" key from localStorage in the browser developer tools."
  },
  "KioskSettings": "Kiosk Mode Settings",
  "KioskModeEnabled": "Kiosk Mode",
  "KioskModeEnabledInfo": "A mode useful for unattended operation at exhibitions and digital signage. When enabled, access to the settings screen is restricted and fullscreen display is activated.",
  "KioskPasscode": "Passcode",
  "KioskPasscodeInfo": "Set a passcode to temporarily unlock kiosk mode. Press and hold the Esc key, or tap the top-right corner of the screen 5 times consecutively to display the passcode input screen.",
  "KioskPasscodeValidation": "Please set at least 4 alphanumeric characters",
  "KioskPasscodeInvalid": "Invalid passcode. Please enter at least 4 alphanumeric characters.",
  "KioskMaxInputLength": "Maximum Input Length",
  "KioskMaxInputLengthInfo": "Limits the maximum number of characters for user input ({{min}} to {{max}} characters).",
  "KioskNgWordEnabled": "NG Word Filter",
  "KioskNgWordEnabledInfo": "Blocks submission of user input containing NG words and displays an error message.",
  "KioskNgWords": "NG Word List",
  "KioskNgWordsInfo": "Enter NG words separated by commas. Case-insensitive, partial match.",
  "KioskNgWordsPlaceholder": "e.g.: violence, discrimination, inappropriate",
  "Characters": "characters",
  "DemoModeNotice": "This feature is not available in the demo version",
  "DemoModeLocalTTSNotice": "TTS using local servers is not available in the demo version",
  "MemoryRestoreExecute": "Execute Restore"
}
