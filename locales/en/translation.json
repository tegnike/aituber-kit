{
  "Description": "About the app",
  "BasedSettings": "Basic Settings",
  "AISettings": "AI Settings",
  "CharacterSettings": "Character Settings",
  "YoutubeSettings": "YouTube Settings",
  "VoiceSettings": "Speech Synthesis Settings",
  "SlideSettings": "Slide Settings",
  "LogSettings": "Conversation History",
  "OtherSettings": "Others",
  "ExternalLinkageMode": "External Linkage Mode (Beta)",
  "YoutubeMode": "YouTube Mode",
  "YoutubeInfo": "The first character of the comment is '#', it is ignored.",
  "YoutubeAPIKey": "YouTube API Key",
  "YoutubeLiveID": "YouTube Live ID",
  "ConversationContinuityMode": "Conversation Continuity Mode (Beta)",
  "ConversationContinuityModeInfo": "When there is no comment, AI tries to continue the conversation. Currently only OpenAI, Anthropic Claude, Google Gemini are supported.",
  "ConversationContinuityModeInfo2": "One answer calls LLM multiple times, so API usage may increase. Please be aware of this.",
  "ConversationContinuityModeInfo3": "gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet work relatively stably.",
  "MaxPastMessages": "Number of Past Messages to Keep",
  "StatusOn": "Status: ON",
  "StatusOff": "Status: OFF",
  "Select": "Select",
  "TestVoice": "Test Voice",
  "SelectAIService": "Select AI Service",
  "LocalLLM": "Local LLM",
  "SelectModel": "Select Model",
  "OpenAIAPIKeyLabel": "OpenAI API Key",
  "AnthropicAPIKeyLabel": "Anthropic API Key",
  "GoogleAPIKeyLabel": "Google Gemini API Key",
  "AzureAPIKeyLabel": "Azure OpenAI API Key",
  "AzureAPIURL": "Azure OpenAI API URL",
  "GroqAPIKeyLabel": "Groq API Key",
  "CohereAPIKeyLabel": "Cohere API Key",
  "MistralAIAPIKeyLabel": "MistralAI API Key",
  "PerplexityAPIKeyLabel": "Perplexity API Key",
  "FireworksAPIKeyLabel": "Fireworks API Key",
  "DifyAPIKeyLabel": "Dify API Key",
  "DeepSeekAPIKeyLabel": "DeepSeek API Key",
  "APIKeyInstruction": "You can obtain the API key below. Enter the obtained API key into the form.",
  "LocalLLMInfo": "Local LLM server must be running. Setup is as follows.",
  "LocalLLMInfo2": "Please enter the URL of the local LLM server (including port number) and the model name.",
  "GroqInfo": "Groq API is accessed directly from the browser.",
  "DifyInfo": "Dify only supports chatbot and agent type.",
  "DifyInfo2": "The length of the conversation history is dependent on the specifications of Dify.",
  "DifyInfo3": "Example: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "If you are using Dify, the system prompt will not be used. Please set Dify chatbot.",
  "EnterURL": "URL",
  "CharacterModelLabel": "Character Model",
  "CharacterModelInfo": "The model may take time to load when first displayed.",
  "OpenVRM": "Open VRM",
  "BackgroundImage": "Background Image",
  "ChangeBackgroundImage": "Change Background Image",
  "CharacterSettingsPrompt": "Character Prompt",
  "CharacterSettingsInfo": "This value is set as the system prompt.\nPlease refer to the initial prompt and specify the emotion tags to control the character's expressions and motions. Example: [neutral]Good morning![happy]Today is also a hard day!",
  "characterpresetInfo": "Selecting a preset changes the character prompt.\nShortcuts are available by pressing Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).\nHolding down the Shift key and selecting a preset will save the current character prompt to the preset.",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Choose Synthetic Voice Engine",
  "VoiceAdjustment": "Voice Adjustment",
  "VoiceEngineInstruction": "Select the synthetic voice engine you want to use.",
  "UsingKoeiromap": "Koeiromap",
  "KoeiromapInfo": "Using Koeiromap API from Koemotion. It only supports Japanese. For more details, please refer to the link below.",
  "UsingVoiceVox": "VOICEVOX",
  "VoiceVoxInfo": "Using VOICEVOX. It only supports Japanese. It uses a local API, you need to download and launch the app that suits your environment from the site below.",
  "VoicevoxSpeed": "Speed",
  "VoicevoxPitch": "Pitch",
  "VoicevoxIntonation": "Intonation",
  "UsingAivisSpeech": "AivisSpeech",
  "AivisSpeechInfo": "Using AivisSpeech. It only supports Japanese. It uses a local API, you need to download and launch the app that suits your environment from the site below.",
  "AivisSpeechSpeaker": "Speaker",
  "AivisSpeechSpeed": "Speed",
  "AivisSpeechPitch": "Pitch",
  "AivisSpeechIntonation": "Intonation",
  "AivisSpeechServerUrl": "AivisSpeech Server URL",
  "UsingNijiVoice": "NijiVoice",
  "NijiVoiceInfo": "NijiVoice API is used. It supports only Japanese. API key can be obtained from the URL below.",
  "NijiVoiceApiKey": "NijiVoice API Key",
  "NijiVoiceActorId": "Actor ID",
  "NijiVoiceSpeed": "Speech Speed",
  "NijiVoiceEmotionalLevel": "Emotional Level",
  "NijiVoiceSoundDuration": "Sound Duration",
  "VoicevoxServerUrl": "VOICEVOX Server URL",
  "UpdateSpeakerList": "Update Speaker List",
  "UsingGoogleTTS": "Use Google Text-to-Speech",
  "UsingStyleBertVITS2": "Style-Bert-VITS2",
  "StyleBertVITS2Info": "Using Style-Bert-VITS2. It supports only Japanese, English, and Chinese. If using a local API, you need to download and launch the app that suits your environment from the site below. Please also set up an API key if necessary.",
  "SpeakerSelection": "Speaker Selection",
  "IncludeTimestampInUserMessage": "Include timestamp in user message",
  "IncludeTimestampInUserMessageInfo": "By including timestamps in user messages, the AI can generate responses while considering the time.\nPlease include the following text in your system prompt:\n\n\"User input may include [timestamp]. This represents the UTC time at the moment of the request, so please generate responses considering this timestamp.\"",
  "GoogleTTSInfo": "Using Google Cloud Text-to-Speech. It supports multiple languages.",
  "AuthFileInstruction": "API key or authentication file is required. Get it from the URL below and place it in the root folder of the repository if it is a JSON file.",
  "LanguageModelURL": "Select the language model from the URL below.",
  "LanguageChoice": "Language Choice",
  "StyleBeatVITS2ServerURL": "Server URL",
  "StyleBeatVITS2ApiKey": "API Key",
  "StyleBeatVITS2ModelID": "Model ID",
  "StyleBeatVITS2Style": "Style",
  "StyleBeatVITS2SdpRatio": "SDP/DP Mixing Ratio",
  "StyleBeatVITS2Length": "Speech Rate",
  "ConversationHistory": "Conversation History",
  "ConversationHistoryInfo": "The last {{count}} conversation texts will be retained as memory.",
  "ConversationHistoryReset": "Reset Conversation History",
  "NotConnectedToExternalAssistant": "Not connected to an external assistant.",
  "APIKeyNotEntered": "API key is not entered.",
  "ChatLog": "Conversation Log",
  "EnterYourQuestion": "Enter your question here",
  "AnswerGenerating": "Answer Generating",
  "AboutThisApplication": "About This Application",
  "AboutThisApplicationDescription": "Enjoy conversations with a 3D character right in your web browser, using microphone or text input and voice synthesis. You can also change the character (VRM), adjust its personality, and modify its voice.<br />Settings can be changed from the menu button in the top left.",
  "AboutThisApplicationDescription2": "If you want to change the character, please refer to the \"Character Settings\" tab.",
  "TechnologyIntroduction": "Technology Introduction",
  "TechnologyIntroductionDescription1": "This app was created by modifying pixiv's <b>ChatVRM</b>. The original source code can be found",
  "TechnologyIntroductionLink1": "here",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "For displaying and manipulating 3D models,",
  "TechnologyIntroductionDescription4": "is used. For generating conversation text, various LLMs such as",
  "TechnologyIntroductionDescription5": "are used. For speech synthesis, various TTS engines like",
  "TechnologyIntroductionDescription6": "are utilized. For more details, please check out this",
  "TechnologyIntroductionLink2": "explanatory article",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "The source code for this app is publicly available on GitHub. Feel free to modify and adapt it as you like.",
  "SourceCodeDescription2": "For commercial use, please refer to the README of the same repository.",
  "RepositoryURL": "Repository URL:",
  "DontShowIntroductionNextTime": "Do not show this dialog next time",
  "Close": "CLOSE",
  "Contact": "Contact",
  "ContactDescription": "Please contact me via the email address or Twitter account below regarding this app.",
  "Creator": "Creator",
  "CreatorDescription": "Creator: Tegan",
  "Language": "Language",
  "UsingGSVITTS": "GSVI TTS",
  "GSVITTSInfo": "GSVI TTS Settings",
  "GSVITTSServerUrl": "GSVI TTS Endpoint API",
  "GSVITTSModelID": "GSVI TTS Model ID",
  "GSVITTSBatchSize": "GSVI TTS Batch Size (1 ~ 100 The larger the value, the faster the inference speed, but it might exhaust memory if too large.)",
  "GSVITTSSpeechRate": "Speech Rate (0.5 ~ 2.0 The bigger the value, the faster it is.)",
  "UsingElevenLabs": "ElevenLabs",
  "ElevenLabsInfo": "ElevenLabs API is used. It supports multiple languages. API key can be obtained from the URL below.",
  "ElevenLabsApiKey": "ElevenLabs API Key",
  "ElevenLabsVoiceId": "ElevenLabs Voice ID",
  "ElevenLabsVoiceIdInfo": "Voice ID can be selected from the URL below.",
  "CharacterName": "Character name",
  "ShowAssistantText": "Show answer box",
  "ShowCharacterName": "Show character name in the answer box",
  "ShowControlPanel": "Show settings button",
  "ShowControlPanelInfo": "You can display the settings screen by pressing Cmd + . (Mac) / Ctrl + . (Windows).\nIf you are using a smartphone, you can also long-press the top left of the screen (for about 1 second).",
  "SlideMode": "Slide Mode",
  "SelectedSlideDocs": "Selected Slide Documents",
  "SlideModeDescription": "This is a mode where AI automatically presents slides. It is only available when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertLabel": "PDF Slide Conversion",
  "PdfConvertDescription": "Convert PDF to slide mode data. Available only when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertFileUpload": "Select PDF file",
  "PdfConvertFolderName": "Save folder name",
  "PdfConvertModelSelect": "Select model",
  "PdfConvertButton": "Convert PDF to slides",
  "PdfConvertLoading": "Converting...",
  "PdfConvertSuccess": "Conversion completed",
  "PdfConvertError": "Conversion failed",
  "PdfConvertSubmitError": "Please make sure the PDF file, folder name, and API key are set.",
  "LocalStorageReset": "Reset Settings",
  "LocalStorageResetInfo": "Environment variables are prioritized if set. The page will be reloaded.",
  "LocalStorageResetButton": "Reset Settings",
  "NoSpeechTimeout": "No Speech Timeout",
  "NoSpeechTimeoutInfo": "Set the time to automatically end input when silence continues during voice input.\nSetting to 0 seconds disables automatic submission by silence detection.",
  "Errors": {
    "EmptyAPIKey": "API key is not set",
    "AIInvalidProperty": "AI service settings are incorrect",
    "AIAPIError": "An error occurred while executing the AI API",
    "InvalidAIService": "The selected AI service is not valid",
    "MethodNotAllowed": "The request is not appropriate",
    "TTSServiceError": "An error occurred in the {{serviceName}} TTS service: {{message}}",
    "UnexpectedError": "An unexpected error occurred",
    "LocalLLMError": "Local LLM error",
    "LocalLLMStreamError": "Local LLM stream error",
    "LocalLLMConnectionError": "Local LLM server connection error",
    "LocalLLMNotFound": "Local LLM endpoint not found",
    "LocalLLMAPIError": "Local LLM API error",
    "EmptyLocalLLMURL": "The local LLM URL is not set",
    "CustomAPIError": "An error occurred with the custom API",
    "InvalidJSON": "The JSON format is incorrect"
  },
  "MessageReceiver": "Receive instructions from outside",
  "MessageReceiverDescription": "You can use API to instruct AI characters to speak from outside.",
  "ClientID": "Client ID",
  "OpenSendMessagePage": "Open Send Message Page",
  "RealtimeAPIMode": "Realtime API Mode",
  "RealtimeAPIModeContentType": "Send Type",
  "RealtimeAPIModeVoice": "Voice Type",
  "AudioMode": "Audio Mode",
  "InputText": "Text",
  "InputAudio": "Audio",
  "SearchGrounding": "Use Search Grounding",
  "SearchGroundingDescription": "When using the multi-modal feature, the search function is automatically disabled.",
  "UpdateRealtimeAPISettings": "Update Realtime API Settings",
  "UpdateRealtimeAPISettingsInfo": "When updating the API key, Azure Endpoint, voice type, model, or system prompt, please press the update button to start a new WebSocket session.",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "Error occurred in WebSocket connection",
    "WebSocketConnectionClosed": "WebSocket connection closed",
    "WebSocketConnectionAttempt": "Attempting WebSocket connection...",
    "WebSocketConnectionSuccess": "WebSocket connection successful",
    "FunctionExecuting": "Executing {{funcName}}",
    "FunctionExecutionFailed": "Execution of {{funcName}} failed",
    "FirefoxNotSupported": "This feature is not supported on Firefox",
    "SpeechRecognitionError": "Speech recognition error occurred",
    "NoSpeechDetected": "No speech detected",
    "PresetSwitching": "Switched to {{presetName}}.",
    "WhisperError": "An error occurred in speech recognition by Whisper"
  },
  "UsingOpenAITTS": "Using OpenAI",
  "OpenAITTSInfo": "Using OpenAI. It supports multiple languages. If you select OpenAI as the AI service, you do not need to set the API key below.",
  "OpenAITTSVoice": "Voice type",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Speed",
  "UsingAzureTTS": "Using Azure OpenAI",
  "AzureTTSInfo": "Using Azure OpenAI. It supports multiple languages.",
  "SendMessage": {
    "title": "AITuberKit External Adapter",
    "directSendTitle": "Directly speak to AI character",
    "directSendDescription": "You can send the message directly to the AI character. If multiple messages are sent, they are processed in order. The voice model is the one selected in the AITuberKit settings.",
    "aiGenerateTitle": "Generate AI response and then speak",
    "aiGenerateDescription": "The AI generates a response from the message sent and then speaks it. If multiple messages are sent, they are processed in order. The AI model and voice model are the ones selected in the AITuberKit settings. The system prompt can be selected to use the AITuberKit system prompt or a custom system prompt. If you want to load the past conversation history, include the string [conversation_history] in the system prompt or user message.",
    "useCurrentSystemPrompt": "Use AITuberKit system prompt",
    "userInputTitle": "Send user input",
    "userInputDescription": "The message sent is processed the same as when input from the AITuberKit input form. If multiple messages are sent, they are processed in order. The AI model and voice model are the ones selected in the AITuberKit settings. The system prompt and conversation history are the values set in AITuberKit."
  },
  "CannotUseVoice": "If real-time API mode or audio mode is enabled,\nSpeech synthesis settings are not needed.",
  "Live2D": {
    "FileInfo": "Place the Live2D model you want to use in the public/live2d folder. The model3.json file must exist in the root of this folder.\nIf it is not displayed in the selection, please reload the screen or check if the folder path is correct.",
    "Info": "You can specify emotions and motions.\nEach emotion is controlled by the prompt. For more details, please refer to \"AI Settings => Character Settings\".",
    "Emotions": "Emotion Settings",
    "EmotionInfo": "Emotions can be specified in comma-separated format. If multiple emotions are specified, they are randomly selected.\nThe initial value is for the model provided by AITuberKit. If you are using an original model, please enter the value according to your model.\nAfter conversation completion, the \"Neutral\" emotion is displayed.",
    "neutralEmotions": "Neutral",
    "happyEmotions": "Happy",
    "sadEmotions": "Sad",
    "angryEmotions": "Angry",
    "relaxedEmotions": "Relaxed",
    "MotionGroups": "Motion Group Settings",
    "MotionGroupsInfo": "Motion groups are randomly selected from the selected group.\nSame as emotion settings, please set it according to your model.\n\"Idle\" is the motion displayed after conversation completion.",
    "SelectMotionGroup": "Select Motion Group",
    "idleMotionGroup": "Idle",
    "neutralMotionGroup": "Neutral",
    "happyMotionGroup": "Happy",
    "sadMotionGroup": "Sad",
    "angryMotionGroup": "Angry",
    "relaxedMotionGroup": "Relaxed",
    "surprisedEmotions": "Surprise",
    "surprisedMotionGroup": "Surprise"
  },
  "UseVideoAsBackground": "Use shared screen or webcam as background",
  "Temperature": "Temperature",
  "MaxTokens": "Maximum Token Count",
  "MaxTokensInfo": "The maximum token count varies depending on the AI model in use. Please check the specifications of each model.",
  "CannotUseParameters": "If real-time API mode or audio mode is enabled, the Temperature and Max Tokens parameters cannot be specified.",
  "DocumentationDescription": "For detailed usage and tutorials of AITuberKit, please visit the URL below.",
  "PresetQuestions": "Preset Questions",
  "PresetQuestionsInfo": "You can create and register multiple question patterns in advance. Registered questions will be displayed as buttons on the user UI, and clicking them will set them in the chat input field.",
  "EnterPresetQuestion": "Please enter a question",
  "DragToReorder": "Drag to reorder",
  "ShowSilenceProgressBar": "Show Silence Detection Progress Bar",
  "CharacterpresetInfo": "Selecting a preset will change the character prompt.\nYou can use shortcuts with Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "SpeechInputSettings": "Speech Input Settings",
  "SpeechRecognitionMode": "Speech Recognition Mode",
  "SpeechRecognitionModeInfo": "You can select the speech recognition mode.\n\"Browser Standard\" uses the built-in speech recognition of the browser. \"OpenAI TTS\" uses OpenAI's Text to Speech API.\nGenerally, \"Browser Standard\" is recommended as it has higher accuracy and faster recognition speed. However, if you are using a browser that does not support the WebSpeech API, such as Firefox, please select \"OpenAI TTS.\"",
  "BrowserSpeechRecognition": "Use Browser Standard Speech Recognition",
  "WhisperSpeechRecognition": "Use OpenAI TTS Speech Recognition",
  "WhisperAPIKeyInfo": "An OpenAI API key is required for Whisper mode. Please set the OpenAI API key in the AI settings.",
  "WhisperTranscriptionModel": "Transcription Model",
  "WhisperTranscriptionModelInfo": "You can select the model to be used for speech recognition. Higher performance models can recognize with higher accuracy, but may incur higher API costs.",
  "InitialSpeechTimeout": "Speech Recognition Timeout",
  "InitialSpeechTimeoutInfo": "Set the waiting time until the first utterance is detected after speech recognition starts. If no utterance is detected within this time, speech recognition will automatically stop.\nSetting it to 0 seconds will make the waiting time unlimited.",
  "Milliseconds": "Milliseconds",
  "ContinuousMic": "Continuous Microphone Input",
  "ContinuousMicActive": "Continuous Microphone Input Active",
  "ContinuousMicModeOn": "Continuous Microphone Input Mode is On",
  "ContinuousMicModeOff": "Continuous Microphone Input Mode is Off",
  "ListeningContinuously": "Waiting for voice input...",
  "ContinuousMicInfo": "The microphone input will automatically resume when the AI's speech ends. It will automatically send after the set silence duration.\nIf the set time is exceeded without speech recognition, continuous microphone input will automatically turn OFF, so if you want it to always be ON, set the speech recognition timeout to 0 seconds.",
  "CustomAPIEndpoint": "Custom API Endpoint",
  "CustomAPIEndpointInfo": "Please enter the URL of the API endpoint to send POST requests.",
  "CustomAPIStream": "Streaming Mode",
  "CustomAPIStreamForced": "Currently, streaming mode is always enabled.",
  "CustomAPIHeaders": "Custom Headers",
  "CustomAPIHeadersInfo": "Please enter the header information to include in the API request in JSON format.",
  "CustomAPIBody": "Custom Body",
  "CustomAPIBodyInfo": "Please enter the body information to include in the API request in JSON format. Messages will be included automatically.",
  "CustomAPIDescription": "Note: Messages are automatically included in the request body. In streaming mode, the server must return text/event-stream.",
  "ShowCharacterPresetMenu": "Show Character Preset Menu Button",
  "SpeechRecognitionModeDisabledInfo": "If audio mode is enabled, only browser speech recognition is available.\nAlso, in real-time API mode, only browser speech recognition is available, and the speech recognition timeout feature will be disabled."
}
