{
  "Description": "About the App",
  "BasedSettings": "Basic Settings",
  "AISettings": "AI Settings",
  "CharacterSettings": "Character Settings",
  "YoutubeSettings": "YouTube Settings",
  "VoiceSettings": "Voice Synthesis Settings",
  "SpeechInputSettings": "Voice Input Settings",
  "SlideSettings": "Slide Settings",
  "LogSettings": "Conversation History",
  "OtherSettings": "Other",
  "ExternalLinkageMode": "External Connection Mode (Beta)",
  "YoutubeMode": "YouTube Mode",
  "YoutubeInfo": "Comments starting with '#' are ignored.",
  "YoutubeAPIKey": "YouTube API Key",
  "YoutubeLiveID": "YouTube Live ID",
  "ConversationContinuityMode": "Conversation Continuity Mode (Beta)",
  "ConversationContinuityModeInfo": "This is a mode where AI tries to continue the conversation when there are no comments. Currently only supports OpenAI, Anthropic Claude, Google Gemini.",
  "ConversationContinuityModeInfo2": "Since LLM is called multiple times for a single response, API usage fees may increase. Please be aware of this.",
  "ConversationContinuityModeInfo3": "Relatively stable operation with gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnet.",
  "MaxPastMessages": "Number of Past Messages to Keep",
  "StatusOn": "Status: ON",
  "StatusOff": "Status: OFF",
  "Select": "Please select",
  "TestVoice": "Test Voice",
  "SelectAIService": "Select AI Service",
  "LocalLLM": "Local LLM",
  "SelectModel": "Select Model",
  "OpenAIAPIKeyLabel": "OpenAI API Key",
  "AnthropicAPIKeyLabel": "Anthropic API Key",
  "GoogleAPIKeyLabel": "Google Gemini API Key",
  "AzureAPIKeyLabel": "Azure OpenAI API Key",
  "AzureAPIURL": "Azure OpenAI API URL",
  "GroqAPIKeyLabel": "Groq API Key",
  "CohereAPIKeyLabel": "Cohere API Key",
  "MistralAIAPIKeyLabel": "MistralAI API Key",
  "PerplexityAPIKeyLabel": "Perplexity API Key",
  "FireworksAPIKeyLabel": "Fireworks API Key",
  "DifyAPIKeyLabel": "Dify API Key",
  "DeepSeekAPIKeyLabel": "DeepSeek API Key",
  "APIKeyInstruction": "API keys can be obtained from the links below. Enter the obtained API key in the form.",
  "LocalLLMInfo": "You need to have a local LLM server running.",
  "LocalLLMInfo2": "Please enter the URL of your local LLM (including port number) and the model name.",
  "GroqInfo": "Groq API is accessed directly from the browser.",
  "DifyInfo": "Dify only supports chatbot or agent types. If you do not receive a satisfactory answer, please delete the conversation history and ask again.",
  "DifyInfo2": "The length of conversation history depends on the Dify chatbot settings.",
  "DifyInfo3": "Example: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "If you are using Dify, this system prompt is not used. Please set it in the Dify chatbot.",
  "EnterURL": "Enter URL",
  "CharacterModelLabel": "Character Model",
  "CharacterModelInfo": "Some models may take time to load during initial display.",
  "OpenVRM": "Open VRM",
  "BackgroundImage": "Background Image",
  "ChangeBackgroundImage": "Change Background Image",
  "BackgroundSettings": "Background Settings",
  "BackgroundSettingsDescription": "You can upload and select background images for the application.",
  "UploadBackground": "Upload Background Image",
  "DefaultBackground": "Default Background",
  "CharacterSettingsPrompt": "Character Prompt",
  "CharacterSettingsInfo": "This value is set as the system prompt.\nReferring to the initial prompt, you can control the character's expressions and motions by specifying emotion tags. Example: [neutral]Good morning![happy]Thank you for your hard work today!",
  "CharacterpresetInfo": "Selecting a preset will change the character prompt.\nShortcuts are available with Cmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows).",
  "Characterpreset1": "Preset 1",
  "Characterpreset2": "Preset 2",
  "Characterpreset3": "Preset 3",
  "Characterpreset4": "Preset 4",
  "Characterpreset5": "Preset 5",
  "SyntheticVoiceEngineChoice": "Select Voice Synthesis Engine",
  "VoiceAdjustment": "Voice Adjustment",
  "VoiceEngineInstruction": "Please select the voice synthesis engine to use.",
  "UsingKoeiromap": "Use Koeiromap",
  "KoeiromapInfo": "Using Koeiromap API from Koemotion. Supports Japanese only. See below for details.",
  "UsingVoiceVox": "Use VOICEVOX",
  "VoiceVoxInfo": "Using VOICEVOX. Supports Japanese only. Since it uses a local API, you need to download and run the appropriate app for your environment from the site below.",
  "VoicevoxSpeed": "Speaking Speed",
  "VoicevoxPitch": "Pitch",
  "VoicevoxIntonation": "Intonation",
  "VoicevoxServerUrl": "VOICEVOX Server URL",
  "UsingAivisSpeech": "Use AivisSpeech",
  "AivisSpeechInfo": "Using AivisSpeech. Supports Japanese only. Since it uses a local API, you need to download and run the appropriate app for your environment from the site below.",
  "AivisSpeechSpeaker": "Speaker",
  "AivisSpeechSpeed": "Speaking Speed",
  "AivisSpeechPitch": "Pitch",
  "AivisSpeechIntonation": "Intonation",
  "AivisSpeechServerUrl": "AivisSpeech Server URL",
  "UsingNijiVoice": "Use NijiVoice",
  "NijiVoiceInfo": "Using NijiVoice API. Supports Japanese only. Please get an API key from the URL below.",
  "NijiVoiceApiKey": "NijiVoice API Key",
  "NijiVoiceActorId": "Speaker ID",
  "NijiVoiceSpeed": "Speaking Speed",
  "NijiVoiceEmotionalLevel": "Emotional Level",
  "NijiVoiceSoundDuration": "Voice Duration",
  "UpdateSpeakerList": "Update Speaker List",
  "UsingGoogleTTS": "Use Google Text-to-Speech",
  "UsingStyleBertVITS2": "Use Style-Bert-VITS2",
  "StyleBertVITS2Info": "Using Style-Bert-VITS2. Supports Japanese, English, and Chinese only. If using a local API, you need to download and run the appropriate app for your environment from the site below. Set up the API key if necessary.",
  "SpeakerSelection": "Voice Type Selection",
  "EnglishToJapanese": "Read English words in Japanese",
  "IncludeTimestampInUserMessage": "Include timestamp in user messages",
  "IncludeTimestampInUserMessageInfo": "Including a timestamp in user messages allows the AI to generate responses considering the time.\nPlease include the following text in your system prompt:\n\n\"User input may be requested with a [timestamp], which represents the time in UTC timezone at the time of the request, so please generate a response considering that time.\"",
  "GoogleTTSInfo": "Using Google Cloud Text-to-Speech. Supports multiple languages.",
  "AuthFileInstruction": "An API key or authentication JSON file is required. Obtain it from below, and if it's a JSON file, place it in the root folder of the repository as 'credentials.json'.",
  "LanguageModelURL": "Please select a language model from the URL below.",
  "LanguageChoice": "Language Selection",
  "StyleBeatVITS2ServerURL": "Server URL",
  "StyleBeatVITS2ApiKey": "API Key",
  "StyleBeatVITS2ModelID": "Model ID",
  "StyleBeatVITS2Style": "Style",
  "StyleBeatVITS2SdpRatio": "SDP/DP Mix Ratio",
  "StyleBeatVITS2Length": "Speaking Speed",
  "ConversationHistory": "Conversation History",
  "ConversationHistoryInfo": "The most recent {{count}} conversation sentences are retained as memory.",
  "ConversationHistoryReset": "Reset Conversation History",
  "NotConnectedToExternalAssistant": "Not connected to external assistant.",
  "APIKeyNotEntered": "API key has not been entered.",
  "ChatLog": "Conversation Log",
  "EnterYourQuestion": "Enter what you want to ask",
  "AnswerGenerating": "Generating answer",
  "AboutThisApplication": "About This Application",
  "AboutThisApplicationDescription": "You can enjoy conversations with 3D characters in a web browser using microphone, text input, and voice synthesis. You can change the character (VRM), personality settings, and voice adjustments.<br />Settings can be changed from the menu button in the top left.",
  "AboutThisApplicationDescription2": "With AITuberKit, you can enjoy conversations with AI characters in a web browser. Please check each setting item for changing characters, personality settings, and voice adjustments.",
  "TechnologyIntroduction": "Technology Introduction",
  "TechnologyIntroductionDescription1": "This app is created by modifying pixiv's <b>ChatVRM</b>. The original source code is",
  "TechnologyIntroductionLink1": "here",
  "TechnologyIntroductionDescription2": ".",
  "TechnologyIntroductionDescription3": "For 3D model display and operation,",
  "TechnologyIntroductionDescription4": ", for conversation generation,",
  "TechnologyIntroductionDescription5": "and various LLMs, for voice synthesis,",
  "TechnologyIntroductionDescription6": "and various TTS services are used. For details, please see this",
  "TechnologyIntroductionLink2": "explanatory article",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "The source code of this app is available on GitHub. You can freely modify and alter it.",
  "SourceCodeDescription2": "For commercial use, please refer to the README in the same repository.",
  "RepositoryURL": "Repository URL:",
  "DontShowIntroductionNextTime": "Don't show this dialog next time",
  "Close": "Close",
  "Contact": "Contact",
  "ContactDescription": "For inquiries about this app, please contact the email address or Twitter account below.",
  "Creator": "Creator Information",
  "CreatorDescription": "Creator: Nike",
  "Documentation": "Documentation",
  "DocumentationDescription": "For detailed usage and tutorials of AITuberKit, please visit the URL below.",
  "Language": "Language Settings",
  "UsingGSVITTS": "Use GSVI TTS",
  "GSVITTSInfo": "GSVI TTS Settings",
  "GSVITTSServerUrl": "GSVI TTS Server URL",
  "GSVITTSModelID": "GSVI TTS Model ID",
  "GSVITTSBatchSize": "GSVI TTS Batch Size (1 ~ 100 The larger the value, the faster the inference speed, but if it's too large, it may exhaust memory)",
  "GSVITTSSpeechRate": "Speaking Speed (0.5 ~ 2.0 The larger the value, the faster)",
  "UsingElevenLabs": "Use ElevenLabs",
  "ElevenLabsInfo": "Using ElevenLabs API. Supports multiple languages. Please get an API key from the URL below.",
  "ElevenLabsApiKey": "ElevenLabs API Key",
  "ElevenLabsVoiceId": "ElevenLabs Voice ID",
  "ElevenLabsVoiceIdInfo": "Please select a Voice ID from the URL below.",
  "CharacterName": "Character Name",
  "ShowAssistantText": "Show answer field",
  "ShowCharacterName": "Show character name in answer field",
  "ShowControlPanel": "Show control panel",
  "ShowControlPanelInfo": "The settings screen can be displayed with Cmd + . (Mac) / Ctrl + . (Windows).\nIf you are using a smartphone, you can also long press (about 1 second) the top left of the screen.",
  "ShowCharacterPresetMenu": "Show character preset menu button",
  "SlideMode": "Slide Mode",
  "SelectedSlideDocs": "Slides to use",
  "SlideModeDescription": "This is a mode where AI automatically presents slides. Only valid when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertLabel": "PDF Slide Conversion",
  "PdfConvertDescription": "Convert PDF to data for slide mode. Only available when the selected AI service is OpenAI, Anthropic Claude, or Google Gemini.",
  "PdfConvertFileUpload": "Select PDF file",
  "PdfConvertFolderName": "Save folder name",
  "CustomVoiceTextPlaceholder": "Enter text you want to hear",
  "TestVoiceSettings": "Voice Test",
  "TestSelectedVoice": "Play",
  "PdfConvertModelSelect": "Select model",
  "PdfConvertButton": "Convert PDF to slides",
  "PdfConvertLoading": "Converting...",
  "PdfConvertSuccess": "Conversion complete",
  "PdfConvertError": "Conversion failed",
  "PdfConvertSubmitError": "Please check that the PDF file, folder name, and API key are set",
  "LocalStorageReset": "Reset settings",
  "LocalStorageResetInfo": "If environment variables are set, those values take precedence. The page will be reloaded.",
  "LocalStorageResetButton": "Reset Settings",
  "InitialSpeechTimeout": "Voice recognition timeout",
  "InitialSpeechTimeoutInfo": "Set the waiting time for the first utterance to be detected after voice recognition starts. If no utterance is detected within this time, voice recognition will automatically stop.\nIf set to 0 seconds, the waiting time is unlimited.",
  "Milliseconds": "milliseconds",
  "NoSpeechTimeout": "Silence detection timeout",
  "NoSpeechTimeoutInfo": "Set the time to automatically end input when no sound is detected during voice input.\nIf set to 0 seconds, automatic submission by silence detection is disabled.",
  "ShowSilenceProgressBar": "Show silence detection progress bar",
  "SpeechRecognitionMode": "Voice recognition mode",
  "SpeechRecognitionModeInfo": "You can select the voice recognition mode.\n'Browser standard' uses the browser's built-in voice recognition. 'OpenAI TTS' uses OpenAI's Text to Speech API.\nGenerally, 'Browser standard' is recommended as it has higher accuracy and faster recognition speed. However, if you are using a browser that does not support WebSpeech API, such as Firefox, please select 'OpenAI TTS'.",
  "BrowserSpeechRecognition": "Use browser standard voice recognition",
  "WhisperSpeechRecognition": "Use OpenAI TTS voice recognition",
  "WhisperTranscriptionModel": "Transcription model",
  "WhisperTranscriptionModelInfo": "You can select the model to use for voice recognition. More advanced models can recognize with higher accuracy, but may incur higher API costs.",
  "SpeechRecognitionModeDisabledInfo": "If audio mode is enabled, only browser voice recognition can be used.\nAlso, in real-time API mode, only browser voice recognition can be used, and the voice recognition timeout function is disabled.",
  "Errors": {
    "EmptyAPIKey": "API key is not set",
    "EmptyLocalLLMURL": "Local LLM URL is not set",
    "AIInvalidProperty": "AI service setting value is incorrect",
    "AIAPIError": "An error occurred during AI API execution",
    "InvalidAIService": "Selected AI service is incorrect",
    "MethodNotAllowed": "Request is not appropriate",
    "TTSServiceError": "An error occurred in {{serviceName}} TTS service: {{message}}",
    "UnexpectedError": "An unknown error occurred",
    "LocalLLMError": "An error occurred in local LLM",
    "LocalLLMStreamError": "An error occurred in local LLM stream processing",
    "LocalLLMConnectionError": "Cannot connect to local LLM server",
    "LocalLLMNotFound": "Local LLM endpoint not found",
    "LocalLLMAPIError": "An error occurred in local LLM API",
    "CustomAPIError": "An error occurred in custom API",
    "InvalidJSON": "JSON format is incorrect"
  },
  "MessageReceiver": "Accept instructions from external sources",
  "MessageReceiverDescription": "You can instruct the AI character's speech from external sources using API.",
  "ClientID": "Client ID",
  "OpenSendMessagePage": "Open message sending page",
  "RealtimeAPIMode": "Real-time API mode",
  "RealtimeAPIModeContentType": "Submission type",
  "RealtimeAPIModeVoice": "Voice type",
  "AudioMode": "Audio mode",
  "InputText": "Text",
  "InputAudio": "Audio",
  "SearchGrounding": "Use search function",
  "SearchGroundingDescription": "When using multimodal features, the search function is automatically disabled.",
  "UpdateRealtimeAPISettings": "Update real-time API settings",
  "UpdateRealtimeAPISettingsInfo": "When you update the API key, Azure Endpoint, voice type, model, or system prompt, press the update button to start a new WebSocket session.",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "An error occurred in the WebSocket connection",
    "WebSocketConnectionClosed": "WebSocket connection has been closed",
    "WebSocketConnectionAttempt": "Attempting WebSocket connection...",
    "WebSocketConnectionSuccess": "WebSocket connection succeeded",
    "FunctionExecuting": "Running {{funcName}}",
    "FunctionExecutionFailed": "Failed to execute {{funcName}}",
    "FirefoxNotSupported": "This feature is not supported in Firefox.",
    "SpeechRecognitionError": "A speech recognition error has occurred",
    "NoSpeechDetected": "No audio was detected.",
    "PresetSwitching": "Switched to {{presetName}}.",
    "WhisperError": "An error occurred in speech recognition by Whisper",
    "UsingTool": "Using {{toolName}}"
  },
  "ContinuousMic": "Continuous microphone input",
  "ContinuousMicActive": "Continuous microphone input active",
  "ContinuousMicModeOn": "Continuous microphone input mode is on",
  "ContinuousMicModeOff": "Continuous microphone input mode is off",
  "ListeningContinuously": "Waiting for voice input...",
  "ContinuousMicInfo": "The microphone input will automatically restart when the AI finishes speaking. It will automatically submit after the set silence time elapses.\nIf voice recognition does not occur and the set time is exceeded, continuous microphone input will automatically turn OFF, so if you want to keep it ON at all times, set the voice recognition timeout to 0 seconds.",
  "UsingOpenAITTS": "Use OpenAI",
  "OpenAITTSInfo": "Using OpenAI. Supports multiple languages. If you have selected OpenAI in the AI service, you do not need to set the API key below.",
  "OpenAITTSVoice": "Voice type",
  "OpenAITTSModel": "Model",
  "OpenAITTSSpeed": "Speaking speed",
  "UsingAzureTTS": "Use Azure OpenAI",
  "AzureTTSInfo": "Using Azure OpenAI. Supports multiple languages.",
  "SendMessage": {
    "title": "AITuberKit External Adapter",
    "directSendTitle": "Make AI character speak directly",
    "directSendDescription": "You can make the AI character speak the sent message directly. If multiple messages are sent, they will be processed in order.\nThe voice model selected in the AITuberKit settings will be used.",
    "aiGenerateTitle": "Generate a response with AI and then make it speak",
    "aiGenerateDescription": "AI generates a response from the sent message, and the AI character speaks that response. If multiple messages are sent, they will be processed in order.\nThe AI model and voice model selected in the AITuberKit settings will be used.\nYou can choose to use the AITuberKit system prompt or a custom system prompt.\nIf you want to load past conversation history, include the string [conversation_history] anywhere in the system prompt or user message.",
    "useCurrentSystemPrompt": "Use AITuberKit's system prompt",
    "userInputTitle": "Send user input",
    "userInputDescription": "The sent message will be processed the same as if it were entered from the AITuberKit input form. If multiple messages are sent, they will be processed in order.\nThe AI model and voice model selected in the AITuberKit settings will be used.\nThe system prompt and conversation history from AITuberKit will be used."
  },
  "CannotUseVoice": "If real-time API mode or audio mode is enabled,\nvoice synthesis settings are not necessary.",
  "Live2D": {
    "FileInfo": "Please place the Live2D model folder you want to use in public/live2d. A model3.json file must exist directly under this folder.\nIf it does not appear in the selection, please reload the screen or check if the folder path is correct.",
    "Info": "You can specify emotions and motions.\nEach emotion is controlled by the prompt. For details, please see 'AI Settings => Character Settings'.",
    "Emotions": "Expression settings",
    "EmotionInfo": "Multiple emotions can be specified with commas. If multiple are specified, one will be randomly selected.\nThe default values correspond to the models prepared by AITuberKit. If you are using your original model, please enter values that match your model.\nAfter the conversation is completed, the 'neutral' expression will be displayed.",
    "neutralEmotions": "Neutral",
    "happyEmotions": "Happy",
    "sadEmotions": "Sad",
    "angryEmotions": "Angry",
    "relaxedEmotions": "Relaxed",
    "surprisedEmotions": "Surprised",
    "MotionGroups": "Motion group settings",
    "MotionGroupsInfo": "Motion groups are randomly selected from the selected group.\nLike the expression settings, please set according to your own model.\n'Idle' is the motion displayed after the conversation is completed.",
    "SelectMotionGroup": "Select motion group",
    "idleMotionGroup": "Idle",
    "neutralMotionGroup": "Neutral",
    "happyMotionGroup": "Happy",
    "sadMotionGroup": "Sad",
    "angryMotionGroup": "Angry",
    "relaxedMotionGroup": "Relaxed",
    "surprisedMotionGroup": "Surprised"
  },
  "UseVideoAsBackground": "Use shared screen or webcam as background",
  "Temperature": "Temperature",
  "MaxTokens": "Maximum tokens",
  "MaxTokensInfo": "The maximum number of tokens varies depending on the AI model being used. Please check the specifications of each model.",
  "CannotUseParameters": "If real-time API mode or audio mode is enabled, Temperature and Max Tokens parameters cannot be specified.",
  "PresetQuestions": "Preset questions",
  "PresetQuestionsInfo": "You can create and register multiple question patterns in advance. Registered questions will be displayed as buttons on the user UI, and clicking them will set them in the chat input field.",
  "EnterPresetQuestion": "Please enter a question",
  "DragToReorder": "Drag to change order",
  "CustomAPIEndpoint": "Custom API endpoint",
  "CustomAPIEndpointInfo": "Enter the URL of the API endpoint to send POST requests to.",
  "CustomAPIStream": "Streaming mode",
  "CustomAPIStreamForced": "Currently, streaming mode is always enabled.",
  "IncludeSystemMessages": "Include System Messages",
  "CustomAPIHeaders": "Custom headers",
  "CustomAPIHeadersInfo": "Enter header information to include in API requests in JSON format.",
  "CustomAPIBody": "Custom body",
  "CustomAPIBodyInfo": "Enter body information to include in API requests in JSON format. messages will be automatically included.",
  "CustomAPIDescription": "Note: Messages are automatically included in the request body. In streaming mode, the server must return text/event-stream.",
  "EditSlideScripts": "Edit Dialogue",
  "PleaseSelectSlide": "Please select a slide"
}
