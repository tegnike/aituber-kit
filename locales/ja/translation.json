{
  "Description": "アプリについて",
  "BasedSettings": "基本設定",
  "AISettings": "AI設定",
  "CharacterSettings": "キャラクター設定",
  "YoutubeSettings": "YouTube設定",
  "VoiceSettings": "合成音声設定",
  "SpeechInputSettings": "音声入力設定",
  "SlideSettings": "スライド設定",
  "LogSettings": "会話履歴",
  "OtherSettings": "その他",
  "ExternalLinkageMode": "外部連携モード（ベータ版）",
  "YoutubeMode": "YouTubeモード",
  "YoutubeInfo": "先頭が「#」のコメントは無視されます。",
  "YoutubeAPIKey": "YouTube API キー",
  "YoutubeLiveID": "YouTube Live ID",
  "ConversationContinuityMode": "会話継続モード（ベータ版）",
  "ConversationContinuityModeInfo": "コメントが無いときにAIが自ら会話を継続しようとするモードです。現在OpenAI, Anthropic Claude, Google Geminiのみ対応しています。",
  "ConversationContinuityModeInfo2": "一度の回答で複数回LLMを呼び出すため、API利用料が増える可能性があります。ご注意ください。",
  "ConversationContinuityModeInfo3": "gpt-4o, gpt-4-turbo, claude-3-opus, claude-3.5-sonnetで比較的安定動作します。",
  "MaxPastMessages": "過去のメッセージ保持数",
  "StatusOn": "状態：ON",
  "StatusOff": "状態：OFF",
  "Select": "選択してください",
  "TestVoice": "ボイスを試聴する",
  "SelectAIService": "AIサービスを選択",
  "LocalLLM": "ローカルLLM",
  "SelectModel": "モデルを選択",
  "OpenAIAPIKeyLabel": "OpenAI API キー",
  "AnthropicAPIKeyLabel": "Anthropic API キー",
  "GoogleAPIKeyLabel": "Google Gemini API キー",
  "AzureAPIKeyLabel": "Azure OpenAI API キー",
  "AzureAPIURL": "Azure OpenAI API URL",
  "GroqAPIKeyLabel": "Groq API キー",
  "CohereAPIKeyLabel": "Cohere API キー",
  "MistralAIAPIKeyLabel": "MistralAI API キー",
  "PerplexityAPIKeyLabel": "Perplexity API キー",
  "FireworksAPIKeyLabel": "Fireworks API キー",
  "DifyAPIKeyLabel": "Dify API キー",
  "DeepSeekAPIKeyLabel": "DeepSeek API キー",
  "APIKeyInstruction": "APIキーは下記のリンクから取得できます。取得したAPIキーをフォームに入力してください。",
  "LocalLLMInfo": "ローカルLLM サーバーを起動している必要があります。",
  "LocalLLMInfo2": "ローカルLLMのURL（ポート番号込み）とモデル名を入力してください。",
  "GroqInfo": "Groq APIはブラウザから直接アクセスしています。",
  "DifyInfo": "Difyでは、チャットボット または エージェントタイプのみ対応しています。\n上手く回答が得られない場合は、会話履歴を削除してから改めて質問してください。",
  "DifyInfo2": "会話履歴の長さはDifyチャットボットの設定に依存します。",
  "DifyInfo3": "例：https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Difyを使用している場合、このシステムプロンプトは使用されません。Difyチャットボットに設定してください。",
  "EnterURL": "URLを入力",
  "CharacterModelLabel": "キャラクターモデル",
  "CharacterModelInfo": "モデルによっては初期表示時の読み込みに時間がかかる可能性があります。",
  "OpenVRM": "VRMを開く",
  "BackgroundImage": "背景画像",
  "ChangeBackgroundImage": "背景画像を変える",
  "BackgroundSettings": "背景設定",
  "BackgroundSettingsDescription": "アプリケーションの背景画像をアップロードして選択できます。",
  "UploadBackground": "背景画像をアップロード",
  "DefaultBackground": "デフォルト背景",
  "CharacterSettingsPrompt": "キャラクタープロンプト",
  "CharacterSettingsInfo": "この値はシステムプロンプトとして設定されます。\n初期プロンプトを参考に、感情タグを指定することでキャラクターの表情やモーションを制御できます。例: [neutral]おはようございます！[happy]今日もお疲れ様です！",
  "CharacterpresetInfo": "プリセットを選択すると、キャラクタープロンプトが変更されます。\nCmd + Shift + 1~5 (Mac) / Ctrl + Shift + 1~5 (Windows)でショートカットが可能です。",
  "Characterpreset1": "プリセット1",
  "Characterpreset2": "プリセット2",
  "Characterpreset3": "プリセット3",
  "Characterpreset4": "プリセット4",
  "Characterpreset5": "プリセット5",
  "SyntheticVoiceEngineChoice": "合成音声エンジンの選択",
  "VoiceAdjustment": "声の調整",
  "VoiceEngineInstruction": "使用する合成音声エンジンを選択してください。",
  "UsingKoeiromap": "Koeiromapを使用する",
  "KoeiromapInfo": "KoemotionのKoeiromap APIを使用しています。日本語のみに対応しています。詳しくは下記をご覧ください。",
  "UsingVoiceVox": "VOICEVOXを使用する",
  "VoiceVoxInfo": "VOICEVOXを使用しています。日本語のみに対応しています。ローカルAPIを使用するので下記のサイトから環境にあったアプリをダウンロードし、起動しておく必要があります。",
  "VoicevoxSpeed": "話速",
  "VoicevoxPitch": "音高",
  "VoicevoxIntonation": "抑揚",
  "VoicevoxServerUrl": "VOICEVOX サーバーURL",
  "UsingAivisSpeech": "AivisSpeechを使用する",
  "AivisSpeechInfo": "AivisSpeechを使用しています。日本語のみに対応しています。ローカルAPIを使用するので下記のサイトから環境にあったアプリをダウンロードし、起動しておく必要があります。",
  "AivisSpeechSpeaker": "話者",
  "AivisSpeechSpeed": "話速",
  "AivisSpeechPitch": "音高",
  "AivisSpeechIntonation": "抑揚",
  "AivisSpeechServerUrl": "AivisSpeech サーバーURL",
  "UsingNijiVoice": "にじボイスを使用する",
  "NijiVoiceInfo": "にじボイス APIを使用しています。日本語のみに対応しています。APIキーを下記のURLから取得してください。",
  "NijiVoiceApiKey": "にじボイス API キー",
  "NijiVoiceActorId": "話者ID",
  "NijiVoiceSpeed": "話速",
  "NijiVoiceEmotionalLevel": "感情レベル",
  "NijiVoiceSoundDuration": "音声の長さ",
  "UpdateSpeakerList": "話者リストを更新",
  "UsingGoogleTTS": "Google Text-to-Speechを使用する",
  "UsingStyleBertVITS2": "Style-Bert-VITS2を使用する",
  "StyleBertVITS2Info": "Style-Bert-VITS2を使用しています。日・英・中のみに対応しています。ローカルAPIを使用する場合は、下記のサイトから環境にあったアプリをダウンロードし起動しておく必要があります。必要な場合はAPIキーも設定してください。",
  "SpeakerSelection": "ボイスタイプ選択",
  "EnglishToJapanese": "英単語を日本語で読み上げる",
  "IncludeTimestampInUserMessage": "ユーザー発言にタイムスタンプを含める",
  "IncludeTimestampInUserMessageInfo": "ユーザー発言にタイムスタンプを含めることで、AIが時間を考慮して応答を生成できるようになります。\n以下のような文章をシステムプロンプトに含めてください。\n\n「ユーザー入力が [timestamp] 付きでリクエストされる場合があります。これはリクエスト時点のUTCタイムゾーンの時刻を表しているので、その時刻を考慮したうえで回答を生成してください。」",
  "GoogleTTSInfo": "Google Cloud Text-to-Speechを使用しています。多言語に対応可能です。",
  "AuthFileInstruction": "APIキーまたは認証用のJSONファイルが必要です。下記から取得し、JSONファイルの場合はリポジトリのルートフォルダに credentials.json という名称で配置してください。",
  "LanguageModelURL": "言語モデルは下記のURLから選択してください。",
  "LanguageChoice": "言語選択",
  "StyleBeatVITS2ServerURL": "サーバーURL",
  "StyleBeatVITS2ApiKey": "API キー",
  "StyleBeatVITS2ModelID": "モデルID",
  "StyleBeatVITS2Style": "スタイル",
  "StyleBeatVITS2SdpRatio": "SDP/DP混合比",
  "StyleBeatVITS2Length": "話速",
  "ConversationHistory": "会話履歴",
  "ConversationHistoryInfo": "直近の{{count}}会話文が記憶として保持されます。",
  "ConversationHistoryReset": "会話履歴リセット",
  "NotConnectedToExternalAssistant": "外部アシスタントと接続されていません。",
  "APIKeyNotEntered": "APIキーが入力されていません。",
  "ChatLog": "会話ログ",
  "EnterYourQuestion": "聞きたいことをいれてね",
  "AnswerGenerating": "回答生成中",
  "AboutThisApplication": "このアプリケーションについて",
  "AboutThisApplicationDescription": "Webブラウザだけで3Dキャラクターとの会話を、マイクやテキスト入力、音声合成を用いて楽しめます。キャラクター（VRM）の変更や性格設定、音声調整もできます。<br />設定は左上のメニューボタンから変更できます。",
  "AboutThisApplicationDescription2": "AITuberKitでは、WebブラウザだけでAIキャラクターとの会話を楽しめます。キャラクターの変更や性格設定、音声調整は各設定項目を確認してください。",
  "TechnologyIntroduction": "技術紹介",
  "TechnologyIntroductionDescription1": "このアプリはpixiv社の<b>ChatVRM</b>を改造して作成されています。元のソースコードは",
  "TechnologyIntroductionLink1": "こちら",
  "TechnologyIntroductionDescription2": "をご覧ください。",
  "TechnologyIntroductionDescription3": "3Dモデルの表示や操作には",
  "TechnologyIntroductionDescription4": "、 会話文生成には",
  "TechnologyIntroductionDescription5": "などの各種LLM、 音声合成には",
  "TechnologyIntroductionDescription6": "などの各種TTSを使用しています。 詳細はこちらの",
  "TechnologyIntroductionLink2": "解説記事",
  "TechnologyIntroductionDescription7": "をご覧ください。",
  "SourceCodeDescription1": "このアプリのソースコードはGitHubで公開しています。自由に変更や改変可能です。",
  "SourceCodeDescription2": "商用利用に関しては、同リポジトリのREADMEをご覧ください。",
  "RepositoryURL": "リポジトリURL:",
  "DontShowIntroductionNextTime": "次回からこのダイアログを表示しない",
  "Close": "閉じる",
  "Contact": "お問い合わせ",
  "ContactDescription": "このアプリに関するお問い合わせは下記のメールアドレスまたはTwitterアカウントにお願いします。",
  "Creator": "作成者情報",
  "CreatorDescription": "作成者: ニケ",
  "Documentation": "ドキュメント",
  "DocumentationDescription": "AITuberKitの詳細な使い方やチュートリアルは下記のURLからご覧ください。",
  "Language": "言語設定",
  "UsingGSVITTS": "GSVI TTSを使用する",
  "GSVITTSInfo": "GSVI TTS設定",
  "GSVITTSServerUrl": "GSVI TTSサーバーのURL",
  "GSVITTSModelID": "GSVI TTS モデルID",
  "GSVITTSBatchSize": "GSVI TTS バッチサイズ (1 ~ 100 数値が大きいほど推論速度は速くなりますが、大きすぎるとメモリを使い果たす可能性があります)",
  "GSVITTSSpeechRate": "話速 (0.5 ~ 2.0 数値が大きいほど速い)",
  "UsingElevenLabs": "ElevenLabsを使用する",
  "ElevenLabsInfo": "ElevenLabs APIを使用しています。多言語に対応可能です。APIキーを下記のURLから取得してください。",
  "ElevenLabsApiKey": "ElevenLabs APIキー",
  "ElevenLabsVoiceId": "ElevenLabs ボイスID",
  "ElevenLabsVoiceIdInfo": "ボイスIDは下記のURLから選択してください。",
  "CharacterName": "キャラクター名",
  "ShowAssistantText": "回答欄を表示する",
  "ShowCharacterName": "回答欄にキャラクター名を表示する",
  "ShowControlPanel": "操作パネルを表示する",
  "ShowControlPanelInfo": "設定画面は Cmd + . (Mac) / Ctrl + . (Windows) で表示することができます。\nスマートフォンをご利用の場合は、画面左上を長押し（約1秒）でも可能です。",
  "ShowCharacterPresetMenu": "キャラクタープリセットメニューボタンを表示する",
  "SlideMode": "スライドモード",
  "SelectedSlideDocs": "使用するスライド",
  "EditSlideScripts": "セリフ編集",
  "PleaseSelectSlide": "スライドを選択してください",
  "SlideModeDescription": "AIが自動でスライドを発表するモードです。選択しているAIサービスがOpenAI, Anthropic Claude, Google Geminiの場合のみ有効です。",
  "PdfConvertLabel": "PDFスライド変換",
  "PdfConvertDescription": "PDFをスライドモード用のデータに変換します。選択しているAIサービスがOpenAI, Anthropic Claude, Google Geminiの場合のみ利用可能です。",
  "PdfConvertFileUpload": "PDFファイルを選択",
  "PdfConvertFolderName": "保存フォルダ名",
  "CustomVoiceTextPlaceholder": "試聴したいテキストを入力してください",
  "TestVoiceSettings": "ボイステスト",
  "TestSelectedVoice": "再生する",
  "PdfConvertModelSelect": "モデルを選択",
  "PdfConvertButton": "PDFをスライドに変換",
  "PdfConvertLoading": "変換中...",
  "PdfConvertSuccess": "変換が完了しました",
  "PdfConvertError": "変換に失敗しました",
  "PdfConvertSubmitError": "PDFファイル、フォルダ名、APIキーが設定されているか確認をしてください",
  "LocalStorageReset": "設定をリセットする",
  "LocalStorageResetInfo": "環境変数が設定されている場合はその値が優先されます。ページが再読み込みされます。",
  "LocalStorageResetButton": "設定リセット",
  "InitialSpeechTimeout": "音声認識タイムアウト",
  "InitialSpeechTimeoutInfo": "音声認識開始後、最初の発話が検出されるまでの待機時間を設定します。この時間内に発話が検出されない場合、音声認識は自動的に停止します。\n0秒に設定すると、待機時間は無制限になります。",
  "Milliseconds": "ミリ秒",
  "NoSpeechTimeout": "無音検出タイムアウト",
  "NoSpeechTimeoutInfo": "音声入力時に無音状態が続いた場合、自動的に入力を終了するまでの時間を設定します。\n0秒に設定すると、無音検出による自動送信を無効にします。",
  "ShowSilenceProgressBar": "無音検出プログレスバーを表示",
  "SpeechRecognitionMode": "音声認識モード",
  "SpeechRecognitionModeInfo": "音声認識モードを選択できます。\n「ブラウザ標準」はブラウザ内蔵の音声認識を使用します。「OpenAI TTS」はOpenAIのText to Speech APIを使用します。\n一般的には「ブラウザ標準」の方が精度が高く、認識速度も速いため推奨されます。ただし、FirefoxなどWebSpeech APIに対応していないブラウザを使用している場合は、「OpenAI TTS」を選択してください。",
  "BrowserSpeechRecognition": "ブラウザ標準の音声認識を使用",
  "WhisperSpeechRecognition": "OpenAI TTS音声認識を使用",
  "WhisperTranscriptionModel": "文字起こしモデル",
  "WhisperTranscriptionModelInfo": "音声認識に使用するモデルを選択できます。より高性能なモデルほど高精度で認識可能ですが、APIコストが高くなる場合があります。",
  "SpeechRecognitionModeDisabledInfo": "オーディオモードが有効な場合、ブラウザ音声認識のみが使用可能です。\nまた、リアルタイムAPIモードではブラウザ音声認識のみが使用可能な上、音声認識タイムアウト機能が無効になります。",
  "Errors": {
    "EmptyAPIKey": "APIキーが設定されていません",
    "EmptyLocalLLMURL": "ローカルLLMのURLが設定されていません",
    "AIInvalidProperty": "AIサービスの設定値が正しくありません",
    "AIAPIError": "AI API実行時にエラーが発生しました",
    "InvalidAIService": "選択しているAIサービスが正しくありません",
    "MethodNotAllowed": "リクエストが適切でありません",
    "TTSServiceError": "{{serviceName}} TTSサービスでエラーが発生しました: {{message}}",
    "UnexpectedError": "不明なエラーが発生しました",
    "LocalLLMError": "ローカルLLMでエラーが発生しました",
    "LocalLLMStreamError": "ローカルLLMのストリーム処理でエラーが発生しました",
    "LocalLLMConnectionError": "ローカルLLMサーバーに接続できません",
    "LocalLLMNotFound": "ローカルLLMのエンドポイントが見つかりません",
    "LocalLLMAPIError": "ローカルLLM APIでエラーが発生しました",
    "CustomAPIError": "カスタムAPIでエラーが発生しました",
    "InvalidJSON": "JSON形式が正しくありません"
  },
  "MessageReceiver": "外部からの指示を受け付ける",
  "MessageReceiverDescription": "APIを利用してAIキャラの発言を外部から指示することができます。",
  "ClientID": "Client ID",
  "OpenSendMessagePage": "メッセージ送信ページを開く",
  "RealtimeAPIMode": "リアルタイムAPIモード",
  "RealtimeAPIModeContentType": "送信タイプ",
  "RealtimeAPIModeVoice": "ボイスタイプ",
  "AudioMode": "オーディオモード",
  "InputText": "テキスト",
  "InputAudio": "音声",
  "SearchGrounding": "検索機能を利用する",
  "SearchGroundingDescription": "マルチモーダル機能利用時は、検索機能は自動的に無効になります。",
  "DynamicRetrieval": "動的検索",
  "DynamicRetrievalDescription": "モデルが検索を実行するタイミングしきい値を設定します。0の場合は常に検索を実行し、1の場合は検索を実行しません。",
  "DynamicRetrievalThreshold": "動的しきい値",
  "UpdateRealtimeAPISettings": "リアルタイムAPI設定を更新",
  "UpdateRealtimeAPISettingsInfo": "APIキー、Azure Endpoint、ボイスタイプ、モデル、システムプロンプトを更新した際は更新ボタンを押して、新しいWebSocketセッションを開始してください。",
  "AzureEndpoint": "Azure Endpoint",
  "Toasts": {
    "WebSocketConnectionError": "WebSocket接続にエラーが発生しました",
    "WebSocketConnectionClosed": "WebSocket接続が閉じられました",
    "WebSocketConnectionAttempt": "WebSocket接続を試みています...",
    "WebSocketConnectionSuccess": "WebSocket接続に成功しました",
    "FunctionExecuting": "{{funcName}}を実行しています",
    "FunctionExecutionFailed": "{{funcName}}の実行に失敗しました",
    "FirefoxNotSupported": "Firefoxではこの機能はサポートされていません",
    "SpeechRecognitionError": "音声認識エラーが発生しました",
    "NoSpeechDetected": "音声が検出されませんでした。",
    "PresetSwitching": "{{presetName}}に切り替わりました。",
    "WhisperError": "Whisperによる音声認識でエラーが発生しました",
    "UsingTool": "{{toolName}}を使用中"
  },
  "ContinuousMic": "常時マイク入力",
  "ContinuousMicActive": "常時マイク入力中",
  "ContinuousMicModeOn": "常時マイク入力モードがオンです",
  "ContinuousMicModeOff": "常時マイク入力モードがオフです",
  "ListeningContinuously": "音声入力を待機中...",
  "ContinuousMicInfo": "AIの発話が終了したタイミングで自動的にマイク入力を再開します。設定された無音時間経過後に自動的に送信します。\n音声認識がされないまま設定時間を超えると、自動的に常時マイク入力はOFFになるため、常にONにしておきたい場合は音声認識タイムアウトを0秒に設定してください。",
  "UsingOpenAITTS": "OpenAIを使用する",
  "OpenAITTSInfo": "OpenAIを使用しています。多言語に対応可能です。AIサービスでOpenAIを選択している場合は下記のAPIキーを設定する必要はありません。",
  "OpenAITTSVoice": "ボイスタイプ",
  "OpenAITTSModel": "モデル",
  "OpenAITTSSpeed": "話速",
  "UsingAzureTTS": "Azure OpenAIを使用する",
  "AzureTTSInfo": "Azure OpenAIを使用しています。多言語に対応可能です。",
  "SendMessage": {
    "title": "AITuberKit 外部アダプター",
    "directSendTitle": "AIキャラにそのまま発言させる",
    "directSendDescription": "送信したメッセージをそのままAIキャラに発言させることができます。複数送信した場合は順番に処理されます。\n音声モデルはAITuberKitの設定で選択したものが使用されます。",
    "aiGenerateTitle": "AIで回答を生成してから発言させる",
    "aiGenerateDescription": "送信したメッセージからAIが回答を生成し、その回答をAIキャラに発言させます。複数送信した場合は順番に処理されます。\nAIモデルおよび音声モデルはAITuberKitの設定で選択したものが使用されます。\nシステムプロンプトはAITuberKitのシステムプロンプトを使用するか、カスタムのシステムプロンプトを使用するかを選択できます。\n過去の会話履歴を読み込ませる場合は、システムプロンプト または ユーザーメッセージの任意の位置に [conversation_history] という文字列を含めてください。",
    "useCurrentSystemPrompt": "AITuberKitのシステムプロンプトを利用する",
    "userInputTitle": "ユーザー入力を送信する",
    "userInputDescription": "送信したメッセージはAITuberKitの入力フォームから入力された場合と同じ処理がされます。複数送信した場合は順番に処理されます。\nAIモデルおよび音声モデルはAITuberKitの設定で選択したものが使用されます。\nシステムプロンプトや会話履歴はAITuberKitの値が使用されます。"
  },
  "CannotUseVoice": "リアルタイムAPIモード または オーディオモードが有効の場合、\n合成音声設定は不要です。",
  "Live2D": {
    "FileInfo": "使用したいLive2Dモデルのフォルダを、public/live2d に配置してください。このフォルダの直下にmodel3.jsonファイルが存在する必要があります。\n選択肢に表示されない場合は、画面を再読込するかフォルダのパスが正しいか確認してください。",
    "Info": "感情とモーションを指定できます。\n各感情はプロンプトで制御しています。詳しくは「AI設定 => キャラクター設定」をご覧ください。",
    "Emotions": "表情設定",
    "EmotionInfo": "感情はカンマ区切りで複数指定できます。複数指定した場合はランダムに選択されます。\n初期値はAITuberKitで用意しているモデルに対応したものです。オリジナルのモデルを使用する場合はご自身のモデルに合わせた値を入力してください。\n会話完了後は「通常」の表情が表示されます。",
    "neutralEmotions": "通常",
    "happyEmotions": "嬉しい",
    "sadEmotions": "悲しい",
    "angryEmotions": "怒り",
    "relaxedEmotions": "リラックス",
    "surprisedEmotions": "驚き",
    "MotionGroups": "モーショングループ設定",
    "MotionGroupsInfo": "モーショングループは選択したグループからランダムに選択されます。\n表情設定と同じく、ご自身のモデルに合わせて設定してください。\n「アイドル時」は会話完了後に表示されるモーションです。",
    "SelectMotionGroup": "モーショングループを選択",
    "idleMotionGroup": "アイドル時",
    "neutralMotionGroup": "通常",
    "happyMotionGroup": "嬉しい",
    "sadMotionGroup": "悲しい",
    "angryMotionGroup": "怒り",
    "relaxedMotionGroup": "リラックス",
    "surprisedMotionGroup": "驚き"
  },
  "UseVideoAsBackground": "共有画面またはWebカメラを背景として使用する",
  "Temperature": "Temperature",
  "MaxTokens": "最大トークン数",
  "MaxTokensInfo": "最大トークン数は利用中のAIモデルによって異なります。各モデルの仕様を確認してください。",
  "CannotUseParameters": "リアルタイムAPIモードまたはオーディオモードが有効の場合、TemperatureとMax Tokensパラメータは指定できません。",
  "PresetQuestions": "質問の事前設定",
  "PresetQuestionsInfo": "複数の質問パターンを事前に作成・登録できます。登録された質問はユーザーUI上にボタン形式で表示され、クリックするとチャット入力欄にセットされます。",
  "EnterPresetQuestion": "質問を入力してください",
  "DragToReorder": "ドラッグして順番を変更",
  "CustomAPIEndpoint": "カスタムAPIエンドポイント",
  "CustomAPIEndpointInfo": "POSTリクエストを送信するAPIエンドポイントのURLを入力してください。",
  "CustomAPIStream": "ストリーミングモード",
  "CustomAPIStreamForced": "現在、ストリーミングモードは常に有効になっています。",
  "IncludeSystemMessages": "システムメッセージを含める",
  "CustomAPIHeaders": "カスタムヘッダー",
  "CustomAPIHeadersInfo": "APIリクエストに含めるヘッダー情報をJSON形式で入力してください。",
  "CustomAPIBody": "カスタムボディ",
  "CustomAPIBodyInfo": "APIリクエストに含めるボディ情報をJSON形式で入力してください。messagesは自動的に含まれます。",
  "CustomAPIDescription": "注意: メッセージは自動的にリクエストボディに含まれます。ストリーミングモードでは、サーバーがtext/event-streamを返す必要があります。",
  "XAIAPIKeyLabel": "xAI APIキー",
  "OpenRouterAPIKeyLabel": "OpenRouter APIキー",
  "OpenRouterModelNameInstruction": "OpenRouterからモデル識別子を入力してください（例： \"openai/gpt-4o\", \"mistralai/mistral-large-latest\"）。モデル識別子はOpenRouterモデルページで確認できます。"
}
