{
  "Description": "Über die App",
  "BasedSettings": "Grundeinstellungen",
  "AISettings": "KI-Einstellungen",
  "CharacterSettings": "Charaktereinstellungen",
  "YoutubeSettings": "YouTube-Einstellungen",
  "VoiceSettings": "Sprachsynthese-Einstellungen",
  "SpeechInputSettings": "Spracheingabe-Einstellungen",
  "SlideSettings": "Präsentationseinstellungen",
  "LogSettings": "Gesprächsverlauf",
  "OtherSettings": "Sonstiges",
  "ExternalLinkageMode": "Externe Verbindungsmodus (Beta)",
  "YoutubeMode": "YouTube-Modus",
  "YoutubeInfo": "Kommentare, die mit \"#\" beginnen, werden ignoriert.",
  "YoutubeAPIKey": "YouTube API-Schlüssel",
  "YoutubeLiveID": "YouTube Live-ID",
  "ConversationContinuityMode": "Gesprächskontinuitätsmodus (Beta)",
  "ConversationContinuityModeInfo": "Dies ist ein Modus, in dem die KI versucht, das Gespräch fortzusetzen, wenn keine Kommentare vorhanden sind. Er ist nur aktiv, wenn ein multimodales Modell ausgewählt ist.",
  "ConversationContinuityModeInfo2": "Da bei einer Antwort mehrere LLM-Aufrufe erfolgen, können sich die API-Nutzungsgebühren erhöhen. Bitte beachten Sie dies.",
  "ConversationContinuityModeInfo3": "Je nach ausgewähltem Modell kann es vorkommen, dass es nicht stabil funktioniert.",
  "MaxPastMessages": "Anzahl der gespeicherten vorherigen Nachrichten",
  "StatusOn": "Status: AN",
  "StatusOff": "Status: AUS",
  "Select": "Bitte auswählen",
  "TestVoice": "Stimme testen",
  "SelectAIService": "KI-Dienst auswählen",
  "LocalLLM": "Lokales LLM",
  "SelectModel": "Modell auswählen",
  "OpenAIAPIKeyLabel": "OpenAI API-Schlüssel",
  "AnthropicAPIKeyLabel": "Anthropic API-Schlüssel",
  "GoogleAPIKeyLabel": "Google Gemini API-Schlüssel",
  "AzureAPIKeyLabel": "Azure OpenAI API-Schlüssel",
  "AzureAPIURL": "Azure OpenAI API URL",
  "GroqAPIKeyLabel": "Groq API-Schlüssel",
  "CohereAPIKeyLabel": "Cohere API-Schlüssel",
  "MistralAIAPIKeyLabel": "MistralAI API-Schlüssel",
  "PerplexityAPIKeyLabel": "Perplexity API-Schlüssel",
  "FireworksAPIKeyLabel": "Fireworks API-Schlüssel",
  "DifyAPIKeyLabel": "Dify API-Schlüssel",
  "DeepSeekAPIKeyLabel": "DeepSeek API-Schlüssel",
  "APIKeyInstruction": "API-Schlüssel können über den folgenden Link bezogen werden. Bitte geben Sie den erhaltenen API-Schlüssel in das Formular ein.",
  "LocalLLMInfo": "Ein lokaler LLM-Server muss gestartet sein.",
  "LocalLLMInfo2": "Bitte geben Sie die URL des lokalen LLM (mit Portnummer) und den Modellnamen ein.",
  "GroqInfo": "Die Groq API wird direkt vom Browser aus aufgerufen.",
  "DifyInfo": "Dify unterstützt nur Chatbot- oder Agententypen. Wenn Sie keine zufriedenstellende Antwort erhalten, löschen Sie den Gesprächsverlauf und stellen Sie die Frage erneut.",
  "DifyInfo2": "Die Länge des Gesprächsverlaufs hängt von den Einstellungen des Dify-Chatbots ab.",
  "DifyInfo3": "Beispiel: https://api.dify.ai/v1, http://localhost:80/v1",
  "DifyInstruction": "Bei Verwendung von Dify wird dieser Systemprompt nicht verwendet. Bitte konfigurieren Sie ihn im Dify-Chatbot.",
  "EnterURL": "URL eingeben",
  "CharacterModelLabel": "Charaktermodell",
  "CharacterModelInfo": "Bei einigen Modellen kann das initiale Laden längere Zeit in Anspruch nehmen.",
  "OpenVRM": "VRM öffnen",
  "BackgroundImage": "Hintergrundbild",
  "ChangeBackgroundImage": "Hintergrundbild ändern",
  "BackgroundSettings": "Hintergrundeinstellungen",
  "BackgroundSettingsDescription": "Sie können ein Hintergrundbild für die Anwendung hochladen und auswählen.",
  "UploadBackground": "Hintergrundbild hochladen",
  "DefaultBackground": "Standard-Hintergrund",
  "CharacterSettingsPrompt": "Charakterprompt",
  "CharacterSettingsInfo": "Dieser Wert wird als Systemprompt festgelegt.\nBasierend auf dem initialen Prompt können Sie Gefühlstags angeben, um die Ausdrücke und Bewegungen des Charakters zu steuern. Beispiel: [neutral]Guten Morgen![happy]Schön, Sie zu sehen!",
  "CharacterpresetInfo": "Durch Auswahl einer Voreinstellung wird der Charakterprompt geändert.\nKurzbefehle sind möglich mit Cmd + Shift + 1-5 (Mac) / Ctrl + Shift + 1-5 (Windows).",
  "Characterpreset1": "Voreinstellung 1",
  "Characterpreset2": "Voreinstellung 2",
  "Characterpreset3": "Voreinstellung 3",
  "Characterpreset4": "Voreinstellung 4",
  "Characterpreset5": "Voreinstellung 5",
  "SyntheticVoiceEngineChoice": "Sprachsynthese-Engine auswählen",
  "VoiceAdjustment": "Stimmanpassung",
  "VoiceEngineInstruction": "Bitte wählen Sie die zu verwendende Sprachsynthese-Engine aus.",
  "UsingKoeiromap": "Koeiromap verwenden",
  "KoeiromapInfo": "Verwendet die Koeiromap API von Koemotion. Unterstützt nur Japanisch. Für weitere Informationen siehe unten.",
  "UsingVoiceVox": "VOICEVOX verwenden",
  "VoiceVoxInfo": "Verwendet VOICEVOX. Unterstützt nur Japanisch. Da eine lokale API verwendet wird, müssen Sie die passende Anwendung von der folgenden Website herunterladen und starten.",
  "VoicevoxSpeed": "Sprechgeschwindigkeit",
  "VoicevoxPitch": "Tonhöhe",
  "VoicevoxIntonation": "Intonation",
  "VoicevoxServerUrl": "VOICEVOX Server-URL",
  "UsingAivisSpeech": "AivisSpeech verwenden",
  "AivisSpeechInfo": "Verwendet AivisSpeech. Unterstützt nur Japanisch. Da eine lokale API verwendet wird, müssen Sie die passende Anwendung von der folgenden Website herunterladen und starten.",
  "AivisSpeechSpeaker": "Sprecher",
  "AivisSpeechSpeed": "Sprechgeschwindigkeit",
  "AivisSpeechPitch": "Tonhöhe",
  "AivisSpeechIntonation": "Intonation",
  "AivisSpeechServerUrl": "AivisSpeech Server-URL",
  "UsingNijiVoice": "NijiVoice verwenden",
  "NijiVoiceInfo": "Verwendet die NijiVoice API. Unterstützt nur Japanisch. Bitte beziehen Sie den API-Schlüssel von der folgenden URL.",
  "NijiVoiceApiKey": "NijiVoice API-Schlüssel",
  "NijiVoiceActorId": "Sprecher-ID",
  "NijiVoiceSpeed": "Sprechgeschwindigkeit",
  "NijiVoiceEmotionalLevel": "Emotionslevel",
  "NijiVoiceSoundDuration": "Sprachdauer",
  "UpdateSpeakerList": "Sprecherliste aktualisieren",
  "UsingGoogleTTS": "Google Text-to-Speech verwenden",
  "UsingStyleBertVITS2": "Style-Bert-VITS2 verwenden",
  "StyleBertVITS2Info": "Verwendet Style-Bert-VITS2. Unterstützt nur Japanisch, Englisch und Chinesisch. Bei Verwendung einer lokalen API müssen Sie die passende Anwendung von der folgenden Website herunterladen und starten. Bei Bedarf konfigurieren Sie bitte auch den API-Schlüssel.",
  "SpeakerSelection": "Stimmtyp auswählen",
  "EnglishToJapanese": "Englische Wörter auf Japanisch vorlesen",
  "IncludeTimestampInUserMessage": "Zeitstempel in Benutzernachrichten einbeziehen",
  "IncludeTimestampInUserMessageInfo": "Durch Einbeziehung eines Zeitstempels in Benutzernachrichten kann die KI die Zeit bei der Generierung von Antworten berücksichtigen.\nBitte fügen Sie den folgenden Satz in Ihren Systemprompt ein:\n\n\"Benutzeranfragen können mit einem [timestamp] versehen sein. Dieser gibt die UTC-Zeit zum Zeitpunkt der Anfrage an, bitte berücksichtigen Sie diese Zeit bei der Generierung Ihrer Antwort.\"",
  "GoogleTTSInfo": "Verwendet Google Cloud Text-to-Speech. Unterstützt mehrere Sprachen.",
  "AuthFileInstruction": "Ein API-Schlüssel oder eine JSON-Authentifizierungsdatei ist erforderlich. Beziehen Sie diese von unten und platzieren Sie die JSON-Datei als 'credentials.json' im Root-Verzeichnis des Repositories.",
  "LanguageModelURL": "Bitte wählen Sie das Sprachmodell über folgende URL aus.",
  "LanguageChoice": "Sprachauswahl",
  "StyleBeatVITS2ServerURL": "Server-URL",
  "StyleBeatVITS2ApiKey": "API-Schlüssel",
  "StyleBeatVITS2ModelID": "Modell-ID",
  "StyleBeatVITS2Style": "Stil",
  "StyleBeatVITS2SdpRatio": "SDP/DP-Mischverhältnis",
  "StyleBeatVITS2Length": "Sprechgeschwindigkeit",
  "ConversationHistory": "Gesprächsverlauf",
  "ConversationHistoryInfo": "Die letzten {{count}} Gesprächssätze werden als Gedächtnis gespeichert.",
  "ConversationHistoryReset": "Gesprächsverlauf zurücksetzen",
  "NotConnectedToExternalAssistant": "Nicht mit externem Assistenten verbunden.",
  "APIKeyNotEntered": "API-Schlüssel wurde nicht eingegeben.",
  "ChatLog": "Gesprächsprotokoll",
  "EnterYourQuestion": "Geben Sie Ihre Frage ein",
  "AnswerGenerating": "Antwort wird generiert",
  "AboutThisApplication": "Über diese Anwendung",
  "AboutThisApplicationDescription": "Genießen Sie Gespräche mit 3D-Charakteren nur mit einem Webbrowser, unter Verwendung von Mikrofon, Texteingabe und Sprachsynthese. Sie können den Charakter (VRM) ändern, Persönlichkeitseinstellungen vornehmen und die Stimme anpassen.<br />Einstellungen können über die Menütaste in der oberen linken Ecke geändert werden.",
  "AboutThisApplicationDescription2": "Mit AITuberKit können Sie Gespräche mit KI-Charakteren direkt in Ihrem Webbrowser genießen. Informationen zur Änderung des Charakters, Persönlichkeitseinstellungen und Stimmanpassung finden Sie in den jeweiligen Einstellungsbereichen.",
  "TechnologyIntroduction": "Technologievorstellung",
  "TechnologyIntroductionDescription1": "Diese App wurde durch Modifikation von pixiv's <b>ChatVRM</b> erstellt. Der ursprüngliche Quellcode ist",
  "TechnologyIntroductionLink1": "hier",
  "TechnologyIntroductionDescription2": "zu finden.",
  "TechnologyIntroductionDescription3": "Für die Anzeige und Steuerung von 3D-Modellen wird",
  "TechnologyIntroductionDescription4": "verwendet, für die Generierung von Gesprächstexten",
  "TechnologyIntroductionDescription5": "und andere LLMs, für die Sprachsynthese",
  "TechnologyIntroductionDescription6": "und andere TTS-Systeme. Weitere Details finden Sie in diesem",
  "TechnologyIntroductionLink2": "Erklärungsartikel",
  "TechnologyIntroductionDescription7": ".",
  "SourceCodeDescription1": "Der Quellcode dieser App ist auf GitHub verfügbar. Er kann frei geändert und modifiziert werden.",
  "SourceCodeDescription2": "Informationen zur kommerziellen Nutzung finden Sie in der README des Repositories.",
  "RepositoryURL": "Repository-URL:",
  "DontShowIntroductionNextTime": "Diesen Dialog beim nächsten Mal nicht anzeigen",
  "Close": "Schließen",
  "Contact": "Kontakt",
  "ContactDescription": "Für Anfragen zu dieser App kontaktieren Sie uns bitte unter folgender E-Mail-Adresse oder Twitter-Account.",
  "Creator": "Erstellerinformation",
  "CreatorDescription": "Ersteller: Nike",
  "Documentation": "Dokumentation",
  "DocumentationDescription": "Detaillierte Anleitungen und Tutorials für AITuberKit finden Sie unter folgender URL.",
  "Language": "Spracheinstellungen",
  "UsingGSVITTS": "GSVI TTS verwenden",
  "GSVITTSInfo": "GSVI TTS-Einstellungen",
  "GSVITTSServerUrl": "GSVI TTS-Server-URL",
  "GSVITTSModelID": "GSVI TTS-Modell-ID",
  "GSVITTSBatchSize": "GSVI TTS-Batchgröße (1 ~ 100, höhere Werte beschleunigen die Inferenz, können aber bei zu großen Werten den Speicher erschöpfen)",
  "GSVITTSSpeechRate": "Sprechgeschwindigkeit (0.5 ~ 2.0, höhere Werte sind schneller)",
  "UsingElevenLabs": "ElevenLabs verwenden",
  "ElevenLabsInfo": "Verwendet die ElevenLabs API. Unterstützt mehrere Sprachen. Bitte beziehen Sie den API-Schlüssel von der folgenden URL.",
  "ElevenLabsApiKey": "ElevenLabs API-Schlüssel",
  "ElevenLabsVoiceId": "ElevenLabs Voice-ID",
  "ElevenLabsVoiceIdInfo": "Bitte wählen Sie die Voice-ID von der folgenden URL aus.",
  "CharacterName": "Charaktername",
  "ShowAssistantText": "Antwortbereich anzeigen",
  "ShowCharacterName": "Charakternamen im Antwortbereich anzeigen",
  "ShowControlPanel": "Steuerungsleiste anzeigen",
  "ShowControlPanelInfo": "Der Einstellungsbildschirm kann mit Cmd + . (Mac) / Ctrl + . (Windows) angezeigt werden.\nBei Smartphone-Nutzung können Sie auch den oberen linken Bildschirmbereich lange drücken (ca. 1 Sekunde).",
  "ShowCharacterPresetMenu": "Charaktervoreinstellungsmenüschaltfläche anzeigen",
  "SlideMode": "Präsentationsmodus",
  "SelectedSlideDocs": "Verwendete Präsentation",
  "SlideModeDescription": "Dies ist ein Modus, in dem die KI die Folien automatisch präsentiert. Er ist nur aktiviert, wenn ein multimodales Modell ausgewählt ist.",
  "PdfConvertLabel": "PDF-Folienkonvertierung",
  "PdfConvertDescription": "PDF wird in Daten für den Folienmodus konvertiert. Nur verfügbar, wenn ein multimodales Modell ausgewählt ist.",
  "PdfConvertFileUpload": "PDF-Datei auswählen",
  "PdfConvertFolderName": "Speicherordnername",
  "CustomVoiceTextPlaceholder": "Geben Sie Text zum Testen ein",
  "TestVoiceSettings": "Stimmtest",
  "TestSelectedVoice": "Abspielen",
  "PdfConvertModelSelect": "Modell auswählen",
  "PdfConvertButton": "PDF in Präsentation konvertieren",
  "PdfConvertLoading": "Konvertierung läuft...",
  "PdfConvertSuccess": "Konvertierung abgeschlossen",
  "PdfConvertError": "Konvertierung fehlgeschlagen",
  "PdfConvertSubmitError": "Bitte überprüfen Sie, ob PDF-Datei, Ordnername und API-Schlüssel konfiguriert sind",
  "LocalStorageReset": "Einstellungen zurücksetzen",
  "LocalStorageResetInfo": "Bei konfigurierten Umgebungsvariablen haben diese Vorrang. Die Seite wird neu geladen.",
  "LocalStorageResetButton": "Einstellungen zurücksetzen",
  "InitialSpeechTimeout": "Spracherkennungs-Timeout",
  "InitialSpeechTimeoutInfo": "Legt fest, wie lange nach dem Start der Spracherkennung auf die erste Sprachaufnahme gewartet wird. Wird in dieser Zeit keine Sprache erkannt, stoppt die Spracherkennung automatisch.\nBei Einstellung auf 0 Sekunden ist die Wartezeit unbegrenzt.",
  "Milliseconds": "Millisekunden",
  "NoSpeechTimeout": "Stilleerkennung-Timeout",
  "NoSpeechTimeoutInfo": "Legt fest, nach welcher Zeit ohne Spracheingabe die Eingabe automatisch beendet wird.\nBei Einstellung auf 0 Sekunden wird das automatische Senden bei Stille deaktiviert.",
  "ShowSilenceProgressBar": "Fortschrittsbalken für Stilleerkennung anzeigen",
  "SpeechRecognitionMode": "Spracherkennungsmodus",
  "SpeechRecognitionModeInfo": "Wählen Sie den Spracherkennungsmodus aus.\n\"Browser-Standard\" verwendet die integrierte Spracherkennung des Browsers. \"OpenAI TTS\" verwendet die Text-to-Speech-API von OpenAI.\nIn der Regel wird \"Browser-Standard\" empfohlen, da er genauer und schneller ist. Bei Verwendung von Browsern wie Firefox, die die WebSpeech-API nicht unterstützen, wählen Sie bitte \"OpenAI TTS\".",
  "BrowserSpeechRecognition": "Browser-Standardspracherkennung verwenden",
  "WhisperSpeechRecognition": "OpenAI TTS-Spracherkennung verwenden",
  "WhisperTranscriptionModel": "Transkriptionsmodell",
  "WhisperTranscriptionModelInfo": "Wählen Sie das für die Spracherkennung zu verwendende Modell aus. Leistungsfähigere Modelle bieten höhere Genauigkeit, können aber höhere API-Kosten verursachen.",
  "SpeechRecognitionModeDisabledInfo": "Im Audiomodus ist nur die Browser-Spracherkennung verfügbar.\nIm Echtzeit-API-Modus ist ebenfalls nur die Browser-Spracherkennung verfügbar, und die Spracherkennungs-Timeout-Funktion ist deaktiviert.",
  "Errors": {
    "EmptyAPIKey": "API-Schlüssel ist nicht konfiguriert",
    "EmptyLocalLLMURL": "URL des lokalen LLM ist nicht konfiguriert",
    "AIInvalidProperty": "Ungültiger KI-Dienstkonfigurationswert",
    "AIAPIError": "Fehler bei der Ausführung der KI-API",
    "InvalidAIService": "Der ausgewählte KI-Dienst ist ungültig",
    "MethodNotAllowed": "Anfrage ist nicht angemessen",
    "TTSServiceError": "Fehler im {{serviceName}} TTS-Dienst: {{message}}",
    "UnexpectedError": "Ein unerwarteter Fehler ist aufgetreten",
    "LocalLLMError": "Fehler im lokalen LLM",
    "LocalLLMStreamError": "Fehler bei der Stream-Verarbeitung des lokalen LLM",
    "LocalLLMConnectionError": "Verbindung zum lokalen LLM-Server nicht möglich",
    "LocalLLMNotFound": "Endpunkt des lokalen LLM nicht gefunden",
    "LocalLLMAPIError": "Fehler in der lokalen LLM-API",
    "CustomAPIError": "Fehler in der benutzerdefinierten API",
    "InvalidJSON": "Ungültiges JSON-Format"
  },
  "MessageReceiver": "Externe Anweisungen akzeptieren",
  "MessageReceiverDescription": "Ermöglicht es, die Aussagen des KI-Charakters über eine API extern zu steuern.",
  "ClientID": "Client-ID",
  "OpenSendMessagePage": "Nachrichtenseite öffnen",
  "RealtimeAPIMode": "Echtzeit-API-Modus",
  "RealtimeAPIModeContentType": "Sendetyp",
  "RealtimeAPIModeVoice": "Stimmtyp",
  "AudioMode": "Audiomodus",
  "InputText": "Text",
  "InputAudio": "Audio",
  "SearchGrounding": "Suchfunktion verwenden",
  "SearchGroundingDescription": "Bei Verwendung der Multimodal-Funktion wird die Suchfunktion automatisch deaktiviert.",
  "UpdateRealtimeAPISettings": "Echtzeit-API-Einstellungen aktualisieren",
  "UpdateRealtimeAPISettingsInfo": "Drücken Sie die Aktualisierungstaste, um eine neue WebSocket-Sitzung zu starten, wenn Sie den API-Schlüssel, Azure-Endpunkt, Stimmtyp, Modell oder Systemprompt aktualisiert haben.",
  "AzureEndpoint": "Azure-Endpunkt",
  "Toasts": {
    "WebSocketConnectionError": "Bei der WebSocket-Verbindung ist ein Fehler aufgetreten",
    "WebSocketConnectionClosed": "WebSocket-Verbindung wurde geschlossen",
    "WebSocketConnectionAttempt": "Versuche, eine WebSocket-Verbindung herzustellen...",
    "WebSocketConnectionSuccess": "WebSocket-Verbindung erfolgreich hergestellt",
    "FunctionExecuting": "{{funcName}} wird ausgeführt",
    "FunctionExecutionFailed": "Fehler bei der Ausführung von {{funcName}}",
    "FirefoxNotSupported": "Diese Funktion wird in Firefox nicht unterstützt",
    "SpeechRecognitionError": "Ein Fehler bei der Spracherkennung ist aufgetreten",
    "NoSpeechDetected": "Keine Sprache erkannt.",
    "PresetSwitching": "Zu {{presetName}} gewechselt.",
    "WhisperError": "Bei der Spracherkennung mit Whisper ist ein Fehler aufgetreten",
    "UsingTool": "{{toolName}} wird verwendet",
    "PositionFixed": "Die Position des Charakters wurde fixiert",
    "PositionUnfixed": "Die Fixierung der Charakterposition wurde aufgehoben",
    "PositionReset": "Die Position des Charakters wurde zurückgesetzt",
    "PositionActionFailed": "Positionsoperation fehlgeschlagen",
    "MicrophonePermissionDenied": "Der Zugriff auf das Mikrofon wurde verweigert"
  },
  "ContinuousMic": "Dauerhafte Mikrofonaufnahme",
  "ContinuousMicActive": "Dauerhafte Mikrofonaufnahme aktiv",
  "ContinuousMicModeOn": "Dauerhafte Mikrofonaufnahme-Modus ist EIN",
  "ContinuousMicModeOff": "Dauerhafte Mikrofonaufnahme-Modus ist AUS",
  "ListeningContinuously": "Warte auf Spracheingabe...",
  "ContinuousMicInfo": "Die Mikrofonaufnahme wird automatisch nach Beendigung der KI-Sprachausgabe neu gestartet. Nach Ablauf der konfigurierten Stillezeit wird die Aufnahme automatisch gesendet.\nWenn keine Spracherkennung innerhalb der konfigurierten Zeit erfolgt, wird die dauerhafte Mikrofonaufnahme automatisch deaktiviert. Wenn Sie sie immer aktiv halten möchten, setzen Sie das Spracherkennungs-Timeout auf 0 Sekunden.",
  "UsingOpenAITTS": "OpenAI verwenden",
  "OpenAITTSInfo": "Verwendet OpenAI. Unterstützt mehrere Sprachen. Wenn Sie OpenAI als KI-Dienst ausgewählt haben, müssen Sie den API-Schlüssel unten nicht konfigurieren.",
  "OpenAITTSVoice": "Stimmtyp",
  "OpenAITTSModel": "Modell",
  "OpenAITTSSpeed": "Sprechgeschwindigkeit",
  "UsingAzureTTS": "Azure OpenAI verwenden",
  "AzureTTSInfo": "Verwendet Azure OpenAI. Unterstützt mehrere Sprachen.",
  "SendMessage": {
    "title": "AITuberKit Externer Adapter",
    "directSendTitle": "KI-Charakter direkt sprechen lassen",
    "directSendDescription": "Die gesendete Nachricht wird direkt vom KI-Charakter gesprochen. Bei mehreren Nachrichten werden diese der Reihe nach verarbeitet.\nEs wird das in den AITuberKit-Einstellungen ausgewählte Sprachmodell verwendet.",
    "aiGenerateTitle": "KI-generierte Antwort sprechen lassen",
    "aiGenerateDescription": "Die KI generiert eine Antwort auf die gesendete Nachricht und lässt den KI-Charakter diese sprechen. Bei mehreren Nachrichten werden diese der Reihe nach verarbeitet.\nEs werden das KI-Modell und das Sprachmodell aus den AITuberKit-Einstellungen verwendet.\nSie können entweder den Systemprompt von AITuberKit verwenden oder einen benutzerdefinierten Systemprompt angeben.\nUm den vorherigen Gesprächsverlauf zu laden, fügen Sie an einer beliebigen Stelle im Systemprompt oder in der Benutzernachricht die Zeichenfolge [conversation_history] ein.",
    "useCurrentSystemPrompt": "AITuberKit-Systemprompt verwenden",
    "userInputTitle": "Benutzereingabe senden",
    "userInputDescription": "Die gesendete Nachricht wird wie eine über das AITuberKit-Eingabeformular eingegebene Nachricht behandelt. Bei mehreren Nachrichten werden diese der Reihe nach verarbeitet.\nEs werden das KI-Modell und das Sprachmodell aus den AITuberKit-Einstellungen verwendet.\nSystemprompt und Gesprächsverlauf aus AITuberKit werden verwendet."
  },
  "CannotUseVoice": "Bei aktiviertem Echtzeit-API-Modus oder Audiomodus\nsind Sprachsynthese-Einstellungen nicht erforderlich.",
  "Live2D": {
    "FileInfo": "Platzieren Sie den Ordner mit Ihrem gewünschten Live2D-Modell im Verzeichnis public/live2d. In diesem Ordner muss sich direkt eine model3.json-Datei befinden.\nWenn die Auswahlmöglichkeit nicht angezeigt wird, laden Sie den Bildschirm neu oder überprüfen Sie, ob der Pfad korrekt ist.",
    "Info": "Sie können Emotionen und Bewegungen festlegen.\nJede Emotion wird über den Prompt gesteuert. Weitere Details finden Sie unter \"KI-Einstellungen => Charaktereinstellungen\".",
    "Emotions": "Ausdruckseinstellungen",
    "EmotionInfo": "Emotionen können durch Kommas getrennt mehrfach angegeben werden. Bei mehreren Angaben wird zufällig ausgewählt.\nDie Standardwerte sind für die von AITuberKit bereitgestellten Modelle optimiert. Bei eigenen Modellen passen Sie die Werte bitte entsprechend an.\nNach Abschluss des Gesprächs wird der \"normale\" Ausdruck angezeigt.",
    "neutralEmotions": "Normal",
    "happyEmotions": "Fröhlich",
    "sadEmotions": "Traurig",
    "angryEmotions": "Wütend",
    "relaxedEmotions": "Entspannt",
    "surprisedEmotions": "Überrascht",
    "MotionGroups": "Bewegungsgruppen-Einstellungen",
    "MotionGroupsInfo": "Bewegungen werden zufällig aus der gewählten Gruppe ausgewählt.\nPassen Sie diese wie bei den Ausdruckseinstellungen an Ihr eigenes Modell an.\n\"Im Leerlauf\" ist die Bewegung, die nach Abschluss des Gesprächs angezeigt wird.",
    "SelectMotionGroup": "Bewegungsgruppe auswählen",
    "idleMotionGroup": "Im Leerlauf",
    "neutralMotionGroup": "Normal",
    "happyMotionGroup": "Fröhlich",
    "sadMotionGroup": "Traurig",
    "angryMotionGroup": "Wütend",
    "relaxedMotionGroup": "Entspannt",
    "surprisedMotionGroup": "Überrascht"
  },
  "UseVideoAsBackground": "Geteilten Bildschirm oder Webcam als Hintergrund verwenden",
  "Temperature": "Temperature",
  "MaxTokens": "Maximale Token-Anzahl",
  "MaxTokensInfo": "Die maximale Token-Anzahl variiert je nach verwendetem KI-Modell. Bitte überprüfen Sie die Spezifikationen jedes Modells.",
  "CannotUseParameters": "Bei aktiviertem Echtzeit-API-Modus oder Audiomodus können Temperature- und Max Tokens-Parameter nicht festgelegt werden.",
  "PresetQuestions": "Vordefinierte Fragen",
  "PresetQuestionsInfo": "Sie können mehrere Fragemuster im Voraus erstellen und registrieren. Registrierte Fragen werden als Schaltflächen in der Benutzeroberfläche angezeigt und können durch Anklicken in das Chat-Eingabefeld übernommen werden.",
  "EnterPresetQuestion": "Bitte geben Sie eine Frage ein",
  "DragToReorder": "Ziehen, um die Reihenfolge zu ändern",
  "CustomAPIEndpoint": "Benutzerdefinierter API-Endpunkt",
  "CustomAPIEndpointInfo": "Geben Sie die URL des API-Endpunkts ein, an den POST-Anfragen gesendet werden sollen.",
  "CustomAPIStream": "Streaming-Modus",
  "CustomAPIStreamForced": "Der Streaming-Modus ist derzeit immer aktiviert.",
  "IncludeSystemMessages": "Systemnachrichten einschließen",
  "CustomAPIHeaders": "Benutzerdefinierte Header",
  "CustomAPIHeadersInfo": "Geben Sie die Header-Informationen im JSON-Format ein, die in API-Anfragen enthalten sein sollen.",
  "CustomAPIBody": "Benutzerdefinierter Body",
  "CustomAPIBodyInfo": "Geben Sie die Body-Informationen im JSON-Format ein, die in API-Anfragen enthalten sein sollen. Nachrichten werden automatisch inkludiert.",
  "CustomAPIDescription": "Hinweis: Nachrichten werden automatisch in den Anfrage-Body aufgenommen. Im Streaming-Modus muss der Server text/event-stream zurückgeben.",
  "EditSlideScripts": "Dialogbearbeitung",
  "PleaseSelectSlide": "Bitte wählen Sie eine Folie aus",
  "XAIAPIKeyLabel": "xAI API-Schlüssel",
  "DynamicRetrievalDescription": "Legt den Schwellenwert fest, wann das Modell die Suche ausführt. Bei 0 wird die Suche immer ausgeführt, bei 1 wird die Suche nicht ausgeführt.",
  "DynamicRetrieval": "Dynamische Suche",
  "OpenRouterModelNameInstruction": "Bitte geben Sie die Modellkennung von OpenRouter ein (z. B. \"openai/gpt-4o\", \"mistralai/mistral-large-latest\"). Die Modellkennung finden Sie auf der OpenRouter-Modellseite.",
  "FixPosition": "Position fixieren",
  "ResetPosition": "Position zurücksetzen",
  "CharacterPosition": "Position des Charakters",
  "DynamicRetrievalThreshold": "Dynamischer Schwellenwert",
  "CurrentStatus": "Aktueller Zustand",
  "PositionNotFixed": "Unbefestigt",
  "PositionFixed": "Fixiert",
  "OpenRouterAPIKeyLabel": "OpenRouter API-Schlüssel",
  "CharacterPositionInfo": "Die Position und Ausrichtung der Charaktere kann fixiert werden. Bei VRM wird die Kameraposition gespeichert, bei Live2D die Modellposition.",
  "UnfixPosition": "Fixierung aufheben"
}
