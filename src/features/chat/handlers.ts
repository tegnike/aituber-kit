import { getAIChatResponseStream } from '@/features/chat/aiChatFactory'
import { Message, EmotionType } from '@/features/messages/messages'
import { speakCharacter } from '@/features/messages/speakCharacter'
import { judgeSlide } from '@/features/slide/slideAIHelpers'
import homeStore from '@/features/stores/home'
import settingsStore from '@/features/stores/settings'
import slideStore from '@/features/stores/slide'
import { goToSlide } from '@/components/slides'
import { messageSelectors } from '../messages/messageSelectors'
import webSocketStore from '@/features/stores/websocketStore'
import i18next from 'i18next'
import toastStore from '@/features/stores/toast'
import { generateMessageId } from '@/utils/messageUtils'
import { isMultiModalAvailable } from '@/features/constants/aiModels'

// è‡ªç”±ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã®ä¼šè©±ã‚’Slackã«å ±å‘Š
const reportConversationToSlack = async (
  userMessage: string,
  assistantMessage: string
): Promise<void> => {
  const sls = slideStore.getState()

  // è‡ªç”±ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã§ãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
  if (!sls.freeConversationMode) return

  try {
    await fetch('/api/slack-conversation', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        slideDocs: sls.selectedSlideDocs,
        userMessage,
        assistantMessage,
        userAgent: typeof navigator !== 'undefined' ? navigator.userAgent : '',
        timestamp: new Date().toLocaleString('ja-JP', {
          timeZone: 'Asia/Tokyo',
        }),
      }),
    })
    console.log('%cğŸ“¨ Slack conversation reported', 'color: #e01e5a')
  } catch (error) {
    console.error('Failed to report conversation to Slack:', error)
  }
}

// ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
const generateSessionId = () => generateMessageId()

// ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ‡ãƒªãƒŸãƒãƒ¼ã‚¿ãƒ¼
const CODE_DELIMITER = '```'

/**
 * AIåˆ¤æ–­æ©Ÿèƒ½ã§ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ã‚’æ±ºå®šã™ã‚‹
 * @param userMessage ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
 * @param image ç”»åƒãƒ‡ãƒ¼ã‚¿
 * @param decisionPrompt AIåˆ¤æ–­ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
 * @returns ç”»åƒã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹
 */
const askAIForMultiModalDecision = async (
  userMessage: string,
  image: string,
  decisionPrompt: string
): Promise<boolean> => {
  try {
    // ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—ï¼ˆæœ€æ–°3ã¤ã¾ã§ï¼‰
    const currentChatLog = homeStore.getState().chatLog
    const recentMessages = currentChatLog.slice(-3)

    // ä¼šè©±å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ§‹ç¯‰
    let conversationHistory = ''
    if (recentMessages.length > 0) {
      conversationHistory = '\n\nç›´è¿‘ã®ä¼šè©±å±¥æ­´:\n'
      // cutImageMessageé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ç”»åƒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
      const textOnlyMessages = messageSelectors.cutImageMessage(recentMessages)
      textOnlyMessages.forEach((msg, index) => {
        const content = msg.content || ''
        conversationHistory += `${index + 1}. ${msg.role === 'user' ? 'ãƒ¦ãƒ¼ã‚¶ãƒ¼' : 'ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ'}: ${content}\n`
      })
    }

    // AIåˆ¤æ–­ç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ§‹ç¯‰
    const decisionMessage: Message = {
      role: 'user',
      content: [
        {
          type: 'text',
          text: `Conversation History:\n${conversationHistory}\n\nUser Message: "${userMessage}"`,
        },
        { type: 'image', image: image },
      ],
      timestamp: new Date().toISOString(),
    }

    // AIåˆ¤æ–­ç”¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    const systemMessage: Message = {
      role: 'system',
      content: decisionPrompt,
    }

    // AIã«åˆ¤æ–­ã‚’æ±‚ã‚ã‚‹
    const response = await getAIChatResponseStream([
      systemMessage,
      decisionMessage,
    ])

    if (!response) {
      return false // ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç”»åƒã‚’ä½¿ç”¨ã—ãªã„
    }

    // ReadableStreamã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    const reader = response.getReader()
    let result = ''

    try {
      while (true) {
        const { done, value } = await reader.read()
        if (done) break
        result += value
      }
    } finally {
      reader.releaseLock()
    }

    const decision = result.trim().toLowerCase()

    // å„è¨€èªã®è‚¯å®šçš„ãªå›ç­”ã‚’ãƒã‚§ãƒƒã‚¯
    const affirmativeResponses = [
      'ã¯ã„',
      'yes',
      'oui',
      'sÃ­',
      'ja',
      'æ˜¯',
      'ì˜ˆ',
      'tak',
      'da',
      'sim',
    ]
    return affirmativeResponses.some((response) => decision.includes(response))
  } catch (error) {
    console.error('AIåˆ¤æ–­ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', error)
    return false // ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç”»åƒã‚’ä½¿ç”¨ã—ãªã„
  }
}

/**
 * ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ„Ÿæƒ…ã‚¿ã‚° `[...]` ã‚’æŠ½å‡ºã™ã‚‹
 * @param text å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
 * @returns æ„Ÿæƒ…ã‚¿ã‚°ã¨æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆ
 */
const extractEmotion = (
  text: string
): { emotionTag: string; remainingText: string } => {
  // å…ˆé ­ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç„¡è¦–ã—ã¦ã€æ„Ÿæƒ…ã‚¿ã‚°ã‚’æ¤œå‡º
  const emotionMatch = text.match(/^\s*\[(.*?)\]/)
  if (emotionMatch?.[0]) {
    return {
      emotionTag: emotionMatch[0].trim(), // ã‚¿ã‚°è‡ªä½“ã®å‰å¾Œã®ã‚¹ãƒšãƒ¼ã‚¹ã¯é™¤å»
      // å…ˆé ­ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚‚å«ã‚ã¦å‰Šé™¤ã—ã€ã•ã‚‰ã«å‰å¾Œã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»
      remainingText: text
        .slice(text.indexOf(emotionMatch[0]) + emotionMatch[0].length)
        .trimStart(),
    }
  }
  return { emotionTag: '', remainingText: text }
}

/**
 * ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ–‡æ³•çš„ã«åŒºåˆ‡ã‚Šã®è‰¯ã„æ–‡ã‚’æŠ½å‡ºã™ã‚‹
 * @param text å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
 * @returns æŠ½å‡ºã•ã‚ŒãŸæ–‡ã¨æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆ
 */
const extractSentence = (
  text: string
): { sentence: string; remainingText: string } => {
  const sentenceMatch = text.match(
    /^(.{1,19}?(?:[ã€‚ï¼.!?ï¼ï¼Ÿ\n]|(?=\[))|.{20,}?(?:[ã€,ã€‚ï¼.!?ï¼ï¼Ÿ\n]|(?=\[)))/
  )
  if (sentenceMatch?.[0]) {
    return {
      sentence: sentenceMatch[0],
      remainingText: text.slice(sentenceMatch[0].length).trimStart(),
    }
  }
  return { sentence: '', remainingText: text }
}

/**
 * ç™ºè©±ã¨é–¢é€£ã™ã‚‹çŠ¶æ…‹æ›´æ–°ã‚’è¡Œã†
 * @param sessionId ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
 * @param sentence ç™ºè©±ã™ã‚‹æ–‡
 * @param emotionTag æ„Ÿæƒ…ã‚¿ã‚° (ä¾‹: "[neutral]")
 * @param currentAssistantMessageListRef ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®å‚ç…§
 * @param currentSlideMessagesRef ã‚¹ãƒ©ã‚¤ãƒ‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®å‚ç…§
 */
const handleSpeakAndStateUpdate = (
  sessionId: string,
  sentence: string,
  emotionTag: string,
  currentAssistantMessageListRef: { current: string[] },
  currentSlideMessagesRef: { current: string[] }
) => {
  const hs = homeStore.getState()
  const emotion = emotionTag.includes('[')
    ? (emotionTag.slice(1, -1).toLowerCase() as EmotionType)
    : 'neutral'

  // ç™ºè©±ä¸è¦/ä¸å¯èƒ½ãªæ–‡å­—åˆ—ã ã£ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
  if (
    sentence === '' ||
    sentence.replace(
      /^[\s\u3000\t\n\r\[\(\{ã€Œï¼»ï¼ˆã€ã€ã€ˆã€Šã€”ï½›Â«â€¹ã€˜ã€šã€›ã€™â€ºÂ»ã€•ã€‹ã€‰ã€ã€‘ï¼‰ï¼½ã€\}\)\]'"''""ãƒ»ã€ã€‚,.!?ï¼ï¼Ÿ:ï¼š;ï¼›\-_=+~ï½*ï¼Š@ï¼ #ï¼ƒ$ï¼„%ï¼…^ï¼¾&ï¼†|ï½œ\\ï¼¼/ï¼`ï½€]+$/gu,
      ''
    ) === ''
  ) {
    return
  }

  speakCharacter(
    sessionId,
    { message: sentence, emotion: emotion },
    () => {
      hs.incrementChatProcessingCount()
      currentSlideMessagesRef.current.push(sentence)
      homeStore.setState({
        slideMessages: [...currentSlideMessagesRef.current],
      })
    },
    () => {
      hs.decrementChatProcessingCount()
      currentSlideMessagesRef.current.shift()
      homeStore.setState({
        slideMessages: [...currentSlideMessagesRef.current],
      })
    }
  )
}

/**
 * å—ã‘å–ã£ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ã—ã€AIã®å¿œç­”ã‚’ç”Ÿæˆã—ã¦ç™ºè©±ã•ã›ã‚‹ (Refactored)
 * @param receivedMessage å‡¦ç†ã™ã‚‹æ–‡å­—åˆ—
 */
export const speakMessageHandler = async (receivedMessage: string) => {
  const sessionId = generateSessionId()
  const currentSlideMessagesRef = { current: [] as string[] }
  const assistantMessageListRef = { current: [] as string[] }

  let isCodeBlock: boolean = false
  let codeBlockContent: string = ''
  let accumulatedAssistantText: string = ''
  let remainingMessage = receivedMessage
  let currentMessageId: string = generateMessageId()

  while (remainingMessage.length > 0 || isCodeBlock) {
    let processableText = ''
    let currentCodeBlock = ''

    if (isCodeBlock) {
      if (remainingMessage.includes(CODE_DELIMITER)) {
        const [codeEnd, ...rest] = remainingMessage.split(CODE_DELIMITER)
        currentCodeBlock = codeBlockContent + codeEnd
        codeBlockContent = ''
        remainingMessage = rest.join(CODE_DELIMITER).trimStart()
        isCodeBlock = false

        if (accumulatedAssistantText.trim()) {
          homeStore.getState().upsertMessage({
            id: currentMessageId,
            role: 'assistant',
            content: accumulatedAssistantText.trim(),
          })
          accumulatedAssistantText = ''
        }
        const codeBlockId = generateMessageId()
        homeStore.getState().upsertMessage({
          id: codeBlockId,
          role: 'code',
          content: currentCodeBlock,
        })

        currentMessageId = generateMessageId()
        continue
      } else {
        codeBlockContent += remainingMessage
        remainingMessage = ''
        continue
      }
    } else if (remainingMessage.includes(CODE_DELIMITER)) {
      const [beforeCode, ...rest] = remainingMessage.split(CODE_DELIMITER)
      processableText = beforeCode
      codeBlockContent = rest.join(CODE_DELIMITER)
      isCodeBlock = true
      remainingMessage = ''
    } else {
      processableText = remainingMessage
      remainingMessage = ''
    }

    if (processableText.length > 0) {
      let localRemaining = processableText.trimStart()
      while (localRemaining.length > 0) {
        const prevLocalRemaining = localRemaining
        const { emotionTag, remainingText: textAfterEmotion } =
          extractEmotion(localRemaining)
        const { sentence, remainingText: textAfterSentence } =
          extractSentence(textAfterEmotion)

        if (sentence) {
          assistantMessageListRef.current.push(sentence)
          const aiText = emotionTag ? `${emotionTag} ${sentence}` : sentence
          accumulatedAssistantText += aiText + ' '
          handleSpeakAndStateUpdate(
            sessionId,
            sentence,
            emotionTag,
            assistantMessageListRef,
            currentSlideMessagesRef
          )
          localRemaining = textAfterSentence
        } else {
          if (localRemaining === prevLocalRemaining && localRemaining) {
            const finalSentence = localRemaining
            assistantMessageListRef.current.push(finalSentence)
            const aiText = emotionTag
              ? `${emotionTag} ${finalSentence}`
              : finalSentence
            accumulatedAssistantText += aiText + ' '
            handleSpeakAndStateUpdate(
              sessionId,
              finalSentence,
              emotionTag,
              assistantMessageListRef,
              currentSlideMessagesRef
            )
            localRemaining = ''
          } else {
            localRemaining = textAfterSentence
          }
        }
        if (
          localRemaining.length > 0 &&
          localRemaining === prevLocalRemaining &&
          !sentence
        ) {
          console.warn(
            'Potential infinite loop detected in speakMessageHandler, breaking. Remaining:',
            localRemaining
          )
          const finalSentence = localRemaining
          assistantMessageListRef.current.push(finalSentence)
          accumulatedAssistantText += finalSentence + ' '
          handleSpeakAndStateUpdate(
            sessionId,
            finalSentence,
            '',
            assistantMessageListRef,
            currentSlideMessagesRef
          )
          break
        }
      }
    }

    if (isCodeBlock && codeBlockContent) {
      if (accumulatedAssistantText.trim()) {
        homeStore.getState().upsertMessage({
          id: currentMessageId,
          role: 'assistant',
          content: accumulatedAssistantText.trim(),
        })
        accumulatedAssistantText = ''
      }
      remainingMessage = codeBlockContent
      codeBlockContent = ''
    }
  }

  if (accumulatedAssistantText.trim()) {
    homeStore.getState().upsertMessage({
      id: currentMessageId,
      role: 'assistant',
      content: accumulatedAssistantText.trim(),
    })
  }
  if (isCodeBlock && codeBlockContent.trim()) {
    console.warn('Loop ended unexpectedly while in code block state.')
    homeStore.getState().upsertMessage({
      role: 'code',
      content: codeBlockContent.trim(),
    })
  }
}

/**
 * AIã‹ã‚‰ã®å¿œç­”ã‚’å‡¦ç†ã™ã‚‹é–¢æ•° (Refactored for chunk-by-chunk saving)
 * @param messages è§£ç­”ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é…åˆ—
 */
export const processAIResponse = async (messages: Message[]) => {
  const sessionId = generateSessionId()
  homeStore.setState({ chatProcessing: true })
  let stream

  const currentSlideMessagesRef = { current: [] as string[] }
  const assistantMessageListRef = { current: [] as string[] }

  try {
    stream = await getAIChatResponseStream(messages)
  } catch (e) {
    console.error(e)
    homeStore.setState({ chatProcessing: false })
    return
  }

  if (stream == null) {
    homeStore.setState({ chatProcessing: false })
    return
  }

  const reader = stream.getReader()
  let receivedChunksForSpeech = ''
  let currentMessageId: string | null = null
  let currentMessageContent = ''
  let currentEmotionTag = ''
  let isCodeBlock = false
  let codeBlockContent = ''

  try {
    while (true) {
      const { done, value } = await reader.read()

      if (value) {
        let textToAdd = value

        if (!isCodeBlock) {
          const delimiterIndexInValue = value.indexOf(CODE_DELIMITER)
          if (delimiterIndexInValue !== -1) {
            textToAdd = value.substring(0, delimiterIndexInValue)
          }
        }

        if (currentMessageId === null) {
          currentMessageId = generateMessageId()
          currentMessageContent = textToAdd
          if (currentMessageContent) {
            homeStore.getState().upsertMessage({
              id: currentMessageId,
              role: 'assistant',
              content: currentMessageContent,
            })
          }
        } else if (!isCodeBlock) {
          currentMessageContent += textToAdd

          if (textToAdd) {
            homeStore.getState().upsertMessage({
              id: currentMessageId,
              role: 'assistant',
              content: currentMessageContent,
            })
          }
        }

        // assistantMessage is now derived from chatLog, no need to set it separately

        receivedChunksForSpeech += value
      }

      let processableTextForSpeech = receivedChunksForSpeech
      receivedChunksForSpeech = ''

      while (processableTextForSpeech.length > 0) {
        const originalProcessableText = processableTextForSpeech

        if (isCodeBlock) {
          codeBlockContent += processableTextForSpeech
          processableTextForSpeech = ''

          const delimiterIndex = codeBlockContent.lastIndexOf(CODE_DELIMITER)

          if (
            delimiterIndex !== -1 &&
            delimiterIndex >=
              codeBlockContent.length -
                (originalProcessableText.length + CODE_DELIMITER.length - 1)
          ) {
            const actualCode = codeBlockContent.substring(0, delimiterIndex)
            const remainingAfterDelimiter = codeBlockContent.substring(
              delimiterIndex + CODE_DELIMITER.length
            )

            if (actualCode.trim()) {
              homeStore.getState().upsertMessage({
                role: 'code',
                content: actualCode,
              })
            }

            codeBlockContent = ''
            isCodeBlock = false
            currentEmotionTag = ''

            currentMessageId = generateMessageId()
            currentMessageContent = ''

            processableTextForSpeech = remainingAfterDelimiter.trimStart()
            continue
          } else {
            receivedChunksForSpeech = codeBlockContent + receivedChunksForSpeech
            codeBlockContent = ''
            break
          }
        } else {
          const delimiterIndex =
            processableTextForSpeech.indexOf(CODE_DELIMITER)
          if (delimiterIndex !== -1) {
            const beforeCode = processableTextForSpeech.substring(
              0,
              delimiterIndex
            )
            const afterDelimiterRaw = processableTextForSpeech.substring(
              delimiterIndex + CODE_DELIMITER.length
            )

            //
            let textToProcessBeforeCode = beforeCode.trimStart()
            while (textToProcessBeforeCode.length > 0) {
              const prevText = textToProcessBeforeCode
              const {
                emotionTag: extractedEmotion,
                remainingText: textAfterEmotion,
              } = extractEmotion(textToProcessBeforeCode)
              if (extractedEmotion) currentEmotionTag = extractedEmotion
              const { sentence, remainingText: textAfterSentence } =
                extractSentence(textAfterEmotion)

              if (sentence) {
                handleSpeakAndStateUpdate(
                  sessionId,
                  sentence,
                  currentEmotionTag,
                  assistantMessageListRef,
                  currentSlideMessagesRef
                )
                textToProcessBeforeCode = textAfterSentence
                if (!textAfterSentence) currentEmotionTag = ''
              } else {
                receivedChunksForSpeech =
                  textToProcessBeforeCode + receivedChunksForSpeech
                textToProcessBeforeCode = ''
                break
              }

              if (
                textToProcessBeforeCode.length > 0 &&
                textToProcessBeforeCode === prevText
              ) {
                console.warn('Speech processing loop stuck on:', prevText)
                receivedChunksForSpeech =
                  textToProcessBeforeCode + receivedChunksForSpeech
                break
              }
            }

            isCodeBlock = true
            codeBlockContent = ''

            const langMatch = afterDelimiterRaw.match(/^ *(\w+)? *\n/)
            let remainingAfterDelimiter = afterDelimiterRaw
            if (langMatch) {
              remainingAfterDelimiter = afterDelimiterRaw.substring(
                langMatch[0].length
              )
            }
            processableTextForSpeech = remainingAfterDelimiter
            continue
          } else {
            const {
              emotionTag: extractedEmotion,
              remainingText: textAfterEmotion,
            } = extractEmotion(processableTextForSpeech)
            if (extractedEmotion) currentEmotionTag = extractedEmotion

            const { sentence, remainingText: textAfterSentence } =
              extractSentence(textAfterEmotion)

            if (sentence) {
              handleSpeakAndStateUpdate(
                sessionId,
                sentence,
                currentEmotionTag,
                assistantMessageListRef,
                currentSlideMessagesRef
              )
              processableTextForSpeech = textAfterSentence
              if (!textAfterSentence) currentEmotionTag = ''
            } else {
              receivedChunksForSpeech =
                processableTextForSpeech + receivedChunksForSpeech
              processableTextForSpeech = ''
              break
            }
          }
        }

        if (
          processableTextForSpeech.length > 0 &&
          processableTextForSpeech === originalProcessableText
        ) {
          console.warn(
            'Main speech processing loop stuck on:',
            originalProcessableText
          )
          receivedChunksForSpeech =
            processableTextForSpeech + receivedChunksForSpeech
          processableTextForSpeech = ''
          break
        }
      }

      if (done) {
        if (receivedChunksForSpeech.length > 0) {
          if (!isCodeBlock) {
            const finalSentence = receivedChunksForSpeech
            const { emotionTag: extractedEmotion, remainingText: finalText } =
              extractEmotion(finalSentence)
            if (extractedEmotion) currentEmotionTag = extractedEmotion

            handleSpeakAndStateUpdate(
              sessionId,
              finalText,
              currentEmotionTag,
              assistantMessageListRef,
              currentSlideMessagesRef
            )
          } else {
            console.warn(
              'Stream ended while still in code block state. Saving remaining code.',
              codeBlockContent
            )
            codeBlockContent += receivedChunksForSpeech
            if (codeBlockContent.trim()) {
              homeStore.getState().upsertMessage({
                role: 'code',
                content: codeBlockContent,
              })
            }
            codeBlockContent = ''
            isCodeBlock = false
          }
        }

        if (isCodeBlock && codeBlockContent.trim()) {
          console.warn(
            'Stream ended unexpectedly while in code block state. Saving buffered code.'
          )
          homeStore.getState().upsertMessage({
            role: 'code',
            content: codeBlockContent,
          })
          codeBlockContent = ''
          isCodeBlock = false
        }
        break
      }
    }
  } catch (e) {
    console.error('Error processing AI response stream:', e)
  } finally {
    reader.releaseLock()
  }

  homeStore.setState({
    chatProcessing: false,
  })

  if (currentMessageContent.trim()) {
    homeStore.getState().upsertMessage({
      id: currentMessageId ?? generateMessageId(),
      role: 'assistant',
      content: currentMessageContent.trim(),
    })
  }
  if (isCodeBlock && codeBlockContent.trim()) {
    console.warn(
      'Stream ended unexpectedly while in code block state. Saving buffered code.'
    )
    homeStore.getState().upsertMessage({
      role: 'code',
      content: codeBlockContent,
    })
    codeBlockContent = ''
    isCodeBlock = false
  }
}

/**
 * ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã®ä¼šè©±ã‚’è¡Œã†
 * ç”»é¢ã®ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰å…¥åŠ›ã•ã‚ŒãŸã¨ãã«å®Ÿè¡Œã•ã‚Œã‚‹å‡¦ç†
 * Youtubeã§ãƒãƒ£ãƒƒãƒˆå–å¾—ã—ãŸå ´åˆã‚‚ã“ã®é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹
 */
export const handleSendChatFn = () => async (text: string) => {
  const sessionId = generateSessionId()
  const newMessage = text
  const timestamp = new Date().toISOString()

  if (newMessage === null) return

  const ss = settingsStore.getState()
  const sls = slideStore.getState()
  const wsManager = webSocketStore.getState().wsManager
  const modalImage = homeStore.getState().modalImage

  if (ss.externalLinkageMode) {
    homeStore.setState({ chatProcessing: true })

    if (wsManager?.websocket?.readyState === WebSocket.OPEN) {
      homeStore.getState().upsertMessage({
        role: 'user',
        content: newMessage,
        timestamp: timestamp,
      })

      wsManager.websocket.send(
        JSON.stringify({ content: newMessage, type: 'chat' })
      )
    } else {
      toastStore.getState().addToast({
        message: i18next.t('NotConnectedToExternalAssistant'),
        type: 'error',
        tag: 'not-connected-to-external-assistant',
      })
      homeStore.setState({
        chatProcessing: false,
      })
    }
  } else if (ss.realtimeAPIMode) {
    if (wsManager?.websocket?.readyState === WebSocket.OPEN) {
      homeStore.getState().upsertMessage({
        role: 'user',
        content: newMessage,
        timestamp: timestamp,
      })
    }
  } else {
    let systemPrompt = ss.systemPrompt
    if (ss.slideMode) {
      if (sls.isPlaying) {
        return
      }

      try {
        let scripts = JSON.stringify(
          require(
            `../../../public/slides/${sls.selectedSlideDocs}/scripts.json`
          )
        )
        systemPrompt = systemPrompt.replace('{{SCRIPTS}}', scripts)

        let supplement = ''
        try {
          const response = await fetch(
            `/api/getSupplement?slideName=${sls.selectedSlideDocs}`
          )
          if (!response.ok) {
            throw new Error('Failed to fetch supplement')
          }
          const data = await response.json()
          supplement = data.supplement
          systemPrompt = systemPrompt.replace('{{SUPPLEMENT}}', supplement)
        } catch (e) {
          console.error('supplement.txtã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ:', e)
        }

        const answerString = await judgeSlide(newMessage, scripts, supplement)
        const answer = JSON.parse(answerString)
        if (answer.judge === 'true' && answer.page !== '') {
          goToSlide(Number(answer.page))
          systemPrompt += `\n\nEspecial Page Number is ${answer.page}.`
        }
      } catch (e) {
        console.error(e)
      }
    }

    homeStore.setState({ chatProcessing: true })

    // ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œãƒã‚§ãƒƒã‚¯
    if (
      modalImage &&
      !isMultiModalAvailable(
        ss.selectAIService,
        ss.selectAIModel,
        ss.enableMultiModal,
        ss.multiModalMode,
        ss.customModel
      )
    ) {
      toastStore.getState().addToast({
        message: i18next.t('MultiModalNotSupported'),
        type: 'error',
        tag: 'multimodal-not-supported',
      })
      homeStore.setState({
        chatProcessing: false,
        modalImage: '',
      })
      return
    }

    // ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ§‹ç¯‰
    let userMessageContent: Message['content'] = newMessage
    let shouldUseImage = false

    if (modalImage) {
      switch (ss.multiModalMode) {
        case 'always':
          shouldUseImage = true
          break
        case 'never':
          shouldUseImage = false
          break
        case 'ai-decide':
          // AIåˆ¤æ–­ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã€AIã«åˆ¤æ–­ã‚’æ±‚ã‚ã‚‹
          shouldUseImage = await askAIForMultiModalDecision(
            newMessage,
            modalImage,
            ss.multiModalAiDecisionPrompt
          )
          break
      }

      if (shouldUseImage) {
        userMessageContent = [
          { type: 'text' as const, text: newMessage },
          { type: 'image' as const, image: modalImage },
        ]
      }
    }

    homeStore.getState().upsertMessage({
      role: 'user',
      content: userMessageContent,
      timestamp: timestamp,
    })

    if (modalImage) {
      homeStore.setState({ modalImage: '' })
    }

    const currentChatLog = homeStore.getState().chatLog

    const messages: Message[] = [
      {
        role: 'system',
        content: systemPrompt,
      },
      ...messageSelectors.getProcessedMessages(
        currentChatLog,
        ss.includeTimestampInUserMessage
      ),
    ]

    try {
      await processAIResponse(messages)

      // è‡ªç”±ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ä¼šè©±ã‚’Slackã«å ±å‘Š
      const sls = slideStore.getState()
      if (sls.freeConversationMode) {
        const currentChatLog2 = homeStore.getState().chatLog
        // æœ€å¾Œã®assistantãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
        const lastAssistantMessage = currentChatLog2
          .slice()
          .reverse()
          .find((msg) => msg.role === 'assistant')
        if (lastAssistantMessage) {
          const assistantContent =
            typeof lastAssistantMessage.content === 'string'
              ? lastAssistantMessage.content
              : ''
          reportConversationToSlack(newMessage, assistantContent)
        }
      }
    } catch (e) {
      console.error(e)
      homeStore.setState({ chatProcessing: false })
    }
  }
}

/**
 * WebSocketã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†
 */
export const handleReceiveTextFromWsFn =
  () =>
  async (
    text: string,
    role?: string,
    emotion: EmotionType = 'neutral',
    type?: string
  ) => {
    const sessionId = generateSessionId()
    if (text === null || role === undefined) return

    const ss = settingsStore.getState()
    const hs = homeStore.getState()
    const wsManager = webSocketStore.getState().wsManager

    if (ss.externalLinkageMode) {
      console.log('ExternalLinkage Mode: true')
    } else {
      console.log('ExternalLinkage Mode: false')
      return
    }

    homeStore.setState({ chatProcessing: true })

    if (role !== 'user') {
      if (type === 'start') {
        // startã®å ´åˆã¯ä½•ã‚‚ã—ãªã„ï¼ˆtextã¯ç©ºæ–‡å­—ã®ãŸã‚ï¼‰
        console.log('Starting new response')
        wsManager?.setTextBlockStarted(false)
      } else if (
        hs.chatLog.length > 0 &&
        hs.chatLog[hs.chatLog.length - 1].role === role &&
        wsManager?.textBlockStarted
      ) {
        // æ—¢å­˜ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ ï¼ˆIDã‚’ç¶­æŒï¼‰
        const lastMessage = hs.chatLog[hs.chatLog.length - 1]
        const lastContent =
          typeof lastMessage.content === 'string' ? lastMessage.content : ''

        homeStore.getState().upsertMessage({
          id: lastMessage.id,
          role: role,
          content: lastContent + text,
        })
      } else {
        // æ–°ã—ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ï¼ˆæ–°è¦IDã‚’ç”Ÿæˆï¼‰
        homeStore.getState().upsertMessage({
          role: role,
          content: text,
        })
        wsManager?.setTextBlockStarted(true)
      }

      if (role === 'assistant' && text !== '') {
        try {
          // æ–‡ã”ã¨ã«éŸ³å£°ã‚’ç”Ÿæˆ & å†ç”Ÿã€è¿”ç­”ã‚’è¡¨ç¤º
          speakCharacter(
            sessionId,
            {
              message: text,
              emotion: emotion,
            },
            () => {
              // assistantMessage is now derived from chatLog, no need to set it separately
            },
            () => {
              // hs.decrementChatProcessingCount()
            }
          )
        } catch (e) {
          console.error('Error in speakCharacter:', e)
        }
      }

      if (type === 'end') {
        // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®çµ‚äº†å‡¦ç†
        console.log('Response ended')
        wsManager?.setTextBlockStarted(false)
        homeStore.setState({ chatProcessing: false })
      }
    }

    homeStore.setState({ chatProcessing: type !== 'end' })
  }

/**
 * RealtimeAPIã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡ã—ãŸã¨ãã®å‡¦ç†
 */
export const handleReceiveTextFromRtFn = () => {
  // é€£ç¶šã™ã‚‹ response.audio ã‚¤ãƒ™ãƒ³ãƒˆã§å…±é€šã® sessionId ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®å¤‰æ•°
  let currentSessionId: string | null = null

  return async (
    text?: string,
    role?: string,
    type?: string,
    buffer?: ArrayBuffer
  ) => {
    // type ãŒ `response.audio` ã‹ã¤ currentSessionId ãŒæœªè¨­å®šã®å ´åˆã«æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç™ºç•ª
    // ãã‚Œä»¥å¤–ã®å ´åˆã¯æ—¢å­˜ã® sessionId ã‚’ä½¿ã„ç¶šã‘ã‚‹ã€‚
    // ãƒ¬ã‚¹ãƒãƒ³ã‚¹çµ‚äº†ï¼ˆcontent_part.done ç­‰ï¼‰æ™‚ã«ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã€‚

    if (currentSessionId === null) {
      currentSessionId = generateSessionId()
    }

    const sessionId = currentSessionId

    const ss = settingsStore.getState()
    const hs = homeStore.getState()

    if (ss.realtimeAPIMode) {
      console.log('realtime api mode: true')
    } else if (ss.audioMode) {
      console.log('audio mode: true')
    } else {
      console.log('realtime api mode: false')
      return
    }

    homeStore.setState({ chatProcessing: true })

    if (role == 'assistant') {
      if (type?.includes('response.audio') && buffer !== undefined) {
        console.log('response.audio:')
        try {
          speakCharacter(
            sessionId,
            {
              emotion: 'neutral',
              message: '',
              buffer: buffer,
            },
            () => {},
            () => {}
          )
        } catch (e) {
          console.error('Error in speakCharacter:', e)
        }
      } else if (type === 'response.content_part.done' && text !== undefined) {
        homeStore.getState().upsertMessage({
          role: role,
          content: text,
        })
      }
    }
    homeStore.setState({ chatProcessing: false })

    // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒå®Œäº†ã—ãŸã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ãƒªã‚»ãƒƒãƒˆ
    if (type === 'response.content_part.done') {
      currentSessionId = null
    }
  }
}
