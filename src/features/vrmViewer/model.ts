import * as THREE from 'three'
import {
  VRM,
  VRMExpressionPresetName,
  VRMLoaderPlugin,
  VRMUtils,
} from '@pixiv/three-vrm'
import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader.js'
import { VRMAnimation } from '../../lib/VRMAnimation/VRMAnimation'
import { VRMLookAtSmootherLoaderPlugin } from '@/lib/VRMLookAtSmootherLoaderPlugin/VRMLookAtSmootherLoaderPlugin'
import { LipSync } from '../lipSync/lipSync'
import { EmoteController } from '../emoteController/emoteController'
import { Talk } from '../messages/messages'

/**
 * 3Dã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
 */
export class Model {
  public vrm?: VRM | null
  public mixer?: THREE.AnimationMixer
  public emoteController?: EmoteController

  private _lookAtTargetParent: THREE.Object3D
  private _lipSync?: LipSync
  private _audioElementWatcher?: {
    observer: MutationObserver
    connectedElements: Set<HTMLAudioElement>
  }

  constructor(lookAtTargetParent: THREE.Object3D) {
    console.log('ğŸ—ï¸ ModelåˆæœŸåŒ–é–‹å§‹')

    this._lookAtTargetParent = lookAtTargetParent

    try {
      // ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªAudioContextã‚’ä½¿ç”¨ï¼ˆã¾ãŸã¯æ—¢å­˜ã®ã‚‚ã®ã‚’å†åˆ©ç”¨ï¼‰
      const audioContext = typeof window !== 'undefined' && window.AudioContext 
        ? new (window.AudioContext || (window as any).webkitAudioContext)()
        : new AudioContext()
      
      this._lipSync = new LipSync(audioContext, { forceStart: true })
      
      console.log('âœ… LipSyncåˆæœŸåŒ–å®Œäº†', {
        audioContextState: audioContext.state,
        sampleRate: audioContext.sampleRate,
        currentTime: audioContext.currentTime
      })
      
      // AudioContextãŒ suspended ã®å ´åˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã§å†é–‹
      if (audioContext.state === 'suspended') {
        console.log('âš ï¸ AudioContext is suspended. å†é–‹ã‚’è©¦ã¿ã¾ã™...')
        audioContext.resume().then(() => {
          console.log('âœ… AudioContext resumed successfully')
        }).catch((error) => {
          console.error('âŒ AudioContext resume failed:', error)
        })
      }
    } catch (error) {
      console.error('âŒ LipSyncåˆæœŸåŒ–å¤±æ•—:', error)
    }

    // å‹•çš„Audioè¦ç´ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®é–‹å§‹
    this.startAudioElementWatcher()
    
    console.log('âœ… ModelåˆæœŸåŒ–å®Œäº†')
  }

  public async loadVRM(url: string): Promise<void> {
    const loader = new GLTFLoader()
    loader.register(
      (parser) =>
        new VRMLoaderPlugin(parser, {
          lookAtPlugin: new VRMLookAtSmootherLoaderPlugin(parser),
        })
    )

    const gltf = await loader.loadAsync(url)

    const vrm = (this.vrm = gltf.userData.vrm)
    vrm.scene.name = 'VRMRoot'

    VRMUtils.rotateVRM0(vrm)
    this.mixer = new THREE.AnimationMixer(vrm.scene)

    this.emoteController = new EmoteController(vrm, this._lookAtTargetParent)
  }

  public unLoadVrm() {
    // Audioè¦ç´ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®åœæ­¢
    this.stopAudioElementWatcher()
    
    if (this.vrm) {
      VRMUtils.deepDispose(this.vrm.scene)
      this.vrm = null
    }
  }

  /**
   * VRMã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª­ã¿è¾¼ã‚€
   *
   * https://github.com/vrm-c/vrm-specification/blob/master/specification/VRMC_vrm_animation-1.0/README.ja.md
   */
  public async loadAnimation(vrmAnimation: VRMAnimation): Promise<void> {
    const { vrm, mixer } = this
    if (vrm == null || mixer == null) {
      throw new Error('You have to load VRM first')
    }

    const clip = vrmAnimation.createAnimationClip(vrm)
    const action = mixer.clipAction(clip)
    action.play()
  }

  /**
   * éŸ³å£°ã‚’å†ç”Ÿã—ã€ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚’è¡Œã†
   */
  public async speak(
    buffer: ArrayBuffer,
    talk: Talk,
    isNeedDecode: boolean = true
  ) {
    console.log('ğŸ—£ï¸ Model.speaké–‹å§‹', {
      emotion: talk.emotion,
      bufferSize: buffer.byteLength,
      hasEmoteController: !!this.emoteController,
      hasLipSync: !!this._lipSync,
    })

    try {
      // è¡¨æƒ…ã‚’è¨­å®š
      if (this.emoteController) {
        console.log(`ğŸ­ è¡¨æƒ…è¨­å®š: ${talk.emotion}`)
        this.emoteController.playEmotion(talk.emotion)
      } else {
        console.warn('âš ï¸ EmoteControllerãŒåˆ©ç”¨ã§ãã¾ã›ã‚“')
      }

      // éŸ³å£°å†ç”Ÿã¨ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯
      if (this._lipSync) {
        console.log('ğŸ”Š éŸ³å£°å†ç”Ÿé–‹å§‹', {
          bufferSize: buffer.byteLength,
          isNeedDecode,
          lipSyncStatus: (this._lipSync as any).getStatus?.()
        })
        
        // ãƒ‡ãƒãƒƒã‚°: LipSyncã®è©³ç´°çŠ¶æ…‹ã‚’å‡ºåŠ›
        if (typeof (this._lipSync as any).logDetailedStatus === 'function') {
          (this._lipSync as any).logDetailedStatus()
        }
        
        await new Promise<void>((resolve) => {
          this._lipSync?.playFromArrayBuffer(
            buffer,
            () => {
              console.log('âœ… éŸ³å£°å†ç”Ÿå®Œäº†')
              resolve()
            },
            isNeedDecode
          )
        })
      } else {
        console.warn('âš ï¸ LipSyncãŒåˆ©ç”¨ã§ãã¾ã›ã‚“')
      }
    } catch (error) {
      console.error('âŒ Model.speakå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error)
    }
  }

  /**
   * LipSyncã‚·ã‚¹ãƒ†ãƒ ã®AudioContextã‚’å–å¾—
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ã§åŒä¸€ã®AudioContextã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«å¿…è¦
   */
  public getAudioContext(): AudioContext | null {
    if (this._lipSync && (this._lipSync as any).audio) {
      return (this._lipSync as any).audio as AudioContext
    }
    console.warn('âš ï¸ Model: LipSyncã®AudioContextãŒå–å¾—ã§ãã¾ã›ã‚“')
    return null
  }

  /**
   * HTMLAudioElementã‚’LipSyncã‚·ã‚¹ãƒ†ãƒ ã«æ¥ç¶šï¼ˆAudioContextçµ±ä¸€ç‰ˆï¼‰
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ã§ã‚‚ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã‚’å‹•ä½œã•ã›ã‚‹ãŸã‚ã«ä½¿ç”¨
   */
  public connectAudioForLipSync(audioElement: HTMLAudioElement, useExistingContext: boolean = false): boolean {
    console.log('ğŸ”— Model: HTMLAudioElementã‚’LipSyncï¼ˆAudioContextçµ±ä¸€ç‰ˆï¼‰ã«æ¥ç¶š')
    
    if (!this._lipSync) {
      console.warn('âš ï¸ Model: LipSyncãŒåˆ©ç”¨ã§ãã¾ã›ã‚“')
      return false
    }

    if (useExistingContext) {
      // AudioContextã‚’çµ±ä¸€ã™ã‚‹å ´åˆã®å‡¦ç†
      console.log('ğŸ¯ åŒä¸€AudioContextã§ã®æ¥ç¶šã‚’å®Ÿè¡Œ')
      if (typeof (this._lipSync as any).connectAudioElement === 'function') {
        try {
          (this._lipSync as any).connectAudioElement(audioElement)
          console.log('âœ… Model: çµ±ä¸€AudioContextã§ã®LipSyncé€£æºé–‹å§‹')
          return true
        } catch (error) {
          console.error('âŒ Model: çµ±ä¸€AudioContextæ¥ç¶šã‚¨ãƒ©ãƒ¼:', error)
          return false
        }
      }
    } else {
      // å¾“æ¥ã®æ–¹æ³•ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
      if (typeof (this._lipSync as any).connectAudioElement === 'function') {
        (this._lipSync as any).connectAudioElement(audioElement)
        console.log('âœ… Model: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ã®LipSyncé€£æºé–‹å§‹')
        return true
      }
    }
    
    console.warn('âš ï¸ Model: connectAudioElementãƒ¡ã‚½ãƒƒãƒ‰ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“')
    return false
  }

  /**
   * HTMLAudioElementã®LipSyncæ¥ç¶šã‚’è§£é™¤
   */
  public disconnectAudioForLipSync() {
    console.log('ğŸ”— Model: HTMLAudioElementã®LipSyncæ¥ç¶šè§£é™¤')
    if (this._lipSync && typeof (this._lipSync as any).disconnectAudioElement === 'function') {
      (this._lipSync as any).disconnectAudioElement()
      console.log('âœ… Model: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ã®LipSyncé€£æºçµ‚äº†')
    }
  }

  /**
   * ç¾åœ¨ã®éŸ³å£°å†ç”Ÿã‚’åœæ­¢
   */
  public stopSpeaking() {
    this._lipSync?.stopCurrentPlayback()
  }

  /**
   * æ„Ÿæƒ…è¡¨ç¾ã‚’å†ç”Ÿã™ã‚‹
   */
  public async playEmotion(preset: VRMExpressionPresetName) {
    this.emoteController?.playEmotion(preset)
  }

  public update(delta: number): void {
    try {
      // ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ã®æ›´æ–°
      if (this._lipSync) {
        const { volume } = this._lipSync.update()

        // EmoteControllerã«ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯æƒ…å ±ã‚’é€ä¿¡
        if (this.emoteController) {
          this.emoteController.lipSync('aa', volume)
        }

        // å¿…è¦ã«å¿œã˜ã¦ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
        // console.log(`ğŸ™ï¸ Model.update: LipSync volume=${volume.toFixed(4)}`)
      }

      // ã‚¨ãƒ¢ãƒ¼ãƒˆã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã®æ›´æ–°
      if (this.emoteController) {
        this.emoteController.update(delta)
      }

      // ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒŸã‚­ã‚µãƒ¼ã®æ›´æ–°
      if (this.mixer) {
        this.mixer.update(delta)
      }

      // VRMã®æ›´æ–°
      if (this.vrm) {
        this.vrm.update(delta)
      }
    } catch (error) {
      console.error('âŒ Model.updateå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error)
    }
  }

  /**
   * å‹•çš„Audioè¦ç´ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®é–‹å§‹
   * DOMå†…ã«æ–°ã—ã„Audioè¦ç´ ãŒè¿½åŠ ã•ã‚ŒãŸã¨ãã«è‡ªå‹•ã§LipSyncã«æ¥ç¶š
   */
  private startAudioElementWatcher() {
    if (typeof window === 'undefined') return // ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã§ã¯å®Ÿè¡Œã—ãªã„
    
    console.log('ğŸ‘ï¸ Audioè¦ç´ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹')
    
    this._audioElementWatcher = {
      observer: new MutationObserver(() => {}), // å¾Œã§è¨­å®š
      connectedElements: new Set()
    }
    
    // æ—¢å­˜ã®Audioè¦ç´ ã‚’æ¤œç´¢ã—ã¦æ¥ç¶š
    this.scanAndConnectAudioElements()
    
    // MutationObserverã§æ–°ã—ã„Audioè¦ç´ ã‚’ç›£è¦–
    const observer = new MutationObserver((mutations) => {
      let hasNewAudioElements = false
      let detectedElements = []
      
      mutations.forEach((mutation) => {
        mutation.addedNodes.forEach((node) => {
          if (node.nodeType === Node.ELEMENT_NODE) {
            const element = node as Element
            
            // Audioè¦ç´ ãŒç›´æ¥è¿½åŠ ã•ã‚ŒãŸå ´åˆ
            if (element.tagName === 'AUDIO') {
              hasNewAudioElements = true
              detectedElements.push('ç›´æ¥Audioè¦ç´ ')
            }
            
            // Audioè¦ç´ ã‚’å«ã‚€è¦ç´ ãŒè¿½åŠ ã•ã‚ŒãŸå ´åˆ
            const audioElements = element.querySelectorAll('audio')
            if (audioElements.length > 0) {
              hasNewAudioElements = true
              detectedElements.push(`${audioElements.length}å€‹ã®Audioè¦ç´ ã‚’å«ã‚€è¦ç´ `)
            }
          }
        })
      })
      
      if (hasNewAudioElements) {
        console.log('ğŸ” æ–°ã—ã„Audioè¦ç´ ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ - æ¥ç¶šãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ')
        setTimeout(() => this.scanAndConnectAudioElements(), 100) // å°‘ã—é…å»¶ã—ã¦å®Ÿè¡Œ
      }
    })
    
    // DOMå…¨ä½“ã‚’ç›£è¦–
    observer.observe(document.body, {
      childList: true,
      subtree: true
    })
    
    this._audioElementWatcher.observer = observer
  }
  
  /**
   * DOMå†…ã®Audioè¦ç´ ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦LipSyncã«æ¥ç¶š
   */
  private scanAndConnectAudioElements() {
    if (!this._audioElementWatcher || !this._lipSync) return
    
    const audioElements = document.querySelectorAll('audio')
    if (audioElements.length === 0) return
    
    let newConnectionCount = 0
    
    audioElements.forEach((audio, index) => {
      // æ—¢ã«æ¥ç¶šæ¸ˆã¿ã®è¦ç´ ã¯ã‚¹ã‚­ãƒƒãƒ—
      if (this._audioElementWatcher!.connectedElements.has(audio)) {
        return
      }
      
      try {
        if (typeof (this._lipSync as any).connectAudioElement === 'function') {
          (this._lipSync as any).connectAudioElement(audio)
          this._audioElementWatcher!.connectedElements.add(audio)
          newConnectionCount++
          console.log(`âœ… Audioè¦ç´ [${index}] ã®LipSyncæ¥ç¶šå®Œäº†`)
          
          // Audioè¦ç´ ãŒå‰Šé™¤ã•ã‚ŒãŸæ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
          const handleRemoved = () => {
            if (this._audioElementWatcher?.connectedElements.has(audio)) {
              this._audioElementWatcher.connectedElements.delete(audio)
            }
          }
          
          // è¦ç´ ãŒå‰Šé™¤ã•ã‚Œã‚‹ã®ã‚’ç›£è¦–
          const removalObserver = new MutationObserver((mutations) => {
            mutations.forEach((mutation) => {
              mutation.removedNodes.forEach((node) => {
                if (node === audio || (node as Element).contains?.(audio)) {
                  handleRemoved()
                  removalObserver.disconnect()
                }
              })
            })
          })
          
          removalObserver.observe(document.body, {
            childList: true,
            subtree: true
          })
        }
      } catch (error) {
        console.error(`âŒ Audioè¦ç´ [${index}]ã®è‡ªå‹•æ¥ç¶šã‚¨ãƒ©ãƒ¼:`, error)
      }
    })
    
    if (newConnectionCount > 0) {
      console.log(`ğŸ“Š ${newConnectionCount}å€‹ã®æ–°ã—ã„Audioè¦ç´ ã‚’æ¥ç¶š`)
    }
  }
  
  /**
   * Audioè¦ç´ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®åœæ­¢
   */
  private stopAudioElementWatcher() {
    if (this._audioElementWatcher) {
      this._audioElementWatcher.observer.disconnect()
      this._audioElementWatcher.connectedElements.clear()
      console.log('ğŸ›‘ Audioè¦ç´ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åœæ­¢')
      this._audioElementWatcher = undefined
    }
  }

  /**
   * Audioè¦ç´ ã®æ‰‹å‹•ã‚¹ã‚­ãƒ£ãƒ³ã‚’ãƒˆãƒªã‚¬ãƒ¼ï¼ˆå¤–éƒ¨ã‹ã‚‰å‘¼ã³å‡ºã—å¯èƒ½ï¼‰
   */
  public scanAudioElements() {
    this.scanAndConnectAudioElements()
  }

  /**
   * ãƒ‡ãƒãƒƒã‚°ç”¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—
   */
  public getStatus() {
    return {
      hasVRM: !!this.vrm,
      hasEmoteController: !!this.emoteController,
      hasLipSync: !!this._lipSync,
      hasMixer: !!this.mixer,
      vrmStatus: this.vrm
        ? {
            hasExpressionManager: !!this.vrm.expressionManager,
            hasLookAt: !!this.vrm.lookAt,
            hasHumanoid: !!this.vrm.humanoid,
          }
        : null,
      emoteControllerStatus:
        this.emoteController &&
        typeof (this.emoteController as any).getStatus === 'function'
          ? (this.emoteController as any).getStatus()
          : null,
      lipSyncStatus:
        this._lipSync && typeof (this._lipSync as any).getStatus === 'function'
          ? (this._lipSync as any).getStatus()
          : null,
    }
  }
}
