import { LipSyncAnalyzeResult } from './lipSyncAnalyzeResult'

const TIME_DOMAIN_DATA_LENGTH = 1024  // 2048ã‹ã‚‰1024ã«å¤‰æ›´ï¼ˆã‚ˆã‚Šé »ç¹ãªæ›´æ–°ï¼‰

export class LipSync {
  public readonly audio: AudioContext
  public readonly analyser: AnalyserNode
  public readonly gainNode: GainNode
  public readonly timeDomainData: Float32Array
  private userInteracted: boolean = false
  private waitingForInteraction: boolean = false
  private pendingPlaybacks: Array<() => void> = []
  private forceStart: boolean = false
  private currentSource: AudioBufferSourceNode | null = null
  private connectedAudioElement: HTMLAudioElement | null = null
  private audioElementSource: MediaElementAudioSourceNode | null = null
  private initializationRetries: number = 0
  private maxRetries: number = 3

  public constructor(audio: AudioContext, options?: { forceStart?: boolean }) {
    console.log('ğŸ”Š LipSyncåˆæœŸåŒ–é–‹å§‹', {
      audioContextState: audio.state,
      sampleRate: audio.sampleRate,
      forceStart: options?.forceStart,
    })

    this.audio = audio
    this.forceStart = options?.forceStart || false

    try {
      // GainNodeã‚’ä½œæˆï¼ˆéŸ³é‡èª¿æ•´ã¨ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç”¨ï¼‰
      this.gainNode = audio.createGain()
      this.gainNode.gain.value = 1.0  // éŸ³é‡ã¯100%
      
      // AnalyserNodeã‚’ä½œæˆ
      this.analyser = audio.createAnalyser()
      this.analyser.fftSize = TIME_DOMAIN_DATA_LENGTH
      // ã‚ˆã‚Šæ•æ„Ÿã«éŸ³å£°ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®è¨­å®š
      this.analyser.smoothingTimeConstant = 0.3  // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã‚’æ¸›ã‚‰ã—ã¦åå¿œæ€§ã‚’å‘ä¸Š
      this.analyser.minDecibels = -90  // ã‚ˆã‚Šå°ã•ãªéŸ³ã‚‚æ¤œå‡º
      this.analyser.maxDecibels = -10  // ã‚ˆã‚Šåºƒã„ç¯„å›²ã®éŸ³ã‚’æ¤œå‡º
      
      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚°ãƒ©ãƒ•ã®æ¥ç¶š: GainNode â†’ AnalyserNode â†’ destination
      // ã“ã‚Œã«ã‚ˆã‚Šã€ã™ã¹ã¦ã®éŸ³å£°ãŒAnalyserNodeã‚’é€šã‚‹
      this.gainNode.connect(this.analyser)
      this.analyser.connect(this.audio.destination)
      
      this.timeDomainData = new Float32Array(TIME_DOMAIN_DATA_LENGTH)

      console.log('âœ… ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚°ãƒ©ãƒ•ä½œæˆæˆåŠŸ', {
        fftSize: this.analyser.fftSize,
        frequencyBinCount: this.analyser.frequencyBinCount,
        smoothingTimeConstant: this.analyser.smoothingTimeConstant,
        minDecibels: this.analyser.minDecibels,
        maxDecibels: this.analyser.maxDecibels,
        gainValue: this.gainNode.gain.value,
        audioGraph: 'source â†’ gainNode â†’ analyser â†’ destination'
      })
    } catch (error) {
      console.error('âŒ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚°ãƒ©ãƒ•ä½œæˆå¤±æ•—:', error)
      throw new Error(`LipSyncåˆæœŸåŒ–å¤±æ•—: ${error}`)
    }

    // AudioContextã®åˆæœŸåŒ–
    this.initializeAudioContext()
  }

  private async initializeAudioContext() {
    console.log(
      `ğŸ”Š AudioContextåˆæœŸåŒ– (è©¦è¡Œ ${this.initializationRetries + 1}/${this.maxRetries})`
    )

    try {
      // forceStartãŒæœ‰åŠ¹ãªå ´åˆã¯å¼·åˆ¶çš„ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æ¸ˆã¿ã¨ãƒãƒ¼ã‚¯
      if (this.forceStart) {
        this.userInteracted = true
        await this.tryResumeAudio()
        console.log('âœ… forceStartæœ‰åŠ¹ - AudioContextå¼·åˆ¶å†é–‹')
      } else {
        // é€šå¸¸ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡ºã‚’è¨­å®š
        this.setupUserInteractionDetection()
        console.log('ğŸ‘† ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡ºã‚’è¨­å®š')
      }

      // æˆåŠŸã—ãŸå ´åˆã¯ãƒªãƒˆãƒ©ã‚¤ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ
      this.initializationRetries = 0
    } catch (error) {
      console.error(
        `âŒ AudioContextåˆæœŸåŒ–å¤±æ•— (è©¦è¡Œ ${this.initializationRetries + 1}):`,
        error
      )

      this.initializationRetries++
      if (this.initializationRetries < this.maxRetries) {
        console.log(`ğŸ”„ ${2000 * this.initializationRetries}mså¾Œã«å†è©¦è¡Œ`)
        setTimeout(() => {
          this.initializeAudioContext()
        }, 2000 * this.initializationRetries) // æŒ‡æ•°çš„ãƒãƒƒã‚¯ã‚ªãƒ•
      } else {
        console.error('âŒ AudioContextåˆæœŸåŒ–ã®æœ€å¤§è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸ')
      }
    }
  }

  // AudioContextã®å†é–‹ã‚’è©¦ã¿ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
  private async tryResumeAudio(): Promise<void> {
    if (this.audio.state === 'suspended') {
      try {
        await this.audio.resume()
        console.log('AudioContext resumed successfully')
        // ä¿ç•™ä¸­ã®å†ç”Ÿã‚’å‡¦ç†
        this.processPendingPlaybacks()
      } catch (error) {
        console.error('Failed to resume AudioContext:', error)
      }
    }
  }

  private setupUserInteractionDetection(): void {
    // ã™ã§ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã¯è¨­å®šã‚’ã‚¹ã‚­ãƒƒãƒ—
    if (this.audio.state === 'running') {
      this.userInteracted = true
      return
    }

    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒªãƒƒã‚¹ãƒ³
    const interactionEvents = ['click', 'touchstart', 'keydown', 'mousedown']
    const handleInteraction = async () => {
      this.userInteracted = true

      if (this.audio.state === 'suspended') {
        try {
          await this.audio.resume()
          console.log('AudioContext resumed successfully')
        } catch (error) {
          console.error('Failed to resume AudioContext:', error)
        }
      }

      // ä¿ç•™ä¸­ã®å†ç”Ÿã‚’å‡¦ç†
      this.processPendingPlaybacks()

      // ä¸€åº¦ã ã‘å®Ÿè¡Œã—ãŸã„ã®ã§ã€ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’å‰Šé™¤
      interactionEvents.forEach((eventType) => {
        window.removeEventListener(eventType, handleInteraction, true)
      })
    }

    // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’è¿½åŠ 
    interactionEvents.forEach((eventType) => {
      window.addEventListener(eventType, handleInteraction, true)
    })
  }

  private processPendingPlaybacks(): void {
    if (this.pendingPlaybacks.length > 0) {
      console.log(
        `Processing ${this.pendingPlaybacks.length} pending audio playbacks`
      )
      const playbacks = [...this.pendingPlaybacks]
      this.pendingPlaybacks = []
      playbacks.forEach((playback) => playback())
    }
  }

  private async ensureAudioContextReady(): Promise<boolean> {
    // forceStartãŒæœ‰åŠ¹ãªå ´åˆã¯å¸¸ã«æº–å‚™å®Œäº†ã¨ã¿ãªã™
    if (this.forceStart) {
      await this.tryResumeAudio()
      return true
    }

    if (this.audio.state === 'running') {
      return true
    }

    if (this.userInteracted) {
      try {
        await this.audio.resume()
        return true
      } catch (error) {
        console.error('Failed to resume AudioContext:', error)
        return false
      }
    }

    this.waitingForInteraction = true
    console.warn('AudioContext cannot start: waiting for user interaction')
    return false
  }

  // forceStartè¨­å®šã‚’å‹•çš„ã«å¤‰æ›´ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ 
  public setForceStart(enable: boolean): void {
    this.forceStart = enable
    if (enable && !this.userInteracted) {
      this.userInteracted = true
      this.tryResumeAudio()
    }
  }

  public update(): LipSyncAnalyzeResult {
    // forceStartãŒæœ‰åŠ¹ã§AudioContextãŒæº–å‚™ã§ãã¦ã„ãªã„å ´åˆã¯å†é–‹ã‚’è©¦ã¿ã‚‹
    if (this.forceStart && this.audio.state === 'suspended') {
      this.tryResumeAudio()
    }

    // AudioContextã¨AnalyserNodeã®çŠ¶æ…‹ç¢ºèª
    if (!this.analyser || !this.timeDomainData) {
      console.warn('âš ï¸ AnalyserNodeã¾ãŸã¯timeDomainDataãŒæœªåˆæœŸåŒ–')
      return { volume: 0 }
    }

    // å†ç”Ÿä¸­ã®éŸ³æºãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆAudioBufferSourceã¾ãŸã¯HTMLAudioElementï¼‰
    const hasAudioBufferSource = !!this.currentSource
    const hasConnectedAudio = !!(this.connectedAudioElement && 
                                !this.connectedAudioElement.paused && 
                                !this.connectedAudioElement.ended)
    const hasSource = hasAudioBufferSource || hasConnectedAudio

    // æ™‚é–“é ˜åŸŸãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    this.analyser.getFloatTimeDomainData(this.timeDomainData)

    // ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®10å€‹ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ç¢ºèª
    let hasData = false
    for (let i = 0; i < Math.min(10, TIME_DOMAIN_DATA_LENGTH); i++) {
      if (this.timeDomainData[i] !== 0) {
        hasData = true
        break
      }
    }

    // RMSï¼ˆäºŒä¹—å¹³å‡å¹³æ–¹æ ¹ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šæ­£ç¢ºãªéŸ³é‡ã‚’è¨ˆç®—
    let sum = 0.0
    for (let i = 0; i < TIME_DOMAIN_DATA_LENGTH; i++) {
      sum += this.timeDomainData[i] * this.timeDomainData[i]
    }
    let rms = Math.sqrt(sum / TIME_DOMAIN_DATA_LENGTH)
    
    // ãƒ”ãƒ¼ã‚¯å€¤ã‚‚ä½µç”¨
    let peak = 0.0
    for (let i = 0; i < TIME_DOMAIN_DATA_LENGTH; i++) {
      peak = Math.max(peak, Math.abs(this.timeDomainData[i]))
    }
    
    // RMSã¨ãƒ”ãƒ¼ã‚¯ã®çµ„ã¿åˆã‚ã›ã§æœ€çµ‚çš„ãªéŸ³é‡ã‚’æ±ºå®š
    let volume = Math.max(rms * 2, peak * 0.8)

    // ã‚ˆã‚Šç·©ã‚„ã‹ãªã‚«ãƒ¼ãƒ–ã§å¤‰æ›ï¼ˆæ„Ÿåº¦å‘ä¸Šï¼‰
    volume = 1 / (1 + Math.exp(-20 * volume + 3))
    
    // æœ€å°é–¾å€¤ã‚’ä¸‹ã’ã¦å°ã•ãªéŸ³ã§ã‚‚åå¿œã™ã‚‹ã‚ˆã†ã«
    if (volume < 0.05) volume = 0
    
    // æœ€å¤§å€¤ã§ã‚¯ãƒªãƒƒãƒ—
    volume = Math.min(volume, 1.0)

    // ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ï¼ˆéŸ³é‡æ¤œå‡ºæ™‚ã®ã¿è¡¨ç¤ºï¼‰
    if (volume > 0.01) {
      // å®Ÿéš›ã«éŸ³é‡ãŒæ¤œå‡ºã•ã‚ŒãŸæ™‚ã®ã¿ãƒ­ã‚°å‡ºåŠ›
      console.log(`ğŸ¤ éŸ³é‡è§£æ: Volume=${volume.toFixed(3)}, hasSource=${hasSource}, hasData=${hasData}`)
    }
    
    // MediaElementAudioSourceNodeæ¥ç¶šæ™‚ã®ã¿ã‚¢ãƒ©ãƒ¼ãƒˆè¡¨ç¤ºï¼ˆæ–°ã—ã„ãƒãƒ£ãƒ³ã‚¯é€ä¿¡æ–¹å¼ã§ã¯æ­£å¸¸ï¼‰
    if (hasSource && !hasData && this.connectedAudioElement) {
      // HTMLAudioElementæ¥ç¶šã§ãƒ‡ãƒ¼ã‚¿ãŒæµã‚Œãªã„å ´åˆã®ã¿è­¦å‘Š
      console.warn('âš ï¸ HTMLAudioElementéŸ³å£°ã‚½ãƒ¼ã‚¹å†ç”Ÿä¸­ã§ã™ãŒã€AnalyserNodeã«ãƒ‡ãƒ¼ã‚¿ãŒæµã‚Œã¦ã„ã¾ã›ã‚“')
    }

    return {
      volume,
    }
  }

  public async playFromArrayBuffer(
    buffer: ArrayBuffer,
    onEnded?: () => void,
    isNeedDecode: boolean = true,
    sampleRate: number = 24000
  ) {
    console.log('ğŸµ éŸ³å£°å†ç”Ÿé–‹å§‹', {
      bufferSize: buffer.byteLength,
      isNeedDecode,
      sampleRate,
      audioContextState: this.audio.state,
    })

    // AudioContextãŒæº–å‚™ã§ãã¦ã„ã‚‹ã‹ç¢ºèª
    const isReady = await this.ensureAudioContextReady()

    if (!isReady) {
      console.warn(
        'âš ï¸ AudioContextãŒæº–å‚™ã§ãã¦ã„ã¾ã›ã‚“ã€‚ãƒšãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ '
      )
      // ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¾…ã¤
      this.pendingPlaybacks.push(() => {
        this.playFromArrayBuffer(buffer, onEnded, isNeedDecode, sampleRate)
      })
      return
    }

    try {
      // ãƒãƒƒãƒ•ã‚¡ã®è©³ç´°æ¤œè¨¼
      if (!(buffer instanceof ArrayBuffer)) {
        throw new Error('The input buffer is not in ArrayBuffer format')
      }

      if (buffer.byteLength === 0) {
        throw new Error('The input buffer is empty')
      }

      console.log('âœ… ãƒãƒƒãƒ•ã‚¡æ¤œè¨¼æˆåŠŸã€‚éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹')

      let audioBuffer: AudioBuffer

      if (!isNeedDecode) {
        // PCM16å½¢å¼ã®å ´åˆ
        console.log('ğŸ”¢ PCM16å½¢å¼ã¨ã—ã¦å‡¦ç†')
        const pcmData = new Int16Array(buffer)

        const floatData = new Float32Array(pcmData.length)
        for (let i = 0; i < pcmData.length; i++) {
          floatData[i] =
            pcmData[i] < 0 ? pcmData[i] / 32768.0 : pcmData[i] / 32767.0
        }

        audioBuffer = this.audio.createBuffer(1, floatData.length, sampleRate)
        audioBuffer.getChannelData(0).set(floatData)

        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¤œè¨¼
        const channelData = audioBuffer.getChannelData(0)
        let nonZeroSamples = 0
        let maxAmplitude = 0
        let sampleSum = 0
        
        for (let i = 0; i < Math.min(1000, channelData.length); i++) {
          const sample = Math.abs(channelData[i])
          if (sample > 0.001) nonZeroSamples++
          maxAmplitude = Math.max(maxAmplitude, sample)
          sampleSum += sample
        }
        
        const avgAmplitude = sampleSum / Math.min(1000, channelData.length)

        console.log('âœ… PCM16ãƒãƒƒãƒ•ã‚¡ä½œæˆæˆåŠŸ', {
          duration: audioBuffer.duration,
          sampleRate: audioBuffer.sampleRate,
          totalSamples: channelData.length,
          nonZeroSamples,
          maxAmplitude: maxAmplitude.toFixed(4),
          avgAmplitude: avgAmplitude.toFixed(4),
          hasAudioData: nonZeroSamples > 0 && maxAmplitude > 0.001
        })
      } else {
        // é€šå¸¸ã®åœ§ç¸®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        console.log('ğŸµ åœ§ç¸®éŸ³å£°ã¨ã—ã¦å‡¦ç†')
        try {
          audioBuffer = await this.audio.decodeAudioData(buffer.slice()) // buffer ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
          
          // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¤œè¨¼
          const channelData = audioBuffer.getChannelData(0)
          let nonZeroSamples = 0
          let maxAmplitude = 0
          let sampleSum = 0
          
          for (let i = 0; i < Math.min(1000, channelData.length); i++) {
            const sample = Math.abs(channelData[i])
            if (sample > 0.001) nonZeroSamples++
            maxAmplitude = Math.max(maxAmplitude, sample)
            sampleSum += sample
          }
          
          const avgAmplitude = sampleSum / Math.min(1000, channelData.length)

          console.log('âœ… éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰æˆåŠŸ', {
            duration: audioBuffer.duration,
            numberOfChannels: audioBuffer.numberOfChannels,
            sampleRate: audioBuffer.sampleRate,
            totalSamples: channelData.length,
            nonZeroSamples,
            maxAmplitude: maxAmplitude.toFixed(4),
            avgAmplitude: avgAmplitude.toFixed(4),
            hasAudioData: nonZeroSamples > 0 && maxAmplitude > 0.001
          })
        } catch (decodeError) {
          console.error('âŒ éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ‰å¤±æ•—:', decodeError)
          throw new Error(`éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—: ${decodeError}`)
        }
      }

      // AudioBufferSourceNodeã®ä½œæˆã¨è¨­å®š
      const bufferSource = this.audio.createBufferSource()
      this.currentSource = bufferSource
      bufferSource.buffer = audioBuffer

      // éŸ³å£°ã®æ¥ç¶šè¨­å®š: bufferSource â†’ gainNode â†’ analyser â†’ destination
      // GainNodeãŒä¸­ç¶™ã™ã‚‹ã“ã¨ã§ã€éŸ³å£°ãŒç¢ºå®Ÿã«AnalyserNodeã‚’é€šã‚‹
      bufferSource.connect(this.gainNode)

      console.log('ğŸ”— ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ¥ç¶šå®Œäº†', {
        bufferDuration: audioBuffer.duration,
        bufferLength: audioBuffer.length,
        bufferSampleRate: audioBuffer.sampleRate,
        numberOfChannels: audioBuffer.numberOfChannels,
        analyserConnected: !!this.analyser,
        audioContextState: this.audio.state,
        currentTime: this.audio.currentTime
      })

      // å†ç”Ÿé–‹å§‹
      bufferSource.start()

      // çµ‚äº†ã‚¤ãƒ™ãƒ³ãƒˆã®è¨­å®š
      bufferSource.onended = () => {
        console.log('ğŸ éŸ³å£°å†ç”Ÿå®Œäº†')
        if (this.currentSource === bufferSource) {
          this.currentSource = null
        }
        onEnded?.()
      }
    } catch (error) {
      console.error('âŒ éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼:', error)

      // ã‚¨ãƒ©ãƒ¼è©³ç´°ã®åˆ†æ
      if (error instanceof DOMException) {
        console.error('DOMä¾‹å¤–è©³ç´°:', {
          name: error.name,
          message: error.message,
          code: error.code,
        })
      }

      // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
      this.currentSource = null
      if (onEnded) {
        onEnded()
      }
    }
  }

  public async playFromURL(url: string, onEnded?: () => void) {
    try {
      const res = await fetch(url)
      const buffer = await res.arrayBuffer()
      await this.playFromArrayBuffer(buffer, onEnded)
    } catch (error) {
      console.error('Failed to fetch audio from URL:', error)
      if (onEnded) {
        onEnded()
      }
    }
  }

  // PCM16å½¢å¼ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
  private detectPCM16(buffer: ArrayBuffer): boolean {
    // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºãŒå¶æ•°ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    if (buffer.byteLength % 2 !== 0) {
      return false
    }

    // ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’ãƒã‚§ãƒƒã‚¯
    const int16Array = new Int16Array(buffer)
    let isWithinRange = true
    for (let i = 0; i < Math.min(1000, int16Array.length); i++) {
      if (int16Array[i] < -32768 || int16Array[i] > 32767) {
        isWithinRange = false
        break
      }
    }

    // ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã‚’ç°¡å˜ã«ãƒã‚§ãƒƒã‚¯
    let nonZeroCount = 0
    for (let i = 0; i < Math.min(1000, int16Array.length); i++) {
      if (int16Array[i] !== 0) {
        nonZeroCount++
      }
    }

    // å°‘ãªãã¨ã‚‚ãƒ‡ãƒ¼ã‚¿ã®10%ãŒéã‚¼ãƒ­ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    const hasReasonableDistribution =
      nonZeroCount > Math.min(1000, int16Array.length) * 0.1

    return isWithinRange && hasReasonableDistribution
  }

  /**
   * HTMLAudioElementã‚’LipSyncåˆ†æã«æ¥ç¶š
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ãªã©ã§LipSyncã‚’å‹•ä½œã•ã›ã‚‹ãŸã‚ã«ä½¿ç”¨
   */
  public connectAudioElement(audioElement: HTMLAudioElement): void {
    console.log('ğŸ”— HTMLAudioElementã‚’LipSyncã«æ¥ç¶šé–‹å§‹')
    
    try {
      // æ—¢å­˜ã®æ¥ç¶šã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      this.disconnectAudioElement()
      
      // MediaElementAudioSourceNodeã‚’ä½œæˆ
      this.audioElementSource = this.audio.createMediaElementSource(audioElement)
      this.connectedAudioElement = audioElement
      
      // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚°ãƒ©ãƒ•ã«æ¥ç¶š: audioElement â†’ mediaElementSource â†’ gainNode â†’ analyser â†’ destination
      this.audioElementSource.connect(this.gainNode)
      
      console.log('âœ… HTMLAudioElementã‚’LipSyncã«æ¥ç¶šå®Œäº†')
      
      // å†ç”Ÿé–‹å§‹/çµ‚äº†ã®ç›£è¦–
      const handlePlay = () => {
        console.log('â–¶ï¸ HTMLAudioElementå†ç”Ÿé–‹å§‹')
      }
      
      const handleEnded = () => {
        console.log('ğŸ HTMLAudioElementå†ç”Ÿçµ‚äº†')
      }
      
      audioElement.addEventListener('play', handlePlay)
      audioElement.addEventListener('ended', handleEnded)
      audioElement.addEventListener('pause', handleEnded)
      
    } catch (error) {
      console.error('âŒ HTMLAudioElementæ¥ç¶šã‚¨ãƒ©ãƒ¼:', error)
      this.disconnectAudioElement()
      throw error // ã‚¨ãƒ©ãƒ¼ã‚’å†ã‚¹ãƒ­ãƒ¼ã—ã¦ä¸Šä½ã§å‡¦ç†
    }
  }

  /**
   * HTMLAudioElementã®æ¥ç¶šã‚’è§£é™¤
   */
  public disconnectAudioElement(): void {
    if (this.audioElementSource) {
      try {
        this.audioElementSource.disconnect()
        this.audioElementSource = null
        console.log('âœ… HTMLAudioElementæ¥ç¶šè§£é™¤å®Œäº†')
      } catch (error) {
        console.warn('âš ï¸ HTMLAudioElementæ¥ç¶šè§£é™¤ã‚¨ãƒ©ãƒ¼:', error)
      }
    }
    this.connectedAudioElement = null
  }

  /**
   * ç¾åœ¨å†ç”Ÿä¸­ã®éŸ³å£°ã‚’åœæ­¢
   */
  public stopCurrentPlayback() {
    console.log('ğŸ›‘ éŸ³å£°å†ç”Ÿåœæ­¢è¦æ±‚')
    try {
      if (this.currentSource) {
        this.currentSource.stop()
        console.log('âœ… AudioBufferSourceéŸ³å£°å†ç”Ÿåœæ­¢å®Œäº†')
      }
      
      if (this.connectedAudioElement) {
        this.connectedAudioElement.pause()
        console.log('âœ… HTMLAudioElementéŸ³å£°å†ç”Ÿåœæ­¢å®Œäº†')
      }
      
      if (!this.currentSource && !this.connectedAudioElement) {
        console.log('â„¹ï¸ åœæ­¢ã™ã‚‹éŸ³å£°ã¯ã‚ã‚Šã¾ã›ã‚“')
      }
    } catch (e) {
      console.warn('âš ï¸ LipSync stopCurrentPlayback error:', e)
    }
    this.currentSource = null
  }

  /**
   * è¨ºæ–­æƒ…å ±ã‚’å–å¾—
   */
  public getStatus() {
    // ç¾åœ¨ã®éŸ³é‡ã‚‚è¨ˆç®—
    let currentVolume = 0
    if (this.analyser && this.timeDomainData) {
      this.analyser.getFloatTimeDomainData(this.timeDomainData)
      for (let i = 0; i < TIME_DOMAIN_DATA_LENGTH; i++) {
        currentVolume = Math.max(currentVolume, Math.abs(this.timeDomainData[i]))
      }
    }

    return {
      audioContextState: this.audio.state,
      sampleRate: this.audio.sampleRate,
      currentTime: this.audio.currentTime,
      userInteracted: this.userInteracted,
      waitingForInteraction: this.waitingForInteraction,
      pendingPlaybacksCount: this.pendingPlaybacks.length,
      forceStart: this.forceStart,
      hasCurrentSource: !!this.currentSource,
      initializationRetries: this.initializationRetries,
      maxRetries: this.maxRetries,
      analyserConnected: !!this.analyser,
      analyserFftSize: this.analyser?.fftSize,
      analyserSmoothingTimeConstant: this.analyser?.smoothingTimeConstant,
      analyserMinDecibels: this.analyser?.minDecibels,
      analyserMaxDecibels: this.analyser?.maxDecibels,
      timeDomainDataLength: this.timeDomainData?.length,
      currentRawVolume: currentVolume,
    }
  }

  /**
   * ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«è©³ç´°ãªè¨ºæ–­æƒ…å ±ã‚’å‡ºåŠ›
   */
  public logDetailedStatus() {
    const status = this.getStatus()
    console.log('ğŸ” LipSyncè©³ç´°çŠ¶æ…‹:', status)

    // å•é¡Œã®å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆã®è­¦å‘Š
    if (status.audioContextState !== 'running') {
      console.warn(
        'âš ï¸ AudioContextãŒå®Ÿè¡Œä¸­ã§ã¯ã‚ã‚Šã¾ã›ã‚“:',
        status.audioContextState
      )
    }

    if (!status.userInteracted && !status.forceStart) {
      console.warn('âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“')
    }

    if (status.pendingPlaybacksCount > 0) {
      console.warn(
        `âš ï¸ ${status.pendingPlaybacksCount}å€‹ã®å†ç”ŸãŒãƒšãƒ³ãƒ‡ã‚£ãƒ³ã‚°ä¸­ã§ã™`
      )
    }

    if (status.initializationRetries > 0) {
      console.warn(
        `âš ï¸ ${status.initializationRetries}å›ã®åˆæœŸåŒ–ãƒªãƒˆãƒ©ã‚¤ãŒç™ºç”Ÿã—ã¾ã—ãŸ`
      )
    }
  }
}
